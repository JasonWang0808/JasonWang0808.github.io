<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Junyu Wang&#39;s Blog</title>
  
  <subtitle>hello</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-01-07T16:46:45.852Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>JunYu Wang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>test</title>
    <link href="http://yoursite.com/2019/01/08/---/"/>
    <id>http://yoursite.com/2019/01/08/---/</id>
    <published>2019-01-07T16:46:45.852Z</published>
    <updated>2019-01-07T16:46:45.852Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Data Structure(1) Linked List</title>
    <link href="http://yoursite.com/2019/01/08/DT_LinkedList/"/>
    <id>http://yoursite.com/2019/01/08/DT_LinkedList/</id>
    <published>2019-01-07T16:12:50.611Z</published>
    <updated>2019-01-07T16:27:46.502Z</updated>
    
    <content type="html"><![CDATA[<ol start="206"><li>Reverse Linked List</li><li>Reverse Linked List 2<br>考察链表的指针操作  </li></ol><p>Notes: 要充分注意首尾是否指针为空</p><p>Tips：<strong>虚拟头节点</strong></p><blockquote><p>可以定义一个dummyHead作为head前面的标志性指针, 好处是，不管head怎样变化，只要调用其next总能找到现在的head（203，82）</p></blockquote><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ListNode *dummyHead = ListNode(-<span class="number">1</span>)<span class="comment">;</span></span><br><span class="line">dummyHead-&gt;next = head<span class="comment">;</span></span><br></pre></td></tr></table></figure><p>对于特定的92号问题，反转链表，我们可以通过一个函数返回两个数据：  </p><ol><li>最左边的元素  </li><li>原本最左边的元素的next</li></ol><p>在链表中穿针引线（23，24，124，125， 237）<br>双指针（61，143，234，19）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol start=&quot;206&quot;&gt;
&lt;li&gt;Reverse Linked List&lt;/li&gt;
&lt;li&gt;Reverse Linked List 2&lt;br&gt;考察链表的指针操作  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Notes: 要充分注意首尾是否指针为空&lt;/p&gt;
&lt;p&gt;Tips：&lt;stron
      
    
    </summary>
    
      <category term="DT" scheme="http://yoursite.com/categories/DT/"/>
    
    
      <category term="DT" scheme="http://yoursite.com/tags/DT/"/>
    
  </entry>
  
  <entry>
    <title>Data Structure(2) Stack VS queue</title>
    <link href="http://yoursite.com/2019/01/07/DT_stack/"/>
    <id>http://yoursite.com/2019/01/07/DT_stack/</id>
    <published>2019-01-07T15:33:05.416Z</published>
    <updated>2019-01-07T16:20:02.023Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、基本介绍"><a href="#一、基本介绍" class="headerlink" title="一、基本介绍"></a>一、基本介绍</h4><h5 id="Stack，又名堆，后进先出问题。非常经典的一个括号匹配问题就是出自Stack之手。"><a href="#Stack，又名堆，后进先出问题。非常经典的一个括号匹配问题就是出自Stack之手。" class="headerlink" title="Stack，又名堆，后进先出问题。非常经典的一个括号匹配问题就是出自Stack之手。"></a>Stack，又名堆，后进先出问题。非常经典的一个括号匹配问题就是出自Stack之手。</h5><h5 id="Queue，又名队列，先进先出，常用于对“TreeNode”的层级问题的解答，因为每一层都可以看作是一个队列来进行处理。常用Vector-lt-Vector-gt-来进行计算"><a href="#Queue，又名队列，先进先出，常用于对“TreeNode”的层级问题的解答，因为每一层都可以看作是一个队列来进行处理。常用Vector-lt-Vector-gt-来进行计算" class="headerlink" title="Queue，又名队列，先进先出，常用于对“TreeNode”的层级问题的解答，因为每一层都可以看作是一个队列来进行处理。常用Vector&lt;Vector&gt;来进行计算"></a>Queue，又名队列，先进先出，常用于对“TreeNode”的层级问题的解答，因为每一层都可以看作是一个队列来进行处理。常用Vector&lt;Vector<int>&gt;来进行计算</int></h5><blockquote><p>102,103,104,199都可以用队列来解答</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Stack常用用法</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stack&gt;</span></span></span><br><span class="line"><span class="built_in">stack</span>&lt; pair &lt;Node*, <span class="keyword">int</span>&gt;&gt; s1; <span class="comment">//设立一个包含pair的Stack  </span></span><br><span class="line">s1.top();</span><br><span class="line">s1.push_back();</span><br><span class="line">s1.pop();</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// queue常用用法</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="built_in">queue</span>&lt;&lt; pair &lt;Node*, <span class="keyword">int</span>&gt;&gt; q1; <span class="comment">//设立一个包含pair的Stack  </span></span><br><span class="line">s1.top();</span><br><span class="line">s1.push();</span><br><span class="line">s1.pop();</span><br></pre></td></tr></table></figure><h4 id="二、图论应用"><a href="#二、图论应用" class="headerlink" title="二、图论应用"></a>二、图论应用</h4><blockquote><p>类似练习127，126<br>例如leetcode279题，寻找相加平方数最少的一种方案。<br>我们可以将其想像成求无权边的最短路径，使用BFS</p></blockquote><blockquote><p>例如计算9，首先8–&gt;9(1), 5–&gt;9(2), 0–&gt;9(3) , 9就连接了三个顶点分别是0,5,8</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Leetcode279</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">numSquares</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt; isvisit(n+<span class="number">1</span>, <span class="number">0</span>);</span><br><span class="line">        isvisit[n] = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">queue</span>&lt; pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt;&gt; queue1;</span><br><span class="line">        queue1.push(make_pair(n, <span class="number">0</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(queue1.empty() == <span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">int</span> Node_n = queue1.front().first;</span><br><span class="line">            <span class="keyword">int</span> dis = queue1.front().second;</span><br><span class="line">            queue1.pop();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; ; i ++)&#123;</span><br><span class="line">                <span class="keyword">int</span> temp = i * i;</span><br><span class="line">                <span class="keyword">if</span>(temp &gt; Node_n) <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(temp == Node_n)&#123;</span><br><span class="line">                    <span class="keyword">return</span> dis + <span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span>&#123;</span><br><span class="line">                    <span class="keyword">if</span>(isvisit[Node_n - temp] == <span class="number">0</span> )&#123;</span><br><span class="line">                        queue1.push(make_pair(Node_n - temp, dis+<span class="number">1</span>));</span><br><span class="line">                        isvisit[Node_n - temp] = <span class="number">1</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;一、基本介绍&quot;&gt;&lt;a href=&quot;#一、基本介绍&quot; class=&quot;headerlink&quot; title=&quot;一、基本介绍&quot;&gt;&lt;/a&gt;一、基本介绍&lt;/h4&gt;&lt;h5 id=&quot;Stack，又名堆，后进先出问题。非常经典的一个括号匹配问题就是出自Stack之手。&quot;&gt;&lt;a hr
      
    
    </summary>
    
      <category term="DT" scheme="http://yoursite.com/categories/DT/"/>
    
    
  </entry>
  
  <entry>
    <title>收到offer之后的申请流程</title>
    <link href="http://yoursite.com/2018/11/27/wisc_prepare/"/>
    <id>http://yoursite.com/2018/11/27/wisc_prepare/</id>
    <published>2018-11-27T11:50:28.000Z</published>
    <updated>2018-11-27T11:50:28.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="我们这里以UW-Madison为例讲一下留学得到offer后的操作"><a href="#我们这里以UW-Madison为例讲一下留学得到offer后的操作" class="headerlink" title="我们这里以UW-Madison为例讲一下留学得到offer后的操作"></a>我们这里以UW-Madison为例讲一下留学得到offer后的操作</h3><h4 id="先给出一个流程图，大概说一下整个的流程"><a href="#先给出一个流程图，大概说一下整个的流程" class="headerlink" title="先给出一个流程图，大概说一下整个的流程"></a>先给出一个流程图，大概说一下整个的流程</h4><p> <img src="/images/qianzheng/process.jpg" width="300" height="200" alt="img1" align="center"></p><h4 id="1-首先要做的当然是Accept-offer"><a href="#1-首先要做的当然是Accept-offer" class="headerlink" title="1. 首先要做的当然是Accept offer"></a>1. 首先要做的当然是<strong>Accept offer</strong></h4><h4 id="2-接着我们需要拿到一个叫做I-20的文件（这个每个学校的操作可能各有不同）"><a href="#2-接着我们需要拿到一个叫做I-20的文件（这个每个学校的操作可能各有不同）" class="headerlink" title="2. 接着我们需要拿到一个叫做I-20的文件（这个每个学校的操作可能各有不同）"></a>2. 接着我们需要拿到一个叫做I-20的文件（这个每个学校的操作可能各有不同）</h4><blockquote><p><a href="https://www.admissions.wisc.edu/admitted/checklist/spring_international.php" target="_blank" rel="noopener">Checklist 4. 中列出了需要的文件</a></p></blockquote><h4 id="申请I20在UW-Madison一共需要4个文件"><a href="#申请I20在UW-Madison一共需要4个文件" class="headerlink" title="申请I20在UW-Madison一共需要4个文件"></a>申请I20在UW-Madison一共需要4个文件</h4><ul><li style="list-style: none"><input type="checkbox" checked> <a href="https://www.admissions.wisc.edu/assets/pdfs/UW_Financial_Verification_Form.pdf" target="_blank" rel="noopener">Financial Verification Form</a></li><li style="list-style: none"><input type="checkbox" checked> 存款证明</li><li style="list-style: none"><input type="checkbox" checked> <a href="https://www.admissions.wisc.edu/assets/pdfs/UW_VISA_Form.pdf/" target="_blank" rel="noopener">Student Visa Information and Mailing Form</a></li><li style="list-style: none"><input type="checkbox" checked> Copies of passport pages showing your identity and full legal name</li></ul><h5 id="准备好了四个文件，将pdf发给onwisconsin-admissions-wisc-edu就结束了I20的申请"><a href="#准备好了四个文件，将pdf发给onwisconsin-admissions-wisc-edu就结束了I20的申请" class="headerlink" title="准备好了四个文件，将pdf发给onwisconsin@admissions.wisc.edu就结束了I20的申请"></a>准备好了四个文件，将pdf发给<a href="mailto:onwisconsin@admissions.wisc.edu" target="_blank" rel="noopener">onwisconsin@admissions.wisc.edu</a>就结束了I20的申请</h5><h4 id="3-等待I-20，这是一个漫长的过程，大概需要两个半星期"><a href="#3-等待I-20，这是一个漫长的过程，大概需要两个半星期" class="headerlink" title="3. 等待I-20，这是一个漫长的过程，大概需要两个半星期"></a>3. 等待I-20，这是一个漫长的过程，大概需要两个半星期</h4><h4 id="4-1-拿到I-20之后就要申请F-1签证了"><a href="#4-1-拿到I-20之后就要申请F-1签证了" class="headerlink" title="4.1 拿到I-20之后就要申请F-1签证了"></a>4.1 拿到I-20之后就要申请F-1签证了</h4><blockquote><p>这里UW-Madison给出了一些<a href="https://www.admissions.wisc.edu/assets/pdfs/obtainvisa.pdf" target="_blank" rel="noopener">F-1签证的tips</a></p></blockquote><p>但是个人感觉上述说的不是很具体，这里给出两个比较生动形象的公众号贴文 (<a href="https://mp.weixin.qq.com/s/-tSUKd-a01NGkra7UxZx0w" target="_blank" rel="noopener">文章1</a>，<a href="https://mp.weixin.qq.com/s/1mStu5ztzIugQR8D7Hkp7Q" target="_blank" rel="noopener">文章2</a>)<br>看完这两个文章，并准备好相应的材料就可以预约面签了  </p><h4 id="4-2-与此同时我们应该开始准备Placement-Test了"><a href="#4-2-与此同时我们应该开始准备Placement-Test了" class="headerlink" title="4.2 与此同时我们应该开始准备Placement Test了"></a>4.2 与此同时我们应该开始准备Placement Test了</h4><blockquote><p><a href="https://exams.wisc.edu/placement/uw-madison-students.php" target="_blank" rel="noopener">这里是FAQ</a>  届时会有邮件通知我们需要参加什么类别的考试<br>点击-&gt; <a href="https://exams.wisc.edu/placement/regionaltesting/information.php" target="_blank" rel="noopener">进入注册placement test</a>  </p></blockquote><blockquote><p><a href="https://soar.wisc.edu/" target="_blank" rel="noopener">同样可以在SOAR 2.中看到详细信息</a>  </p></blockquote><h4 id="5-拿到F-1签证准备好行李顺顺利利去上学"><a href="#5-拿到F-1签证准备好行李顺顺利利去上学" class="headerlink" title="5. 拿到F-1签证准备好行李顺顺利利去上学"></a>5. 拿到F-1签证准备好行李顺顺利利去上学</h4>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;我们这里以UW-Madison为例讲一下留学得到offer后的操作&quot;&gt;&lt;a href=&quot;#我们这里以UW-Madison为例讲一下留学得到offer后的操作&quot; class=&quot;headerlink&quot; title=&quot;我们这里以UW-Madison为例讲一下留学得到of
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>how to use Ubuntu and Git to push projects</title>
    <link href="http://yoursite.com/2018/11/19/Ubuntu-git/"/>
    <id>http://yoursite.com/2018/11/19/Ubuntu-git/</id>
    <published>2018-11-19T12:28:46.000Z</published>
    <updated>2018-11-19T12:28:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>首先下载git，这个不用我说了<br>在github上建立一个名字为XXX的仓库作为你要托管的对象，这里我采用learn-repo作为我的名字  </p><blockquote><p>JasonWang0808/Learn-repo</p></blockquote><p>在Ubuntu下生成SSH key来连接自己的github，可以参考<a href="https://segmentfault.com/a/1190000013154540" target="_blank" rel="noopener">这个博文</a>, 此处也不啰嗦  </p><p>接下来在ubuntu中建立一个文件夹作为本地仓库</p><figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 初始化</span></span><br><span class="line">git init</span><br><span class="line"></span><br><span class="line"><span class="meta"># 建立文件（以及做出类似改动）</span></span><br><span class="line">touch README.md</span><br><span class="line">git add README.md</span><br><span class="line"></span><br><span class="line"><span class="meta"># 提交本次的改动，注意后面的注释参数不要拉下</span></span><br><span class="line">git commit -m <span class="string">'first_commit'</span></span><br><span class="line"></span><br><span class="line"><span class="meta"># 建立远程连接 origin就是仓库名字而已，允许修改</span></span><br><span class="line">git remote add origin https:<span class="comment">//github.com/JasonWang0808/learn-repo.git</span></span><br><span class="line"></span><br><span class="line"><span class="meta"># 将新的仓库内容push到刚刚命名的origin，并且为master分支  </span></span><br><span class="line">git push origin master</span><br><span class="line">---------------------</span><br></pre></td></tr></table></figure><p>遇到的坑</p><ol><li>直接复制文件夹过来上传后是灰色的</li></ol><blockquote><p>不知道为啥，自己新建然后cp吧</p></blockquote><ol start="2"><li>报错：error:failed to push som refs to……</li></ol><blockquote><p>git pull –rebase origin master   可能是本地和远程有区别等原因</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;首先下载git，这个不用我说了&lt;br&gt;在github上建立一个名字为XXX的仓库作为你要托管的对象，这里我采用learn-repo作为我的名字  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;JasonWang0808/Learn-repo&lt;/p&gt;
&lt;/blockquote&gt;

      
    
    </summary>
    
      <category term="Git" scheme="http://yoursite.com/categories/Git/"/>
    
    
      <category term="Git" scheme="http://yoursite.com/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>Hidden Markov Model，HMM</title>
    <link href="http://yoursite.com/2018/11/19/HMM/"/>
    <id>http://yoursite.com/2018/11/19/HMM/</id>
    <published>2018-11-19T02:25:44.000Z</published>
    <updated>2018-11-19T02:25:44.000Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>  <h3 id="隐马尔可夫模型在词性标注上的应用"><a href="#隐马尔可夫模型在词性标注上的应用" class="headerlink" title="隐马尔可夫模型在词性标注上的应用"></a>隐马尔可夫模型在词性标注上的应用</h3><blockquote><p>给定前提我们只关注N/M/V三个词性  </p></blockquote><h4 id="首先介绍第一个概念-Emission-Probabilities"><a href="#首先介绍第一个概念-Emission-Probabilities" class="headerlink" title="首先介绍第一个概念  Emission Probabilities"></a>首先介绍第一个概念  Emission Probabilities</h4><h4 id="gt-是指同一种状态各个数值得可能性，可以看下图"><a href="#gt-是指同一种状态各个数值得可能性，可以看下图" class="headerlink" title="&gt; 是指同一种状态各个数值得可能性，可以看下图"></a>&gt; 是指同一种状态各个数值得可能性，可以看下图</h4><p><img src="/images/NLP/HMM/1.png" alt="">  </p><h4 id="我们可以看到，当认为是当前词语是N的时候有4-9的可能性是mary"><a href="#我们可以看到，当认为是当前词语是N的时候有4-9的可能性是mary" class="headerlink" title="我们可以看到，当认为是当前词语是N的时候有4/9的可能性是mary"></a>我们可以看到，当认为是当前词语是N的时候有4/9的可能性是mary</h4><h4 id="接下来是第二个概念-Transition-Probabilities"><a href="#接下来是第二个概念-Transition-Probabilities" class="headerlink" title="接下来是第二个概念  Transition Probabilities"></a>接下来是第二个概念  Transition Probabilities</h4><h4 id="gt-指状态之间的转换概率，S-E分别表示开始和结束，看下图"><a href="#gt-指状态之间的转换概率，S-E分别表示开始和结束，看下图" class="headerlink" title="&gt; 指状态之间的转换概率，S/E分别表示开始和结束，看下图"></a>&gt; 指状态之间的转换概率，S/E分别表示开始和结束，看下图</h4><p><img src="/images/NLP/HMM/2.png" alt="">  </p><h4 id="OK，那我们先来看一个例子"><a href="#OK，那我们先来看一个例子" class="headerlink" title="OK，那我们先来看一个例子"></a>OK，那我们先来看一个例子</h4><blockquote><p>Jane will spot Will  </p></blockquote><h4 id="我们根据前序经验统计出前面的两个概率，然后可以构造流程图如下"><a href="#我们根据前序经验统计出前面的两个概率，然后可以构造流程图如下" class="headerlink" title="我们根据前序经验统计出前面的两个概率，然后可以构造流程图如下"></a>我们根据前序经验统计出前面的两个概率，然后可以构造流程图如下</h4><p><img src="/images/NLP/HMM/3.png" alt="">   </p><h4 id="我们要计算每一条链的可能性就是把边数值与节点数值一路相乘，为了减少计算，我们采用每一层的动态规划（就是最简单那种），每个节点只保留前序节点数值最大的那一条。"><a href="#我们要计算每一条链的可能性就是把边数值与节点数值一路相乘，为了减少计算，我们采用每一层的动态规划（就是最简单那种），每个节点只保留前序节点数值最大的那一条。" class="headerlink" title="我们要计算每一条链的可能性就是把边数值与节点数值一路相乘，为了减少计算，我们采用每一层的动态规划（就是最简单那种），每个节点只保留前序节点数值最大的那一条。"></a>我们要计算每一条链的可能性就是把边数值与节点数值一路相乘，为了减少计算，我们采用每一层的动态规划（就是最简单那种），每个节点只保留前序节点数值最大的那一条。</h4><h4 id="最后我们就可以得到这样一条-通过分析我们可以发现确实得到的结果和我们预期相同"><a href="#最后我们就可以得到这样一条-通过分析我们可以发现确实得到的结果和我们预期相同" class="headerlink" title="最后我们就可以得到这样一条,通过分析我们可以发现确实得到的结果和我们预期相同"></a>最后我们就可以得到这样一条,通过分析我们可以发现确实得到的结果和我们预期相同</h4><h2 id=""><a href="#" class="headerlink" title="   "></a><img src="/images/NLP/HMM/3.png" alt="">   </h2><h3 id="以上是找best-path，接下来我们看一下HMM的forward-algorithm"><a href="#以上是找best-path，接下来我们看一下HMM的forward-algorithm" class="headerlink" title="以上是找best path，接下来我们看一下HMM的forward algorithm"></a>以上是找best path，接下来我们看一下HMM的forward algorithm</h3><hr><p>已知概率分布  </p><p><strong>1. Initial</strong></p><table><thead><tr><th>Sunny</th><th>Rainy</th></tr></thead><tbody><tr><td>0.5</td><td>0.5</td></tr></tbody></table><p><strong>2. Emission Probabilities</strong></p><table><thead><tr><th>null</th><th>yes</th><th>no</th></tr></thead><tbody><tr><td>sunny</td><td>0.1</td><td>0.9</td></tr><tr><td>rainy</td><td>0.8</td><td>0.2</td></tr></tbody></table><p><strong>3. State transition probabilities</strong></p><table><thead><tr><th>null</th><th>sunny</th><th>rainy</th></tr></thead><tbody><tr><td>sunny</td><td>0.8</td><td>0.2</td></tr><tr><td>rainy</td><td>0.4</td><td>0.6  </td></tr></tbody></table><h5 id="现在给定一个序列-S-‘yes’-‘no’-‘yes’"><a href="#现在给定一个序列-S-‘yes’-‘no’-‘yes’" class="headerlink" title="现在给定一个序列 S = [‘yes’, ‘no’, ‘yes’]"></a>现在给定一个序列 S = [‘yes’, ‘no’, ‘yes’]</h5><h5 id="通过forward-algorithm可以计算出在所有的天气组合当中所有满足该序列的概率"><a href="#通过forward-algorithm可以计算出在所有的天气组合当中所有满足该序列的概率" class="headerlink" title="通过forward algorithm可以计算出在所有的天气组合当中所有满足该序列的概率\"></a>通过forward algorithm可以计算出在所有的天气组合当中所有满足该序列的概率\</h5><p>$$<br>P(S|1-sunny) = 0.5 * 0.1 = 0.05<br>$$</p><p>$$<br>P(S|1-rainy) = 0.5 * 0.8 = 0.4<br>$$</p><p>$$<br>P(S|2-sunny) = (P(S|1-sunny)*0.8 + P(S|1-rainy)*0.4)P(no|sunny)<br>$$</p><h4 id="以此类推，最终结果为-P-S-3-sunny-P-S-3-rainy"><a href="#以此类推，最终结果为-P-S-3-sunny-P-S-3-rainy" class="headerlink" title="以此类推，最终结果为\(P(S|3-sunny) + P(S|3-rainy)\)"></a>以此类推，最终结果为\(P(S|3-sunny) + P(S|3-rainy)\)</h4><h4 id="我们可以看出来这个过程相当繁琐-这里用pomegranate库来实现"><a href="#我们可以看出来这个过程相当繁琐-这里用pomegranate库来实现" class="headerlink" title="我们可以看出来这个过程相当繁琐, 这里用pomegranate库来实现"></a>我们可以看出来这个过程相当繁琐, 这里用pomegranate库来实现</h4><blockquote><p>参考的问题是关于一个海藻的理论推导 <a href="https://blog.csdn.net/TH_NUM/article/details/51570174" target="_blank" rel="noopener">https://blog.csdn.net/TH_NUM/article/details/51570174</a></p></blockquote><h4 id="为什么和手动算的结果有些偏差呢，因为这个每一步都会进行估算"><a href="#为什么和手动算的结果有些偏差呢，因为这个每一步都会进行估算" class="headerlink" title="为什么和手动算的结果有些偏差呢，因为这个每一步都会进行估算"></a>为什么和手动算的结果有些偏差呢，因为这个每一步都会进行估算</h4><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">from pomegranate import State, HiddenMarkovModel, <span class="keyword">DiscreteDistribution</span></span><br><span class="line"><span class="keyword">import </span>numpy as np</span><br><span class="line">model = HiddenMarkovModel(name=<span class="string">"Example Model"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置每个状态的发射概率</span></span><br><span class="line">sunny_emissions = <span class="keyword">DiscreteDistribution(&#123;"Dry": </span><span class="number">0</span>.<span class="number">6</span>, <span class="string">"Dryish"</span>: <span class="number">0</span>.<span class="number">2</span>, <span class="string">"Damp"</span>:<span class="number">0</span>.<span class="number">15</span>, <span class="string">"Soggy"</span>:<span class="number">0</span>.<span class="number">05</span>&#125;)</span><br><span class="line">sunny_state = State(sunny_emissions, name=<span class="string">"Sunny"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">cloud_emissions </span>= <span class="keyword">DiscreteDistribution(&#123;"Dry": </span><span class="number">0</span>.<span class="number">25</span>, <span class="string">"Dryish"</span>: <span class="number">0</span>.<span class="number">25</span>, <span class="string">"Damp"</span>:<span class="number">0</span>.<span class="number">25</span>, <span class="string">"Soggy"</span>:<span class="number">0</span>.<span class="number">25</span>&#125;)</span><br><span class="line"><span class="keyword">cloud_state </span>= State(<span class="keyword">cloud_emissions, </span>name=<span class="string">"Cloud"</span>)</span><br><span class="line"></span><br><span class="line">rainy_emissions = <span class="keyword">DiscreteDistribution(&#123;"Dry": </span><span class="number">0</span>.<span class="number">05</span>, <span class="string">"Dryish"</span>: <span class="number">0</span>.<span class="number">10</span>, <span class="string">"Damp"</span>:<span class="number">0</span>.<span class="number">35</span>, <span class="string">"Soggy"</span>:<span class="number">0</span>.<span class="number">50</span>&#125;)</span><br><span class="line">rainy_state = State(rainy_emissions, name=<span class="string">"Rainy"</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="keyword">cloud_emissions.probability("Dryish"))</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword"># </span>添加状态</span><br><span class="line">model.<span class="keyword">add_states(sunny_state, </span><span class="keyword">cloud_state, </span>rainy_state)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加转移概率，从init开始</span></span><br><span class="line">model.<span class="keyword">add_transition(model.start, </span>sunny_state, <span class="number">0</span>.<span class="number">63</span>)</span><br><span class="line">model.<span class="keyword">add_transition(model.start, </span>rainy_state, <span class="number">0</span>.<span class="number">20</span>)</span><br><span class="line">model.<span class="keyword">add_transition(model.start, </span><span class="keyword">cloud_state, </span><span class="number">0</span>.<span class="number">17</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.<span class="keyword">add_transition(sunny_state, </span>sunny_state, <span class="number">0</span>.<span class="number">5</span>)  <span class="comment"># 50% sunny-&gt;sunny</span></span><br><span class="line">model.<span class="keyword">add_transition(sunny_state, </span>rainy_state, <span class="number">0</span>.<span class="number">125</span>)  <span class="comment"># 12.5% sunny-&gt;rainy</span></span><br><span class="line">model.<span class="keyword">add_transition(sunny_state, </span><span class="keyword">cloud_state, </span><span class="number">0</span>.<span class="number">375</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.<span class="keyword">add_transition(rainy_state, </span>sunny_state, <span class="number">0</span>.<span class="number">25</span>)  <span class="comment"># 25% rainy-&gt;sunny</span></span><br><span class="line">model.<span class="keyword">add_transition(rainy_state, </span>rainy_state, <span class="number">0</span>.<span class="number">375</span>)  <span class="comment"># 37.5% rainy-&gt;rainy</span></span><br><span class="line">model.<span class="keyword">add_transition(rainy_state, </span><span class="keyword">cloud_state, </span><span class="number">0</span>.<span class="number">375</span>)</span><br><span class="line"></span><br><span class="line">model.<span class="keyword">add_transition(cloud_state, </span><span class="keyword">cloud_state, </span><span class="number">0</span>.<span class="number">125</span>)</span><br><span class="line">model.<span class="keyword">add_transition(cloud_state, </span>sunny_state, <span class="number">0</span>.<span class="number">25</span>)</span><br><span class="line">model.<span class="keyword">add_transition(cloud_state, </span>rainy_state, <span class="number">0</span>.<span class="number">625</span>)</span><br><span class="line"><span class="comment"># 最后使用bake完结</span></span><br><span class="line">model.<span class="keyword">bake()</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword">observations </span>= [<span class="string">'Dry'</span>, <span class="string">'Damp'</span>, <span class="string">'Soggy'</span>]</span><br><span class="line">forward_matrix = np.exp(model.forward(observations))</span><br><span class="line"></span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span> use model.log_probability() to calculate the all-paths likelihood of the</span></span><br><span class="line"><span class="comment"># observed sequence and then use np.exp() to convert log-likelihood to likelihood</span></span><br><span class="line">probability_percentage = np.exp(model.log_probability(observations))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display the forward probabilities</span></span><br><span class="line">print(<span class="string">"         "</span> + <span class="string">""</span>.<span class="keyword">join(s.name.center(len(s.name)+6) </span>for s in model.states))</span><br><span class="line">for i in range(len(observations) + <span class="number">1</span>):</span><br><span class="line">    print(<span class="string">" &lt;start&gt; "</span> if i==<span class="number">0</span> else observations[i - <span class="number">1</span>].center(<span class="number">9</span>), end=<span class="string">""</span>)</span><br><span class="line">    print(<span class="string">""</span>.<span class="keyword">join("&#123;:.0f&#125;%".format(100 </span>* forward_matrix[i, <span class="keyword">j]).center(len(s.name) </span>+ <span class="number">6</span>)</span><br><span class="line">                  for <span class="keyword">j, </span>s in enumerate(model.states)))</span><br><span class="line"></span><br><span class="line">print(<span class="string">"\nThe likelihood over all possible paths "</span> + \</span><br><span class="line">      <span class="string">"of this model producing the sequence &#123;&#125; is &#123;:.2f&#125;%\n\n"</span></span><br><span class="line">      .format(observations, <span class="number">100</span> * probability_percentage))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&quot;&gt;&lt;/script&gt;  

&lt;h3 id=&quot;隐马尔可夫模型在词性标注
      
    
    </summary>
    
      <category term="NLP" scheme="http://yoursite.com/categories/NLP/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Basic modules of NLP python</title>
    <link href="http://yoursite.com/2018/11/18/python_models/"/>
    <id>http://yoursite.com/2018/11/18/python_models/</id>
    <published>2018-11-18T14:13:36.000Z</published>
    <updated>2018-11-18T14:13:36.000Z</updated>
    
    <content type="html"><![CDATA[<ol><li>指定二维数组, 可以调用a.keys()来查看索引  </li></ol><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">a</span> = defaultdict(list)</span><br></pre></td></tr></table></figure><ol start="2"><li>Cunter 可以统计一个list中各个部件出现的数量，可以搭配上面的defaultlist使用  </li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;指定二维数组, 可以调用a.keys()来查看索引  &lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight ini&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;
      
    
    </summary>
    
      <category term="tool" scheme="http://yoursite.com/categories/tool/"/>
    
    
      <category term="tool" scheme="http://yoursite.com/tags/tool/"/>
    
  </entry>
  
  <entry>
    <title>spam classification --- naive bayes</title>
    <link href="http://yoursite.com/2018/11/17/spam-classification/"/>
    <id>http://yoursite.com/2018/11/17/spam-classification/</id>
    <published>2018-11-17T05:57:40.000Z</published>
    <updated>2018-11-17T05:57:40.000Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script> <h3 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h3><h5 id="我们在清分的时候认为有easy和money就可能使垃圾邮件，通过检查邮件中有两个单词就可以说明是否为spam，“朴素”贝叶斯朴素在于认为各个元素是相互独立的，因此直接将概率相乘"><a href="#我们在清分的时候认为有easy和money就可能使垃圾邮件，通过检查邮件中有两个单词就可以说明是否为spam，“朴素”贝叶斯朴素在于认为各个元素是相互独立的，因此直接将概率相乘" class="headerlink" title="我们在清分的时候认为有easy和money就可能使垃圾邮件，通过检查邮件中有两个单词就可以说明是否为spam，“朴素”贝叶斯朴素在于认为各个元素是相互独立的，因此直接将概率相乘"></a>我们在清分的时候认为有easy和money就可能使垃圾邮件，通过检查邮件中有两个单词就可以说明是否为spam，“朴素”贝叶斯朴素在于认为各个元素是相互独立的，因此直接将概率相乘</h5><p>$$<br>(1) P(spam) P(‘easy’|spam) P(‘money’|spam)  +  P(ham) P(‘easy’|ham) P(‘money’|ham) = \alpha<br>$$</p><p>$$<br>(2) P(spam|’easy’, ‘money’) = \frac{ P(spam) P(‘easy’|spam) P(‘money’|spam) }{\alpha}<br>$$    </p><p>$$<br>(3) P(ham|’easy’, ‘money’) = \frac{ P(ham) P(‘easy’|ham) P(‘money’|ham) }{\alpha}<br>$$</p><p>$$<br> Final : P(spam|’easy’, ‘money’)  +  P(ham|’easy’, ‘money’) = 1<br>$$</p><h5 id="当然我们在实际过程中调用sklearn-naive-bayes-MultinomialNB就可以"><a href="#当然我们在实际过程中调用sklearn-naive-bayes-MultinomialNB就可以" class="headerlink" title="当然我们在实际过程中调用sklearn.naive_bayes.MultinomialNB就可以"></a>当然我们在实际过程中调用sklearn.naive_bayes.MultinomialNB就可以</h5><h5 id="gt-注意训练数据的形式是dataframe，用pandas直接读取或者是用matrix转换"><a href="#gt-注意训练数据的形式是dataframe，用pandas直接读取或者是用matrix转换" class="headerlink" title="&gt; 注意训练数据的形式是dataframe，用pandas直接读取或者是用matrix转换"></a>&gt; 注意训练数据的形式是dataframe，用pandas直接读取或者是用matrix转换</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># Dataset from - https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"></span><br><span class="line">df = pd.read_table(</span><br><span class="line">        <span class="string">'./smsspamcollection/SMSSpamCollection'</span>,</span><br><span class="line">        sep=<span class="string">'\t'</span>,</span><br><span class="line">       names = [<span class="string">'label'</span>, <span class="string">'sms_message'</span>]</span><br><span class="line">        )</span><br><span class="line"><span class="comment"># Note1. 注意读出的是data_frame，命名用names</span></span><br><span class="line"></span><br><span class="line">df[<span class="string">'label'</span>] = df.label.map(&#123;<span class="string">'spam'</span>:<span class="number">1</span>, <span class="string">'ham'</span>:<span class="number">0</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Note2. 二分类问题</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(df[<span class="string">'sms_message'</span>],</span><br><span class="line">                                                    df[<span class="string">'label'</span>],</span><br><span class="line">                                                    random_state=<span class="number">1</span>)</span><br><span class="line">count_vector = CountVectorizer()</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">fit是找到规律，如果fit过之后就可以直接transform，因为规律已经学会了</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">training_data = count_vector.fit_transform(X_train)</span><br><span class="line">testing_data = count_vector.transform(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line">naive_bayes = MultinomialNB()</span><br><span class="line">naive_bayes.fit(training_data, y_train)</span><br><span class="line">predictions = naive_bayes.predict(testing_data)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Precision tells us what proportion of messages we classified as spam, actually were spam.</span></span><br><span class="line"><span class="string">[True Positives/(True Positives + False Positives)]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Recall tells us what proportion of messages we classified as spam in the total number of spam</span></span><br><span class="line"><span class="string">[True Positives/(True Positives + False Negatives)]</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, precision_score, recall_score, f1_score</span><br><span class="line">print(<span class="string">'Accuracy score: '</span>, format(accuracy_score(y_test, predictions)))</span><br><span class="line">print(<span class="string">'Precision score: '</span>, format(precision_score(y_test, predictions)))</span><br><span class="line">print(<span class="string">'Recall score: '</span>, format(recall_score(y_test, predictions)))</span><br><span class="line">print(<span class="string">'F1 score: '</span>, format(f1_score(y_test, predictions)))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&quot;&gt;&lt;/script&gt; 

&lt;h3 id=&quot;举个栗子&quot;&gt;&lt;a href
      
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>NLP(First) Text Processing</title>
    <link href="http://yoursite.com/2018/11/14/NLP1/"/>
    <id>http://yoursite.com/2018/11/14/NLP1/</id>
    <published>2018-11-14T14:26:22.000Z</published>
    <updated>2018-11-14T14:26:22.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="basic-rules-of-text-procession-and-how-to-use-nltk"><a href="#basic-rules-of-text-procession-and-how-to-use-nltk" class="headerlink" title="basic rules of text procession and how to use nltk"></a>basic rules of text procession and how to use nltk</h2><h3 id="下图是一个简单的处理流程"><a href="#下图是一个简单的处理流程" class="headerlink" title="下图是一个简单的处理流程"></a>下图是一个简单的处理流程</h3><p><img src="/images/NLP/text_processing/text_p.png" alt=""></p><p>判断一段文字中单词出现的数量是一个经典的问题，首先建立一个dict。接着把str用spilt给分开，用正则表达式去除标点，然后统计数量</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def count_words(str):</span><br><span class="line">    <span class="string">""</span><span class="string">"Count how many times each unique word occurs in text."</span><span class="string">""</span></span><br><span class="line">    counts = dict()  <span class="comment"># dictionary of &#123; &lt;word&gt;: &lt;count&gt; &#125; pairs to return</span></span><br><span class="line">    <span class="comment"># text = str(text)</span></span><br><span class="line">    <span class="comment"># str = "one and two and three and two and one\nbuffalo buffalo buffalo, buffalo buffalo!"</span></span><br><span class="line">    str = str.<span class="built_in">replace</span>(<span class="string">"\n"</span>, <span class="string">" "</span>)</span><br><span class="line">    str = str.<span class="built_in">lower</span>()</span><br><span class="line">    word_l = str.<span class="built_in">split</span>(<span class="string">" "</span>)</span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Split text into tokens (words), leaving out punctuation</span></span><br><span class="line">    <span class="comment"># (Hint: Use regex to split on non-alphanumeric characters)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Aggregate word counts using a dictionary</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">word</span> <span class="keyword">in</span> word_l:</span><br><span class="line">        <span class="built_in">word</span> = re.match(<span class="string">"([a-zA-Z]+).*"</span>, <span class="built_in">word</span>)</span><br><span class="line">        <span class="built_in">word</span> = <span class="built_in">word</span>.group(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">word</span> <span class="keyword">not</span> <span class="keyword">in</span> counts:</span><br><span class="line">            counts[<span class="built_in">word</span>] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            counts[<span class="built_in">word</span>] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="literal">return</span> counts</span><br></pre></td></tr></table></figure><p>看起来不错，但是如果有一套统一的工具来做这些是不是会更好，这时候就出现了nltk(Natural Language ToolKit)  </p><blockquote><p>pip install nltk  </p></blockquote><p><strong>1. from nltk.tokenize import word_tokenize</strong></p><blockquote><p>将一个句子中的单词一个个提取出来，相比于自己split好在他更智能。e.g. 可以提取出Dr.</p></blockquote><p><strong>2. from nltk.tokenize import sent_tokenize</strong> </p><blockquote><p>可以将一个个句子提取出来  </p></blockquote><p><strong>3. from nltk.corpus import stopwords</strong>  </p><blockquote><p>有一些句子中的单词是没有意义的，stopwords可以帮助我们快速提取出来  </p></blockquote><p><strong>4. Sentence Parsing</strong></p><blockquote><p>根据语法规则把一句话变成一棵树，没搞懂啥意思</p></blockquote><p><img src="/images/NLP/text_processing/parse_tree.png" alt=""></p><p><strong>5. Stemming &amp; Lemmatization</strong></p><blockquote><p>同一个单词可能有不同时态、单复数等，取其枝干可以大大减小运算量和内存占用  </p></blockquote><p>另外我们需要了解的还有beautiful的相应用法，imooc的爬虫课程讲解了基础。</p><p>正则表达式也是很重要的知识，在这里就不一一阐述</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;basic-rules-of-text-procession-and-how-to-use-nltk&quot;&gt;&lt;a href=&quot;#basic-rules-of-text-procession-and-how-to-use-nltk&quot; class=&quot;headerlink&quot;
      
    
    </summary>
    
      <category term="NLP" scheme="http://yoursite.com/categories/NLP/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Pyspider (Four) how to use a simple Spider</title>
    <link href="http://yoursite.com/2018/11/12/pyspider4/"/>
    <id>http://yoursite.com/2018/11/12/pyspider4/</id>
    <published>2018-11-11T17:15:50.000Z</published>
    <updated>2018-11-11T17:15:50.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、创建环境"><a href="#一、创建环境" class="headerlink" title="一、创建环境"></a>一、创建环境</h3><p>使用pycharm安装spyder<br>打开想要创建的目录</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">scrapy </span>startproject ArticleSpyder <span class="comment">#创建工程</span></span><br><span class="line"><span class="keyword">scrapy </span>genspider <span class="keyword">jobbole </span><span class="keyword">blog.jobbole.com </span><span class="comment">#创建模板</span></span><br></pre></td></tr></table></figure><p>这时候我们就会发现用pycharm打开这个文件~<br>在setting.py中将obey robots.txt 设置为false防止去多url被过滤<br>在ArticleSpider下创立main.py  </p><blockquote></blockquote><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from scrapy<span class="selector-class">.cmdline</span> import execute</span><br><span class="line">import sys</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">path = os<span class="selector-class">.path</span><span class="selector-class">.dirname</span>(os<span class="selector-class">.path</span><span class="selector-class">.abspath</span>(__file__))</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(path)</span></span></span><br><span class="line">sys<span class="selector-class">.path</span><span class="selector-class">.append</span>(path)</span><br><span class="line"><span class="function"><span class="title">execute</span><span class="params">([<span class="string">"scrapy"</span>,<span class="string">"crawl"</span>, <span class="string">"jobblole"</span>])</span></span></span><br></pre></td></tr></table></figure><h3 id="二、在cmd中进行实验"><a href="#二、在cmd中进行实验" class="headerlink" title="二、在cmd中进行实验"></a>二、在cmd中进行实验</h3><p>好处是不用反复run对网页内容进行拉取  </p><blockquote></blockquote><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy shell http:<span class="regexp">//</span>blog.jobbole.com<span class="regexp">/114461/</span></span><br></pre></td></tr></table></figure><h3 id="三、使用xpath"><a href="#三、使用xpath" class="headerlink" title="三、使用xpath"></a>三、使用xpath</h3><p>这里可以一次拉取我们需要的信息，接着我们选取拉回的response进行操作<br>这里我们选取一篇可怜的博客作为实验对象，分别拉取他的title、create_date、praise_nums</p><blockquote><p>实验对象 <a href="http://blog.jobbole.com/114461/" target="_blank" rel="noopener">http://blog.jobbole.com/114461/</a>   </p></blockquote><p>这里我们分别采用绝对路径、选取全部class名字、选取部分class名字进行操作。<strong>extract()帮助我们提取出里面的有效信息</strong>，操作时候注意我们需要的文本是在 <strong>当前class下还是h10等小标签下</strong> </p><p>注意：在python project中在def parse(self, response)下进行操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#这里是用绝对路径并extract出里面的文本信息  </span></span><br><span class="line">title = response.xpath(<span class="string">"/html/head/title/text()"</span>) </span><br><span class="line">title.extract() </span><br><span class="line"></span><br><span class="line"><span class="comment"># //p: 所有的p标签 、[@class=xxx]:class 名字为xxx</span></span><br><span class="line"><span class="comment"># strip():去掉空格和换行</span></span><br><span class="line">create_date = response.xpath(<span class="string">"//p[@class='entry-meta-hide-on-mobile']/text()"</span>).extract()[<span class="number">0</span>].strip()</span><br><span class="line">create_date = create_date.replace(<span class="string">"`"</span>,<span class="string">""</span>).strip()</span><br><span class="line"></span><br><span class="line"><span class="comment">#用了contains函数：注意要加[]以及'，'分割两个参数</span></span><br><span class="line">praise_nums = response.xpath(<span class="string">"//span[contains(@class,'vote-post-up')]/h10/text()"</span>).extract()</span><br><span class="line"></span><br><span class="line"> favor = response.xpath(<span class="string">"//span[contains(@class,'bookmark-btn')]/text()"</span>).extract()</span><br></pre></td></tr></table></figure><p>全部操作完成后可以用正则表达式进行清洗  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">favor = response.xpath(<span class="string">"//span[contains(@class,'bookmark-btn')]/text()"</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        match_f = re.match(<span class="string">".*(\d+).*"</span>,favor)</span><br><span class="line">        print(<span class="string">"sdfg"</span>)</span><br><span class="line">        <span class="keyword">if</span> match_f:</span><br><span class="line">            print(match_f.group(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># given a tag_list 我们要去除掉不是tag的评论</span></span><br><span class="line">[element <span class="keyword">for</span> element <span class="keyword">in</span> tag_list <span class="keyword">if</span> <span class="keyword">not</span> element.endswith(<span class="string">"评论"</span>)]  </span><br><span class="line">```</span><br></pre></td></tr></table></figure><hr><h3 id="四、使用css"><a href="#四、使用css" class="headerlink" title="四、使用css"></a>四、使用css</h3><p>*: 选择所有  </p><p>#container: 选择id为container的节点<br>.container: 选取所有class包含container的节点<br>li a: 选取所有li下的所有a节点<br>ul + p: 选择ul后面的第一个p元素<br>div#container &gt; ul: 选取id为container的div的第一个ul元素<br>ul ~ p : 选取和ul相邻的所有p元素<br>a[href=”<a href="http://jobbole.com&quot;]" target="_blank" rel="noopener">http://jobbole.com&quot;]</a>: 选出所有该gref的所有元素<br>a[href*=”jobblole”]: 选出所有该gref的所有元素<br>a[href^=”http”]: 选出所有该gref以http的所有元素<br>a[href$=”.jpg”]: 选出所有该gref以jpg结尾的所有元素</p><p>#id: id 写法</p><blockquote><p>爬取例子 <a href="http://blog.jobbole.com/107390/" target="_blank" rel="noopener">http://blog.jobbole.com/107390/</a></p></blockquote><ol><li>选取p元素下的entry-meta-hide-on-mobile类的text</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">date = response.css(<span class="string">"p.entry-meta-hide-on-mobile::text"</span>).extract()[<span class="number">0</span>].strip()</span><br></pre></td></tr></table></figure><ol start="2"><li>取span下vote-post-up中和h10的文本（点赞数），第一个用’.’,后面的用空格，text用冒号。如果说后面的class唯一可以省去span  </li></ol><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">vote</span> = response.css(<span class="string">"span.vote-post-up h10::text"</span>).extract()[<span class="number">0</span>].strip()</span><br></pre></td></tr></table></figure><ol start="3"><li>取herf=”#article-comment”下的span中的文字  </li></ol><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">comment</span> = response.css(<span class="string">"a[href='#article-comment'] span::text"</span>).extract()[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><ol start="4"><li><p>提取内容  </p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">content</span> = response.css(<span class="string">".entry"</span>)</span><br></pre></td></tr></table></figure></li><li><p>提取tag并用’,’连接  </p></li></ol><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">tags</span> = response.css(<span class="string">"div.entry-meta p a::text"</span>).extract()</span><br><span class="line"><span class="attr">t</span> = <span class="string">","</span>.join(tags)</span><br></pre></td></tr></table></figure><ol start="6"><li>提取一个页面中的所有url</li></ol><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">post_urls</span> = response.css(<span class="string">"#archive .floated-thumb .post-thumb a::attr(href)"</span>).extract()</span><br></pre></td></tr></table></figure><ol start="7"><li>选取下一页  <blockquote><p>注意attr的提取功能  </p></blockquote></li></ol><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">next_p</span> = response.css(<span class="string">".next.page-numbers::attr(href)"</span>).extract_first(<span class="string">""</span>)</span><br></pre></td></tr></table></figure><h3 id="五、实战"><a href="#五、实战" class="headerlink" title="五、实战"></a>五、实战</h3><h5 id="这里记录下来debug了两个小时的坑"><a href="#这里记录下来debug了两个小时的坑" class="headerlink" title="这里记录下来debug了两个小时的坑"></a>这里记录下来debug了两个小时的坑</h5><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name</span> = <span class="string">"jobblole"</span></span><br><span class="line">   <span class="attr">allowed_domains</span> = [<span class="string">"web.jobbole.com"</span>]</span><br><span class="line">   <span class="attr">start_urls</span> = ['http://web.jobbole.com/all-posts/']</span><br></pre></td></tr></table></figure><h5 id="一直没注意domain，我们应该确保搜索的范围在domain中，不然会出现错误"><a href="#一直没注意domain，我们应该确保搜索的范围在domain中，不然会出现错误" class="headerlink" title="一直没注意domain，我们应该确保搜索的范围在domain中，不然会出现错误"></a>一直没注意domain，我们应该确保搜索的范围在domain中，不然会出现错误</h5><p>接着打开一中创建的模板  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 递归运行函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        1. 获取文章列表页中的文章url并交给scrapy下载后并进行解析</span></span><br><span class="line"><span class="string">        2. 获取下一页的url并交给scrapy进行下载， 下载完成后交给parse</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 解析列表页中的所有文章url并交给scrapy下载后并进行解析</span></span><br><span class="line"></span><br><span class="line">        post_nodes = response.css(<span class="string">"#archive .floated-thumb .post-thumb a"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> post_node <span class="keyword">in</span> post_nodes:</span><br><span class="line">            post_url = post_node.css(<span class="string">"::attr(href)"</span>).extract_first(<span class="string">""</span>)</span><br><span class="line">            print(post_url)</span><br><span class="line">            <span class="keyword">yield</span> Request(url=parse.urljoin(response.url, post_url), callback=self.parse_detail)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取下一页并交给scrapy进行下载</span></span><br><span class="line">        next_url = response.css(<span class="string">".next.page-numbers::attr(href)"</span>).extract_first(<span class="string">""</span>)</span><br><span class="line">        <span class="keyword">if</span> next_url:</span><br><span class="line">            <span class="keyword">yield</span> Request(url=parse.urljoin(response.url, post_url), callback=self.parse)</span><br></pre></td></tr></table></figure><p>这里有三个需要注意的地方  </p><ol><li>yield Request就是运行，无需其他操作</li><li>url要使用parse.urljoin(response.url, post_url), 比如github，能抓取到的只有仓库名，但是前面需要加上github的大域名  </li><li>callback不需要加括号，只需要函数名字  </li></ol><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def parse_detail(self, response):</span><br><span class="line"></span><br><span class="line">       <span class="comment"># 通过css选择器提取字段</span></span><br><span class="line"></span><br><span class="line">       <span class="attr">title</span> = response.css(<span class="string">".entry-header h1::text"</span>).extract()[<span class="number">0</span>]</span><br><span class="line">       <span class="attr">create_date</span> = response.css(<span class="string">"p.entry-meta-hide-on-mobile::text"</span>).extract()[<span class="number">0</span>].strip().replace(<span class="string">"·"</span>, <span class="string">""</span>).strip()</span><br><span class="line">       <span class="attr">praise_nums</span> = response.css(<span class="string">".vote-post-up h10::text"</span>).extract()[<span class="number">0</span>]</span><br><span class="line">       <span class="attr">fav_nums</span> = response.css(<span class="string">".bookmark-btn::text"</span>).extract()[<span class="number">0</span>]</span><br><span class="line">       <span class="attr">match_re</span> = re.match(<span class="string">".*?(\d+).*"</span>, fav_nums)</span><br><span class="line">       <span class="keyword">if</span> match_re:</span><br><span class="line">           <span class="attr">fav_nums</span> = int(match_re.group(<span class="number">1</span>))</span><br><span class="line">       <span class="keyword">else</span>:</span><br><span class="line">           <span class="attr">fav_nums</span> = <span class="number">0</span></span><br></pre></td></tr></table></figure><p>未完待续….等项目全部做完附赠项目地址  </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;一、创建环境&quot;&gt;&lt;a href=&quot;#一、创建环境&quot; class=&quot;headerlink&quot; title=&quot;一、创建环境&quot;&gt;&lt;/a&gt;一、创建环境&lt;/h3&gt;&lt;p&gt;使用pycharm安装spyder&lt;br&gt;打开想要创建的目录&lt;/p&gt;
&lt;figure class=&quot;high
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Pyspider (Third) Basic knowledge</title>
    <link href="http://yoursite.com/2018/11/11/pyspider3/"/>
    <id>http://yoursite.com/2018/11/11/pyspider3/</id>
    <published>2018-11-11T04:08:50.000Z</published>
    <updated>2018-11-11T04:08:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>URL网络实际是一个树形结构，因此分为广度优先和深度优先搜索。<br>真实网站是存在许多环路的，因此一个重要的方法就是去重。本文介绍去重和字符串编码问题  </p><h4 id="一、Depth-First-amp-Width-First"><a href="#一、Depth-First-amp-Width-First" class="headerlink" title="一、Depth-First &amp; Width-First"></a>一、Depth-First &amp; Width-First</h4><p>不做赘述。  </p><h4 id="二、爬虫去重序列"><a href="#二、爬虫去重序列" class="headerlink" title="二、爬虫去重序列"></a>二、爬虫去重序列</h4><ol><li>url经过md5等方法哈希后保存到set中  </li><li>用bitmap方法，将url hash到某一位（缺点：冲突不命中会比较高）  </li><li>用bloomfilter对bitmap进行优化 </li></ol><h3 id="三、Unicode-amp-utf8"><a href="#三、Unicode-amp-utf8" class="headerlink" title="三、Unicode &amp; utf8"></a>三、Unicode &amp; utf8</h3><p>Unicode将所有语言统一到一套编码，都用2byte表示。但是如果说一篇文章全是英文，储存空间和传输量会比Ascii多一倍<br>utf-8将英文又变回一个字节<br>将UTF-8文件读取成Unicode（方便统一操作），处理完后保存成UFT-8文件（节省空间）<br>python3现在用unicode统一进行表示  </p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">"我爱python"</span></span><br><span class="line">s.encode(<span class="string">"utf8"</span>) <span class="comment"># 此时s必须是unicode，不然会报错</span></span><br></pre></td></tr></table></figure><p>前面介绍了基本背景(First)，正则表达式(Second)，和去重及编码，下章节开始讲解Scrapy框架</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;URL网络实际是一个树形结构，因此分为广度优先和深度优先搜索。&lt;br&gt;真实网站是存在许多环路的，因此一个重要的方法就是去重。本文介绍去重和字符串编码问题  &lt;/p&gt;
&lt;h4 id=&quot;一、Depth-First-amp-Width-First&quot;&gt;&lt;a href=&quot;#一、Dep
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Pyspider (Second) regular expression</title>
    <link href="http://yoursite.com/2018/11/11/pyspider2/"/>
    <id>http://yoursite.com/2018/11/11/pyspider2/</id>
    <published>2018-11-11T04:06:18.000Z</published>
    <updated>2018-11-11T04:06:18.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、基本规则"><a href="#一、基本规则" class="headerlink" title="一、基本规则"></a>一、基本规则</h4><p> ^b: 强制以b开头<br> .: 可以匹配任意字符<br> *: 可以代表无限多个前一字符<br> 3$: 必须以3强制结尾<br> (): 返回括号内匹配的内容<br> ？: 非贪婪匹配，遇到该字符的第一个就停下 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">line = <span class="string">"waaaaangww123"</span></span><br><span class="line"></span><br><span class="line">regex_str = <span class="string">".*?(w.*w).*"</span> <span class="comment"># waaaaangww</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">regex_str = ".*?(w.*?w).*" # waaaaangw</span></span><br><span class="line"><span class="string">regex_str = ".*(w.*w).*" # ww</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">match_str = re.match(regex_str, line)</span><br><span class="line"><span class="keyword">if</span> match_str:</span><br><span class="line">    print(match_str.group(<span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>+: 前面的字符至少出现一次(与<em>都是次数限定符)<br>{2}: 前面的出现2次  {2,}:前面的出现至少两次  {2，5}: 前面的出现至少两次至多5次<br>|：或, 模式1或者模式2 (优先提取竖线前的模式)<br>[abcd]:前面的字符是abcd中任意一个均可<br>[0-9]:区间任意一个字符<br>[^1]: 不为1<br>[.</em>]: 去除特殊字符的特殊含义</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line"><span class="section"># 举个例子提取电话号码</span></span><br><span class="line">phone_num = "17673168577"</span><br><span class="line">regex_str = "(1[<span class="string">5678</span>][<span class="symbol">0-9</span>]&#123;9&#125;)" # "(1[<span class="string">5678</span>][<span class="symbol">^1</span>]&#123;9&#125;)"</span><br><span class="line"><span class="section"># 17673168577</span></span><br><span class="line"><span class="section"># 以1开头，后面跟5or6or7or8, 再跟9个任意数字</span></span><br><span class="line">match<span class="emphasis">_str = re.match(regex_</span>str, phone_num)</span><br><span class="line">if match_str:</span><br><span class="line"><span class="code">    print(match_str.group(1))</span></span><br></pre></td></tr></table></figure><p>\s: 空格(小写)<br>\S: 单一字符且只要不为空格都可以(大写)<br>\w: 与[A-Za-z0-9_]相同<br>\W: 与上面的相反<br>[\u4E00–u9FA5]: 任意汉字</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;一、基本规则&quot;&gt;&lt;a href=&quot;#一、基本规则&quot; class=&quot;headerlink&quot; title=&quot;一、基本规则&quot;&gt;&lt;/a&gt;一、基本规则&lt;/h4&gt;&lt;p&gt; ^b: 强制以b开头&lt;br&gt; .: 可以匹配任意字符&lt;br&gt; *: 可以代表无限多个前一字符&lt;br&gt; 3$
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Introduction of Pyspider(First)</title>
    <link href="http://yoursite.com/2018/11/09/pyspider1/"/>
    <id>http://yoursite.com/2018/11/09/pyspider1/</id>
    <published>2018-11-09T06:12:50.000Z</published>
    <updated>2018-11-09T06:12:50.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、mysql-fo-navicat连接权限问题"><a href="#一、mysql-fo-navicat连接权限问题" class="headerlink" title="一、mysql fo navicat连接权限问题"></a>一、mysql fo navicat连接权限问题</h4><ol><li>在windows上下载navicat</li><li>在linux上配置mysql并在win下用navicat进行连接  </li></ol><blockquote><p>mysql配置文件修改  </p></blockquote><p>外部访问：/etc/mysql/mysql.conf.d/mysqld.cnf<br>编辑文件：bind-address=0.0.0.0</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">to</span> <span class="string">'root'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'root'</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> <span class="keyword">OPTION</span>;</span><br><span class="line"><span class="keyword">flush</span> <span class="keyword">privileges</span>;     <span class="comment">#刷新权限</span></span><br></pre></td></tr></table></figure><h4 id="二、用什么技术"><a href="#二、用什么技术" class="headerlink" title="二、用什么技术"></a>二、用什么技术</h4><p>requests和beautifulsoup都是库，而scrapy是框架。因此本教程运用scrapy  </p><blockquote><p>Scrapy内置的css和xpath selector方便  </p></blockquote><h4 id="三、网页分类"><a href="#三、网页分类" class="headerlink" title="三、网页分类"></a>三、网页分类</h4><ol><li>静态网页（例如hexo）  </li><li>动态网页（例如淘宝）  </li><li>webservice  </li></ol><h4 id="四、能做什么"><a href="#四、能做什么" class="headerlink" title="四、能做什么"></a>四、能做什么</h4><ol><li>搜索引擎—Baidu  </li><li>推荐引擎—今日头条  </li><li>机器学习的数据样本  </li><li>数据分析  </li><li>….</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;一、mysql-fo-navicat连接权限问题&quot;&gt;&lt;a href=&quot;#一、mysql-fo-navicat连接权限问题&quot; class=&quot;headerlink&quot; title=&quot;一、mysql fo navicat连接权限问题&quot;&gt;&lt;/a&gt;一、mysql fo nav
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Super-Resolution Research</title>
    <link href="http://yoursite.com/2018/11/04/super-resolution/"/>
    <id>http://yoursite.com/2018/11/04/super-resolution/</id>
    <published>2018-11-04T10:34:26.000Z</published>
    <updated>2018-11-04T10:34:26.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Adapt-Super-resolution-into-real-production"><a href="#Adapt-Super-resolution-into-real-production" class="headerlink" title="Adapt Super-resolution into real production"></a>Adapt Super-resolution into real production</h3><h4 id="08-2018-11-2018"><a href="#08-2018-11-2018" class="headerlink" title="08/2018-11/2018"></a>08/2018-11/2018</h4><ul><li><strong>Tutor:</strong> <a href="http://www.cs.cornell.edu/selman/" target="_blank" rel="noopener">Bart Selman from Cornell University</a> </li><li><strong>Purpose:</strong> Used symmetric padding to improve perceptual quality of image after super-resolution   </li><li><strong>Duties:</strong> Edited code to realize VDSR using tensorflow and symmetric padding to process the images with three channels; Used EC2 of AWS to do experiments using classic Datasets (ImageNet, Set5, Set14) and evaluated the outcomes via PSNR and SSIM; Wrote the Introduction and Experiment&amp;Analysis of the final paper</li><li><a href="https://github.com/JasonWang0808/paper_reading/blob/master/Super-resolution-final.pdf" target="_blank" rel="noopener">Final paper</a> and <a href="https://github.com/JasonWang0808/paper_reading/blob/master/RL.jpg" target="_blank" rel="noopener">Recommendation Letter</a> <strong>(&lt;-CLICK)</strong></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Adapt-Super-resolution-into-real-production&quot;&gt;&lt;a href=&quot;#Adapt-Super-resolution-into-real-production&quot; class=&quot;headerlink&quot; title=&quot;Adapt 
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Reinforment Learning(Five) Actor-Critic</title>
    <link href="http://yoursite.com/2018/11/04/Reinforment_Learning5/"/>
    <id>http://yoursite.com/2018/11/04/Reinforment_Learning5/</id>
    <published>2018-11-04T08:10:58.000Z</published>
    <updated>2018-11-04T08:10:58.000Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>    <blockquote><p>这个方法比较综合，结合了Deep Q-learning Network(DQN)以及Policy-Based Method，通过搭建两个神经网络实现目标<br>buffer、fixed-Q</p></blockquote><h5 id="一、首先看一下action的职责，基于policy-based。当输入不同state的时候，神经网络可以帮我们自动计算出当前采取各个动作的概率。而训练过程我们只需要-action-porb-和-TD-error-即可。-TD-error-是Critic传过来的，actor部分要做的就是通过神经网络得到当前动作，拿到Critic给的-TD-error-反向传播"><a href="#一、首先看一下action的职责，基于policy-based。当输入不同state的时候，神经网络可以帮我们自动计算出当前采取各个动作的概率。而训练过程我们只需要-action-porb-和-TD-error-即可。-TD-error-是Critic传过来的，actor部分要做的就是通过神经网络得到当前动作，拿到Critic给的-TD-error-反向传播" class="headerlink" title="一、首先看一下action的职责，基于policy-based。当输入不同state的时候，神经网络可以帮我们自动计算出当前采取各个动作的概率。而训练过程我们只需要\(action \_porb\)和\(TD\_error\)即可。\(TD\_error\)是Critic传过来的，actor部分要做的就是通过神经网络得到当前动作，拿到Critic给的 \(TD\_error\)反向传播"></a>一、首先看一下action的职责，基于policy-based。当输入不同state的时候，神经网络可以帮我们自动计算出当前采取各个动作的概率。而训练过程我们只需要\(action \_porb\)和\(TD\_error\)即可。\(TD\_error\)是Critic传过来的，actor部分要做的就是通过神经网络得到当前动作，拿到Critic给的 \(TD\_error\)反向传播</h5><blockquote><ol><li>构建网络  </li><li>def learn： 通过state和当前的action(构建one-hot来选择state得到的结果)，以及critic传入的TD-error得到self.exp_v传给优化器优化  </li><li>choose_action : 从概率数组里按照动作的概率选择动作  </li></ol></blockquote><p>注意： 公式\(TD\_error = (r+gamma*V\_next) - V\_eval\)用来说明当前是否比平均状况好，\(TD\_error\)为正且越大说明当前动作选择的越好</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Actor</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, sess, n_features, n_actions, lr=<span class="number">0.001</span>)</span>:</span></span><br><span class="line">        self.sess = sess</span><br><span class="line"></span><br><span class="line">        self.s = tf.placeholder(tf.float32, [<span class="number">1</span>, n_features], <span class="string">"state"</span>)</span><br><span class="line">        self.a = tf.placeholder(tf.int32, <span class="keyword">None</span>, <span class="string">"act"</span>)</span><br><span class="line">        self.td_error = tf.placeholder(tf.float32, <span class="keyword">None</span>, <span class="string">"td_error"</span>)  <span class="comment"># TD_error</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'Actor'</span>):</span><br><span class="line">            l1 = tf.layers.dense(</span><br><span class="line">                inputs=self.s,</span><br><span class="line">                units=<span class="number">20</span>,    <span class="comment"># number of hidden units</span></span><br><span class="line">                activation=tf.nn.relu,</span><br><span class="line">                kernel_initializer=tf.random_normal_initializer(<span class="number">0.</span>, <span class="number">.1</span>),    <span class="comment"># weights</span></span><br><span class="line">                bias_initializer=tf.constant_initializer(<span class="number">0.1</span>),  <span class="comment"># biases</span></span><br><span class="line">                name=<span class="string">'l1'</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            self.acts_prob = tf.layers.dense(</span><br><span class="line">                inputs=l1,</span><br><span class="line">                units=n_actions,    <span class="comment"># output units</span></span><br><span class="line">                activation=tf.nn.softmax,   <span class="comment"># get action probabilities</span></span><br><span class="line">                kernel_initializer=tf.random_normal_initializer(<span class="number">0.</span>, <span class="number">.1</span>),  <span class="comment"># weights</span></span><br><span class="line">                bias_initializer=tf.constant_initializer(<span class="number">0.1</span>),  <span class="comment"># biases</span></span><br><span class="line">                name=<span class="string">'acts_prob'</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'exp_v'</span>):</span><br><span class="line">            log_prob = tf.log(self.acts_prob[<span class="number">0</span>, self.a])</span><br><span class="line">            self.exp_v = tf.reduce_mean(log_prob * self.td_error)  <span class="comment"># advantage (TD_error) guided loss</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'train'</span>):</span><br><span class="line">            self.train_op = tf.train.AdamOptimizer(lr).minimize(-self.exp_v)  <span class="comment"># minimize(-exp_v) = maximize(exp_v)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">learn</span><span class="params">(self, s, a, td)</span>:</span></span><br><span class="line">        s = s[np.newaxis, :]</span><br><span class="line">        feed_dict = &#123;self.s: s, self.a: a, self.td_error: td&#125;</span><br><span class="line">        _, exp_v = self.sess.run([self.train_op, self.exp_v], feed_dict)</span><br><span class="line">        <span class="keyword">return</span> exp_v</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">choose_action</span><span class="params">(self, s)</span>:</span></span><br><span class="line">        s = s[np.newaxis, :]</span><br><span class="line">        probs = self.sess.run(self.acts_prob, &#123;self.s: s&#125;)   <span class="comment"># get probabilities for all actions</span></span><br><span class="line">        <span class="keyword">return</span> np.random.choice(np.arange(probs.shape[<span class="number">1</span>]), p=probs.ravel())   <span class="comment"># return a int</span></span><br></pre></td></tr></table></figure><h5 id="二、看一下Critic的职责。拿到了-state，next-state-reward-计算得到TD-error-进行优化器优化，并传给actor"><a href="#二、看一下Critic的职责。拿到了-state，next-state-reward-计算得到TD-error-进行优化器优化，并传给actor" class="headerlink" title="二、看一下Critic的职责。拿到了\(state，next\_state,reward\), 计算得到TD_error, 进行优化器优化，并传给actor"></a>二、看一下Critic的职责。拿到了\(state，next\_state,reward\), 计算得到TD_error, 进行优化器优化，并传给actor</h5><blockquote><ol><li>构建网络，state对应唯一输出，意思就是当前state应该对应的\(value\_eval\)（平均值，期望），更加简单  </li><li>\(loss={TD\_error}^{2}\), 并不断减小这个loss。</li><li>def learn：传入当前\(s, reward, s\_next\)运行tf得到error   </li></ol></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Critic</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, sess, n_features, lr=<span class="number">0.01</span>)</span>:</span></span><br><span class="line">        self.sess = sess</span><br><span class="line"></span><br><span class="line">        self.s = tf.placeholder(tf.float32, [<span class="number">1</span>, n_features], <span class="string">"state"</span>)</span><br><span class="line">        self.v_ = tf.placeholder(tf.float32, [<span class="number">1</span>, <span class="number">1</span>], <span class="string">"v_next"</span>)</span><br><span class="line">        self.r = tf.placeholder(tf.float32, <span class="keyword">None</span>, <span class="string">'r'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'Critic'</span>):</span><br><span class="line">            l1 = tf.layers.dense(</span><br><span class="line">                inputs=self.s,</span><br><span class="line">                units=<span class="number">20</span>,  <span class="comment"># number of hidden units</span></span><br><span class="line">                activation=tf.nn.relu,  <span class="comment"># None</span></span><br><span class="line">                <span class="comment"># have to be linear to make sure the convergence of actor.</span></span><br><span class="line">                <span class="comment"># But linear approximator seems hardly learns the correct Q.</span></span><br><span class="line">                kernel_initializer=tf.random_normal_initializer(<span class="number">0.</span>, <span class="number">.1</span>),  <span class="comment"># weights</span></span><br><span class="line">                bias_initializer=tf.constant_initializer(<span class="number">0.1</span>),  <span class="comment"># biases</span></span><br><span class="line">                name=<span class="string">'l1'</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            self.v = tf.layers.dense(</span><br><span class="line">                inputs=l1,</span><br><span class="line">                units=<span class="number">1</span>,  <span class="comment"># output units</span></span><br><span class="line">                activation=<span class="keyword">None</span>,</span><br><span class="line">                kernel_initializer=tf.random_normal_initializer(<span class="number">0.</span>, <span class="number">.1</span>),  <span class="comment"># weights</span></span><br><span class="line">                bias_initializer=tf.constant_initializer(<span class="number">0.1</span>),  <span class="comment"># biases</span></span><br><span class="line">                name=<span class="string">'V'</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'squared_TD_error'</span>):</span><br><span class="line">            self.td_error = self.r + GAMMA * self.v_ - self.v</span><br><span class="line">            self.loss = tf.square(self.td_error)    <span class="comment"># TD_error = (r+gamma*V_next) - V_eval</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'train'</span>):</span><br><span class="line">            self.train_op = tf.train.AdamOptimizer(lr).minimize(self.loss)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">learn</span><span class="params">(self, s, r, s_)</span>:</span></span><br><span class="line">        s, s_ = s[np.newaxis, :], s_[np.newaxis, :]</span><br><span class="line"></span><br><span class="line">        v_ = self.sess.run(self.v, &#123;self.s: s_&#125;)</span><br><span class="line">        td_error, _ = self.sess.run([self.td_error, self.train_op],</span><br><span class="line">                                          &#123;self.s: s, self.v_: v_, self.r: r&#125;)</span><br><span class="line">        <span class="keyword">return</span> td_error</span><br></pre></td></tr></table></figure><h5 id="三、两者实现交互"><a href="#三、两者实现交互" class="headerlink" title="三、两者实现交互"></a>三、两者实现交互</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = actor.choose_action(s)</span><br><span class="line"></span><br><span class="line">s_, r, done, info = env.step(a)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   td_error = critic.learn(s, r, s_)  <span class="comment"># gradient = grad[r + gamma * V(s_) - V(s)]</span></span><br><span class="line">   actor.learn(s, a, td_error)     <span class="comment"># true_gradient = grad[logPi(s,a) * td_error]</span></span><br></pre></td></tr></table></figure><p>Refer : <a href="https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/6-1-actor-critic/" target="_blank" rel="noopener">https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/6-1-actor-critic/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&quot;&gt;&lt;/script&gt;    

&lt;blockquote&gt;
&lt;p&gt;这个
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Reinforment Learning(Four) Policy Based Method</title>
    <link href="http://yoursite.com/2018/11/04/Reinforcement_Learning4/"/>
    <id>http://yoursite.com/2018/11/04/Reinforcement_Learning4/</id>
    <published>2018-11-04T07:59:40.000Z</published>
    <updated>2018-11-04T07:59:40.000Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>  <h3 id="Policy-Based-method"><a href="#Policy-Based-method" class="headerlink" title="Policy Based method"></a>Policy Based method</h3><h5 id="莫烦python-Policy-Based-Method"><a href="#莫烦python-Policy-Based-Method" class="headerlink" title="莫烦python Policy Based Method"></a><a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/7_Policy_gradient_softmax" target="_blank" rel="noopener">莫烦python Policy Based Method</a></h5><p>意思是给特定的状态特定的动作 ,适用于一个连续的运动 , <strong>相比于Value-Based方法，我们只在乎当前状态经过神经网络运算出来的action。通过Reward进行训练神经网络的参数\(w\)，而不考虑其数值的算法进行收敛</strong>。<br>随机性搜索策略 (这里以蒙特卡洛为例子，即有限个动作)<br>$$<br>\theta = \theta + \alpha \bigtriangledown_{\theta}log \pi_{\theta}(s_{\tau},a_{t}, \theta)v_{\tau}，可以看到v_{\tau}越大，更新的幅度越大<br>$$</p><blockquote></blockquote><p>$$<br>R_{\tau} = R_{t+1} + \gamma R_{t+2} + \gamma^{2} R_{t+3} + ….<br>$$</p><blockquote></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">neg_log_prob = tf.reduce_sum(-tf.log(self.all_act_prob)*tf.one_hot(self.tf_acts, self.n_actions), axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment">##这里log有符号，因此minimize其实是增大</span></span><br><span class="line">loss = tf.reduce_mean(neg_log_prob * self.tf_vt) </span><br><span class="line"><span class="comment"># 对于不同action，他们的tf.vt不同，train的过程都是增加，但是vt越大增加的概率越大，训练到最后会选择那些vt大的动作</span></span><br></pre></td></tr></table></figure><blockquote><p>\(v_{t}\)是指奖惩的大小，如果我们发现奖惩很好，那么调整神经网络使得这个动作以后多被选中一些。 如果觉得不好，则下一次选中的机会会变小  </p></blockquote><p>但是对于没有终点的任务，比如我们训练一个小孩子上学、吃饭、睡觉、再上学….显然这个是没有终点的，我们找不到一个合适的时间点来更新我们的\(w\)，因此我们采用下面的公式</p><p>$$<br>\Delta \theta = \alpha \ \bigtriangledown_{\theta}(log (S_{t}, A_{t}, \theta) Q(S_{t},A_{t}), 我们采用Q(S_{t},A_{t}来替换R_{\tau}<br>$$</p><p>$$<br>Q(S_{t},A_{t} )= Q(S_{t}, A_{t}) + \beta(R_{t+1} + \gamma Q(S_{t+1}, A_{t+1} - Q(S_{t},A_{t}))<br>$$</p><h4 id="actor-critic-method"><a href="#actor-critic-method" class="headerlink" title="actor-critic method"></a>actor-critic method</h4><p>用两套神经网络，一套用于预测动作，另一套用于评估动作的好坏。 \(\theta \)是Policy Based 来选择动作，\(w\)是前面DQN来生成反馈\(\hat{q}(S, A)\)。因此这个方法也叫做Actor-Critic</p><blockquote><p>actor来源于policy-based， critic来源于value-based。actor来指手画脚，critic告诉他哪一个动作是对，哪一个是错  </p></blockquote><p>$$<br>Actor : \Delta \theta = \alpha \bigtriangledown_{\theta}(log\pi(S_{t},A_{t},\theta))\hat{q}(S_{t}, A_{t}, w)<br>\pi 是选取动作的指令，q是反馈的动作值<br>$$</p><blockquote></blockquote><p>$$<br>Critic : \Delta w = \beta(R_{t+1} + \gamma \hat{q}(S_{t+1}, A_{t}, w)) - \hat{q}(S_{t}, A_{t}, w)) \bigtriangledown_{w} \hat{q}(S_{t}, A_{t}, w)<br>$$</p><h3 id="Deep-Deterministic-Policy-Gradient-DDPG"><a href="#Deep-Deterministic-Policy-Gradient-DDPG" class="headerlink" title="Deep Deterministic Policy Gradient(DDPG)"></a>Deep Deterministic Policy Gradient(DDPG)</h3><p>Deep: 仿照DQN，有一个buffer，两个更新频率不相同的神经网络参数\(w\) , 由deepMind对actor-critic method  </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&quot;&gt;&lt;/script&gt;  

&lt;h3 id=&quot;Policy-Based
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Reinforcement Learning（First）</title>
    <link href="http://yoursite.com/2018/11/02/Reinforce_Learning1/"/>
    <id>http://yoursite.com/2018/11/02/Reinforce_Learning1/</id>
    <published>2018-11-02T07:24:02.000Z</published>
    <updated>2018-11-02T07:24:02.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="我看到网上的强化学习教程通常比较复杂-看完莫烦python后总结出来如下-我将主要用代码形式进行理论的展现-其中个别地方用的是OPENAI的表示方式"><a href="#我看到网上的强化学习教程通常比较复杂-看完莫烦python后总结出来如下-我将主要用代码形式进行理论的展现-其中个别地方用的是OPENAI的表示方式" class="headerlink" title="我看到网上的强化学习教程通常比较复杂, 看完莫烦python后总结出来如下, 我将主要用代码形式进行理论的展现, 其中个别地方用的是OPENAI的表示方式"></a>我看到网上的强化学习教程通常比较复杂, 看完莫烦python后总结出来如下, 我将主要用代码形式进行理论的展现, 其中个别地方用的是OPENAI的表示方式</h4><hr><h3 id="一、回合更新-Monte-Carlo-update"><a href="#一、回合更新-Monte-Carlo-update" class="headerlink" title="一、回合更新(Monte-Carlo update)"></a>一、回合更新(Monte-Carlo update)</h3><h4 id="玩完所有的步数-等到一个episode结束之后再更新数值"><a href="#玩完所有的步数-等到一个episode结束之后再更新数值" class="headerlink" title="玩完所有的步数, 等到一个episode结束之后再更新数值"></a>玩完所有的步数, 等到一个episode结束之后再更新数值</h4><blockquote><p>Monte-Carlo Learning<br>这个方法比较esay, 就是根据尽可能多的经验, 以及平均期望来更新数值。实验成本大, 并且现在很多需要决策的问题是没有结束标志的。  </p></blockquote><h3 id="二、单步更新-Temporal-Difference-update"><a href="#二、单步更新-Temporal-Difference-update" class="headerlink" title="二、单步更新(Temporal-Difference update)"></a>二、单步更新(Temporal-Difference update)</h3><h4 id="每走一步都会更新当前的数值"><a href="#每走一步都会更新当前的数值" class="headerlink" title="每走一步都会更新当前的数值"></a>每走一步都会更新当前的数值</h4><blockquote><p>Q-Learning(off-policy), Sarsa(on-policy)    </p></blockquote><h4 id="1-什么是off-on-policy"><a href="#1-什么是off-on-policy" class="headerlink" title="1. 什么是off/on-policy?"></a>1. 什么是off/on-policy?</h4><h4 id="off-policy的更新value时候的next-action不一定会真实采取-而on-policy更新时候的next-value就是真实采取的"><a href="#off-policy的更新value时候的next-action不一定会真实采取-而on-policy更新时候的next-value就是真实采取的" class="headerlink" title="off-policy的更新value时候的next_action不一定会真实采取, 而on-policy更新时候的next_value就是真实采取的"></a>off-policy的更新value时候的next_action不一定会真实采取, 而on-policy更新时候的next_value就是真实采取的</h4><blockquote><p>小明正在准备高考, 课间的时候小明在思考接下来学习什么知识。首先, 小明想学习数学, 但是小明的数学已经学习的很熟练了，于是<strong>小明并没有拿出课本, 而是在脑海里把课本背诵了一边, 这样一来, 小明虽然没有拿出课本, 但是依然更新了当前的知识,</strong> 接下来小明可能拿出的是英语/语文/物理课本进行学习。这就是我们的off-policy。<strong>倘若是on-policy, 小明就失去了默背这一流程, 想回忆一下数学下一步骤必须拿出数学课本</strong>   </p></blockquote><h4 id="2-epsilon-greedy策略"><a href="#2-epsilon-greedy策略" class="headerlink" title="2. epsilon_greedy策略"></a>2. epsilon_greedy策略</h4><blockquote><p>取到最大值的概率为 <strong>(1-eps) + (eps)/n</strong><br>取到其他n-1种动作的概率为 <strong>(eps)/n</strong></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">epsilon_greedy</span><span class="params">(Q, state, nA, eps)</span>:</span></span><br><span class="line">    <span class="string">"""Selects epsilon-greedy action for supplied state.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Params</span></span><br><span class="line"><span class="string">    ======</span></span><br><span class="line"><span class="string">        Q (dictionary): action-value function</span></span><br><span class="line"><span class="string">        state (int): current state</span></span><br><span class="line"><span class="string">        nA (int): number actions in the environment</span></span><br><span class="line"><span class="string">        eps (float): epsilon</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> random.random() &gt; eps: </span><br><span class="line">    <span class="comment">#  此时是选取最大数值的action进行返回</span></span><br><span class="line">        <span class="keyword">return</span> np.argmax(Q[state])</span><br><span class="line">    <span class="keyword">else</span>:                     </span><br><span class="line">    <span class="comment"># 这个时候对每个取平均</span></span><br><span class="line">        <span class="keyword">return</span> random.choice(np.arange(env.action_space.n))</span><br></pre></td></tr></table></figure><h4 id="3-Q-learning-with-sarsa-max-off-policy"><a href="#3-Q-learning-with-sarsa-max-off-policy" class="headerlink" title="3. Q-learning with sarsa_max?(off-policy)"></a>3. Q-learning with sarsa_max?(off-policy)</h4><p>sarsa_max: 选取下一状态是value最大的动作更新当前状态  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Q-learning Sarsamax</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_Q_sarsamax</span><span class="params">(alpha, gamma, Q, state, action, reward, next_state=None)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Returns updated Q-value for the most recent experience.</span></span><br><span class="line">    </span><br><span class="line">    current = Q[state][action]  <span class="comment"># estimate in Q-table (for current state, action pair)</span></span><br><span class="line">    Qsa_next = np.max(Q[next_state]) <span class="keyword">if</span> next_state <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span> <span class="keyword">else</span> <span class="number">0</span> </span><br><span class="line">    <span class="comment"># find the max q in next_state, but this action is not the real action</span></span><br><span class="line">    target = reward + (gamma * Qsa_next)               <span class="comment"># construct TD target</span></span><br><span class="line">    new_value = current + (alpha * (target - current)) <span class="comment"># get updated value </span></span><br><span class="line">    <span class="keyword">return</span> new_value</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Q-learning</span></span><br><span class="line"> <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    </span><br><span class="line">    action = epsilon_greedy(Q, state, nA, eps)</span><br><span class="line">    <span class="comment"># epsilon-greedy action selection, get next_action in every interation</span></span><br><span class="line">    next_state, reward, done, info = env.step(action)  <span class="comment"># take action A, observe R, S'</span></span><br><span class="line">    score += reward                                    <span class="comment"># add reward to agent's score</span></span><br><span class="line">    Q[state][action] = update_Q_sarsamax(alpha, gamma, Q, \</span><br><span class="line">                                                 state, action, reward, next_state)        </span><br><span class="line">    state = next_state                                 </span><br><span class="line">    <span class="comment">#只更新状态</span></span><br><span class="line">    <span class="keyword">if</span> done:</span><br><span class="line">        tmp_scores.append(score)                       <span class="comment"># append score</span></span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><h4 id="4-Sarsa-Learning"><a href="#4-Sarsa-Learning" class="headerlink" title="4. Sarsa Learning"></a>4. Sarsa Learning</h4><p>每次迭代都会选出下一状态和下一状态将要采取的动作，根据事实(update_Q_sarsa)来进行更新<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_Q_sarsa</span><span class="params">(alpha, gamma, Q, state, action, reward, next_state=None, next_action=None)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#Returns updated Q-value for the most recent experience.</span></span><br><span class="line">    </span><br><span class="line">    current = Q[state][action]  <span class="comment"># estimate in Q-table (for current state, action pair)</span></span><br><span class="line">    <span class="comment"># get value of state, action pair at next time step</span></span><br><span class="line">    Qsa_next = Q[next_state][next_action] <span class="keyword">if</span> next_state <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span> <span class="keyword">else</span> <span class="number">0</span>    </span><br><span class="line">    target = reward + (gamma * Qsa_next)               <span class="comment"># construct TD target</span></span><br><span class="line">    new_value = current + (alpha * (target - current)) <span class="comment"># get updated value</span></span><br><span class="line">    <span class="keyword">return</span> new_value</span><br></pre></td></tr></table></figure></p><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">while True:</span><br><span class="line">    next_state, reward, done, info = env.step(action) <span class="comment"># take action A, observe R, S'</span></span><br><span class="line">    score += reward                                   <span class="comment"># add reward to agent's score</span></span><br><span class="line">    if not done:</span><br><span class="line">    next_action = epsilon_greedy(Q, next_state, nA, eps) <span class="comment"># epsilon-greedy action</span></span><br><span class="line">    Q[<span class="keyword">state</span>][action] = update_Q_sarsa(alpha, gamma, Q, \</span><br><span class="line">                                                  <span class="keyword">state</span>, action, reward, next_state, next_action)</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">state</span> = next_state     <span class="comment"># S &lt;- S'</span></span><br><span class="line">                action = next_action   <span class="comment"># A &lt;- A'</span></span><br><span class="line">                '''</span><br><span class="line">                这里会根据传入update函数的next_action 和 next_state进行更新</span><br><span class="line">                '''</span><br><span class="line">            if done:</span><br><span class="line">                Q[<span class="keyword">state</span>][action] = update_Q_sarsa(alpha, gamma, Q, \</span><br><span class="line">                                                  <span class="keyword">state</span>, action, reward)</span><br><span class="line">                tmp_scores.append(score)    <span class="comment"># append score</span></span><br><span class="line">                break</span><br></pre></td></tr></table></figure><h4 id="5-expected-Sarsa"><a href="#5-expected-Sarsa" class="headerlink" title="5. expected Sarsa"></a>5. expected Sarsa</h4><p>3,4 种描述的更新方法都是取单一action的value, 在期望Sarsa中将对所有的action产生的value计算一个平均期望进行更新  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_Q_expsarsa</span><span class="params">(alpha, gamma, nA, eps, Q, state, action, reward, next_state=None)</span>:</span></span><br><span class="line">    <span class="string">"""Returns updated Q-value for the most recent experience."""</span></span><br><span class="line">    current = Q[state][action]         <span class="comment"># estimate in Q-table (for current state, action pair)</span></span><br><span class="line">    policy_s = np.ones(nA) * eps / nA  </span><br><span class="line">    <span class="comment"># 建立一个向量储存概率，每一个都是 （eps / nA）, nA表示action数量</span></span><br><span class="line">    policy_s[np.argmax(Q[next_state])] = <span class="number">1</span> - eps + (eps / nA) </span><br><span class="line">    <span class="comment"># 将最大value的action的概率变为1 - eps + (eps / nA) </span></span><br><span class="line">    Qsa_next = np.dot(Q[next_state], policy_s)         <span class="comment"># get value of state at next time step</span></span><br><span class="line">    target = reward + (gamma * Qsa_next)               <span class="comment"># construct target</span></span><br><span class="line">    new_value = current + (alpha * (target - current)) <span class="comment"># get updated value </span></span><br><span class="line">    <span class="keyword">return</span> new_value</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;我看到网上的强化学习教程通常比较复杂-看完莫烦python后总结出来如下-我将主要用代码形式进行理论的展现-其中个别地方用的是OPENAI的表示方式&quot;&gt;&lt;a href=&quot;#我看到网上的强化学习教程通常比较复杂-看完莫烦python后总结出来如下-我将主要用代码形式
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Reinforcement Learning（Third）Code of DQN with TF</title>
    <link href="http://yoursite.com/2018/11/02/Reinforcement_Learning3/"/>
    <id>http://yoursite.com/2018/11/02/Reinforcement_Learning3/</id>
    <published>2018-11-02T07:19:48.000Z</published>
    <updated>2018-11-02T07:19:48.000Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>  <h3 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h3><hr><h4 id="缓冲区及神经网络"><a href="#缓冲区及神经网络" class="headerlink" title="缓冲区及神经网络"></a>缓冲区及神经网络</h4><h5 id="先用-epsilon-greedy-策略选出下一个action，并得到reward和next-state。将-lt-s-t-action-reward-s-t-1-gt-存入缓冲区"><a href="#先用-epsilon-greedy-策略选出下一个action，并得到reward和next-state。将-lt-s-t-action-reward-s-t-1-gt-存入缓冲区" class="headerlink" title="先用\(\epsilon greedy\)策略选出下一个action，并得到reward和next_state。将 \(&lt;s_{t}, action, reward, s_{t+1}&gt;\)存入缓冲区"></a>先用\(\epsilon greedy\)策略选出下一个action，并得到reward和next_state。将 \(&lt;s_{t}, action, reward, s_{t+1}&gt;\)存入缓冲区</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Memory</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, max_size=<span class="number">1000</span>)</span>:</span></span><br><span class="line">        self.buffer = deque(maxlen=max_size)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(self, experience)</span>:</span></span><br><span class="line">        self.buffer.append(experience) <span class="comment">## 添加</span></span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sample</span><span class="params">(self, batch_size)</span>:</span></span><br><span class="line">        idx = np.random.choice(np.arange(len(self.buffer)), </span><br><span class="line">                               size=batch_size, </span><br><span class="line">                               replace=<span class="keyword">False</span>)</span><br><span class="line">        <span class="keyword">return</span> [self.buffer[ii] <span class="keyword">for</span> ii <span class="keyword">in</span> idx] <span class="comment">##随机返回一些batch进行学习</span></span><br></pre></td></tr></table></figure><h5 id="构建一个基础的神经网络，将state的单热点编码作为输入，得到若干个action及他们的数值。"><a href="#构建一个基础的神经网络，将state的单热点编码作为输入，得到若干个action及他们的数值。" class="headerlink" title="构建一个基础的神经网络，将state的单热点编码作为输入，得到若干个action及他们的数值。"></a>构建一个基础的神经网络，将state的单热点编码作为输入，得到若干个action及他们的数值。</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QNetwork</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, learning_rate=<span class="number">0.01</span>, state_size=<span class="number">4</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">                 action_size=<span class="number">2</span>, hidden_size=<span class="number">10</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">                 name=<span class="string">'QNetwork'</span>)</span>:</span></span><br><span class="line">        <span class="comment"># state inputs to the Q-network</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(name):</span><br><span class="line">            self.inputs_ = tf.placeholder(tf.float32, [<span class="keyword">None</span>, state_size], name=<span class="string">'inputs'</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 由于我们都是选定一个动作之后比较Q值，因此在计算时我们会传入当前state选择的action</span></span><br><span class="line">            self.actions_ = tf.placeholder(tf.int32, [<span class="keyword">None</span>], name=<span class="string">'actions'</span>)</span><br><span class="line">            one_hot_actions = tf.one_hot(self.actions_, action_size)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># targetQ另作计算,在training的时候直接传入</span></span><br><span class="line">            self.targetQs_ = tf.placeholder(tf.float32, [<span class="keyword">None</span>], name=<span class="string">'target'</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 构建relu网络</span></span><br><span class="line">            self.fc1 = tf.contrib.layers.fully_connected(self.inputs_, hidden_size)</span><br><span class="line">            self.fc2 = tf.contrib.layers.fully_connected(self.fc1, hidden_size)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 这里是神经网络的输出，targetQ的计算就是单独得到self.output进行处理  </span></span><br><span class="line">            self.output = tf.contrib.layers.fully_connected(self.fc2, action_size, </span><br><span class="line">                                                            activation_fn=<span class="keyword">None</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment">### Train with loss (targetQ - Q)^2</span></span><br><span class="line">            <span class="comment"># </span></span><br><span class="line">            <span class="comment"># 根据state选择的action得到相应的结果，axis=1，说明是行相乘</span></span><br><span class="line">            self.Q = tf.reduce_sum(tf.multiply(self.output, one_hot_actions), axis=<span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># self.targetQs是用神经网络得到不同action的数值后选取max，因此每一个targetQ也是单一数值，与上面的Q对应</span></span><br><span class="line">            self.loss = tf.reduce_mean(tf.square(self.targetQs_ - self.Q))</span><br><span class="line">            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)</span><br></pre></td></tr></table></figure><blockquote><p>\(s_{t}\)与对应的action用来得到\(\hat{Q}(s,a,w)\) then 得到 \(Q(s, max_a, w)\)  </p></blockquote><hr><h4 id="算法主体"><a href="#算法主体" class="headerlink" title="算法主体"></a>算法主体</h4><h5 id="1-使用-epsilon-策略拿到每一次的action"><a href="#1-使用-epsilon-策略拿到每一次的action" class="headerlink" title="1. 使用\(\epsilon \)策略拿到每一次的action"></a>1. 使用\(\epsilon \)策略拿到每一次的action</h5><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">if explore_p &gt; np.<span class="keyword">random</span>.rand():</span><br><span class="line">    <span class="comment"># Make a random action</span></span><br><span class="line">    action = env.action_space.sample()</span><br><span class="line">else:</span><br><span class="line">            <span class="comment"># Get action from Q-network</span></span><br><span class="line">            feed = &#123;mainQN.inputs_: <span class="keyword">state</span>.reshape((<span class="number">1</span>, *<span class="keyword">state</span>.shape))&#125;</span><br><span class="line">            Qs = sess.run(mainQN.output, feed_dict=feed)</span><br><span class="line">            action = np.argmax(Qs)</span><br></pre></td></tr></table></figure><h5 id="2-接着拿到reward、next-state-并存入"><a href="#2-接着拿到reward、next-state-并存入" class="headerlink" title="2. 接着拿到reward、next_state  并存入"></a>2. 接着拿到reward、next_state  并存入</h5><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">next_state, reward, done, _ = env.step(action) <span class="comment">#拿到信息</span></span><br><span class="line"></span><br><span class="line">memory.add((<span class="keyword">state</span>, action, reward, next_state)) <span class="comment">#存入</span></span><br></pre></td></tr></table></figure><blockquote></blockquote><h5 id="3-得到-reward-Q-s-a-w-策略是选取神经网络输出的若干个动作value的最大值"><a href="#3-得到-reward-Q-s-a-w-策略是选取神经网络输出的若干个动作value的最大值" class="headerlink" title="3. 得到\reward + (Q(s,a, w)\), 策略是选取神经网络输出的若干个动作value的最大值"></a>3. 得到\reward + (Q(s,a, w)\), 策略是选取神经网络输出的若干个动作value的最大值</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">    # Train network</span><br><span class="line">    target_Qs = sess.run(mainQN.output, feed_dict=&#123;mainQN.inputs_: next_states&#125;)</span><br><span class="line">                </span><br><span class="line">    # Set target_Qs to <span class="number">0</span> <span class="keyword">for</span> states where episode ends</span><br><span class="line">    episode_ends = (next_states == np.zeros(states[<span class="number">0</span>].shape)).all(axis=<span class="number">1</span>)</span><br><span class="line">    target_Qs[episode_ends] = (<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">                </span><br><span class="line">    targets = rewards + gamma * np.max(target_Qs, axis=<span class="number">1</span>)</span><br><span class="line">```    </span><br><span class="line">&gt; </span><br><span class="line"></span><br><span class="line">#####  <span class="number">4.</span> 训练</span><br></pre></td></tr></table></figure><pre><code>loss, _ = sess.run([mainQN.loss, mainQN.opt],                    feed_dict={mainQN.inputs_: states, ##当前状态                    mainQN.targetQs_: targets,         ##已经计算好                    mainQN.actions_: actions})         ##当前状态所要选取的动作</code></pre><p><code>`</code></p><h5 id="点击这里查看完整ipynb"><a href="#点击这里查看完整ipynb" class="headerlink" title="点击这里查看完整ipynb"></a><a href="https://github.com/JasonWang0808/JasonWang0808.github.io/blob/master/codes/Q-learning-cart.ipynb" target="_blank" rel="noopener">点击这里查看完整ipynb</a></h5>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&quot;&gt;&lt;/script&gt;  

&lt;h3 id=&quot;算法思想&quot;&gt;&lt;a hre
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Reinforcement Learning (Second)</title>
    <link href="http://yoursite.com/2018/11/01/Reinforce_Learning2/"/>
    <id>http://yoursite.com/2018/11/01/Reinforce_Learning2/</id>
    <published>2018-11-01T12:32:20.000Z</published>
    <updated>2018-11-01T12:32:20.000Z</updated>
    
    <content type="html"><![CDATA[<p><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script></p><h4 id="Reference-An-introduction-to-Deep-Q-Learning-let’s-play-Doom"><a href="#Reference-An-introduction-to-Deep-Q-Learning-let’s-play-Doom" class="headerlink" title="Reference : An introduction to Deep Q-Learning: let’s play Doom"></a>Reference : <a href="https://medium.freecodecamp.org/an-introduction-to-deep-q-learning-lets-play-doom-54d02d8017d8/" target="_blank" rel="noopener">An introduction to Deep Q-Learning: let’s play Doom</a></h4><h3 id="Deep-Q-Learning-Network-DQN"><a href="#Deep-Q-Learning-Network-DQN" class="headerlink" title="Deep Q-Learning Network (DQN)"></a>Deep Q-Learning Network (DQN)</h3><h5 id="1-深度强化学习"><a href="#1-深度强化学习" class="headerlink" title="1. 深度强化学习"></a>1. 深度强化学习</h5><p>对于一个复杂的游戏，表示动作及其Value、在Q表里搜索相应的动作变得十分没有效率。因此这里改用神经网络进行Q表的计算。  每次将S放入，即可计算出相应的action及对应的value</p><blockquote><p>\(w\)表示神经网络的权值，\(R\)表示Reward，\(Q\)表示Q表中相应状态和动作对应的数值  </p></blockquote><p>$$<br>current\_predict\_Q = \hat{Q}(s,a,w)<br>$$  </p><p>$$<br>Grdient = \bigtriangledown \hat{Q}(s,a,w)<br>$$   </p><p>$$<br>\Delta w(TDerror) = \alpha[R + \gamma max_{a} \hat{Q}(s\prime ,a, w)) - current\_predict\_Q]<br>$$   </p><h5 id="2-主要优化方法"><a href="#2-主要优化方法" class="headerlink" title="2. 主要优化方法"></a>2. 主要优化方法</h5><blockquote><p>经验回放(Experience Deplay)和固定Q目标是其中的两个主要贡献</p></blockquote><ul><li>经验回放<br>有些动作的代价很大，我们可以把经历过的  \(&lt;S_{t}, A_{t}, R_{t+1}, S_{t+1}&gt;\) 储存在缓冲区中(replay buffer)，后面可以再次用来学习。并可以采取<strong>优先经验回收</strong><br>我们认为，loss越大的数值越具有学习价值，因此buffer里的所有数据都根据其loss决定被选择的概率，每一次学习之后都会更新其概率\(p(i)=\frac{p_{i}^{a}}{\sum_{k=1}^{n} p_{k}^{a}}\),这里的\(a\)保证了不完全按照概率，减少过拟合。（a=1时完全按照概率选取）</li></ul><blockquote><p>研究证明，优先经验回收策略可以减少迭代次数</p></blockquote><ul><li>Q固定<br>我们可以看到在我们的\(R + \gamma max_{a} \hat{Q}(s\prime ,a, w)\)和\(\hat{Q}(s,a,w)\)中都有\(w\)存在。因此两者都在变，导致无法持续收敛。<blockquote><p>打个比方。小明在追他养的牛，想要不断向他的牛靠近。然而他的牛的位置（Q）因为\(w\)的改变也在不断变化。可能一会在小明前，一会去小明后。小明也会懵逼，到底该往哪个方向追。因此我们将\(w^{-}\)固定，事后更新\(w^{-} \gets w\)。这样保证了在收敛过程中目标是确定的不会变化。</p></blockquote></li></ul><p>$$<br>\Delta w(TDerror) = \alpha[R + \gamma max_{a} \hat{Q}(s\prime ,a, w^{-})) - \hat{Q}(s,a,w)]\bigtriangledown \hat{Q}(s,a,w)<br>$$   </p><blockquote><p>Thrun 和 Schwartz，1993 年，<a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.73.3097" target="_blank" rel="noopener">《使用函数逼近进行强化学习存在的问题》（ 高估 Q 值）</a><br>van Hasselt et al.，2015 年，<a href="https://arxiv.org/abs/1509.06461" target="_blank" rel="noopener">《双 Q 学习的深度强化学习》</a><br>Schaul et al.，2016 年，<a href="https://arxiv.org/abs/1511.05952" target="_blank" rel="noopener">《优先经验回放》</a><br>Wang et al.，2015 年，<a href="https://arxiv.org/abs/1511.06581/" target="_blank" rel="noopener">《深度强化学习的对抗网络架构》</a><br>Hausknecht 和 Stone，2015 年，<a href="https://arxiv.org/abs/1507.06527/" target="_blank" rel="noopener">《部分可观察 MDP 的深度递归 Q 学习》</a>    </p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&quot;&gt;&lt;/script&gt;&lt;/p&gt;
&lt;h4 id=&quot;Referenc
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Basic Rules of Tensorflow</title>
    <link href="http://yoursite.com/2018/11/01/tensorflow_basic/"/>
    <id>http://yoursite.com/2018/11/01/tensorflow_basic/</id>
    <published>2018-11-01T12:31:50.000Z</published>
    <updated>2018-11-01T12:31:50.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="常见符号"><a href="#常见符号" class="headerlink" title="常见符号"></a>常见符号</h2><h3 id="1-tf-Variable-与-tf-constant"><a href="#1-tf-Variable-与-tf-constant" class="headerlink" title="1. tf.Variable 与 tf.constant"></a>1. tf.Variable 与 tf.constant</h3><blockquote><p>第一个可以根据计算改变，第二个是不能变的, 因此神经网络的权值通常都是Variable<br>另外要注意, 定义了变量和常量之后，要初始化才能使用</p></blockquote><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">init = <span class="keyword">tf</span>.global_variables_initializer()</span><br><span class="line">with <span class="keyword">tf</span>.Session() <span class="keyword">as</span> ses<span class="variable">s:</span></span><br><span class="line">    sess.run(init)</span><br></pre></td></tr></table></figure><h3 id="2-tf-reduce-mean"><a href="#2-tf-reduce-mean" class="headerlink" title="2. tf.reduce_mean"></a>2. tf.reduce_mean</h3><blockquote><p>取平均值，后面跟1是取行，跟0是取列</p></blockquote><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">x = np.array([[1.,2.,3.],[4.,5.,6.]])</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    mean_none = sess.<span class="builtin-name">run</span>(tf.reduce_mean(x))</span><br><span class="line">    mean_1 = sess.<span class="builtin-name">run</span>(tf.reduce_mean(x,1))</span><br><span class="line">    mean_2 = sess.<span class="builtin-name">run</span>(tf.reduce_mean(x,0))</span><br><span class="line">    <span class="builtin-name">print</span>(x)</span><br><span class="line">    <span class="builtin-name">print</span>(mean_none)</span><br><span class="line">    <span class="builtin-name">print</span>(mean_1)</span><br><span class="line">    <span class="builtin-name">print</span>(mean_2)</span><br></pre></td></tr></table></figure><h3 id="3-tf-equal"><a href="#3-tf-equal" class="headerlink" title="3. tf.equal"></a>3. tf.equal</h3><blockquote><p>分别比较矩阵中相同的元素，相同就返回true,不同就返回false</p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf  </span><br><span class="line"> import numpy as np  </span><br><span class="line">   </span><br><span class="line"> A = <span class="string">[[1,3,4,5,6]]</span>  </span><br><span class="line"> B = <span class="string">[[1,3,4,3,2]]</span>  </span><br><span class="line">   </span><br><span class="line"> with tf.Session() as sess:  </span><br><span class="line">     <span class="built_in">print</span>(sess.run(tf.equal(A, B)))</span><br></pre></td></tr></table></figure><h3 id="4-tf-truncated-normal"><a href="#4-tf-truncated-normal" class="headerlink" title="4. tf.truncated_normal"></a>4. tf.truncated_normal</h3><blockquote><p>shape 表示要生成的矩阵的大小<br>mean 表示正态函数的均值<br>stddev表示要生成的随机数的方差<br>seed 是随机数种，通常条件下为None</p></blockquote><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.random_normal(shape, <span class="attribute">mean</span>=0.0, <span class="attribute">stddev</span>=1.0, <span class="attribute">dtype</span>=tf.float32, <span class="attribute">seed</span>=None, <span class="attribute">name</span>=None)</span><br></pre></td></tr></table></figure><h3 id="5-tf-reshape"><a href="#5-tf-reshape" class="headerlink" title="5. tf.reshape"></a>5. tf.reshape</h3><blockquote><p>更改矩阵的大小, 通常对图像进行改变<br>参数中可以指定一个 -1 （且只能有一个）, 将根据其他参数的指定自动计算出该维度</p></blockquote><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:<span class="regexp">//</span>blog.csdn.net<span class="regexp">/m0_37592397/</span>article<span class="regexp">/details/</span><span class="number">78695318</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;常见符号&quot;&gt;&lt;a href=&quot;#常见符号&quot; class=&quot;headerlink&quot; title=&quot;常见符号&quot;&gt;&lt;/a&gt;常见符号&lt;/h2&gt;&lt;h3 id=&quot;1-tf-Variable-与-tf-constant&quot;&gt;&lt;a href=&quot;#1-tf-Variable-与-tf
      
    
    </summary>
    
    
  </entry>
  
</feed>
