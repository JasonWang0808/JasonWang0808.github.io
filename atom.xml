<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Junyu Wang&#39;s Blog</title>
  
  <subtitle>hello</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-11-18T12:10:25.936Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>JunYu Wang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hidden Markov Model，HMM</title>
    <link href="http://yoursite.com/2018/11/18/HMM/"/>
    <id>http://yoursite.com/2018/11/18/HMM/</id>
    <published>2018-11-18T05:20:11.753Z</published>
    <updated>2018-11-18T12:10:25.936Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>  <h3 id="隐马尔可夫模型在词性标注上的应用"><a href="#隐马尔可夫模型在词性标注上的应用" class="headerlink" title="隐马尔可夫模型在词性标注上的应用"></a>隐马尔可夫模型在词性标注上的应用</h3><blockquote><p>给定前提我们只关注N/M/V三个词性  </p></blockquote><h4 id="首先介绍第一个概念-Emission-Probabilities"><a href="#首先介绍第一个概念-Emission-Probabilities" class="headerlink" title="首先介绍第一个概念  Emission Probabilities"></a>首先介绍第一个概念  Emission Probabilities</h4><h4 id="gt-是指同一种状态各个数值得可能性，可以看下图"><a href="#gt-是指同一种状态各个数值得可能性，可以看下图" class="headerlink" title="&gt; 是指同一种状态各个数值得可能性，可以看下图"></a>&gt; 是指同一种状态各个数值得可能性，可以看下图</h4><p><img src="/images/NLP/HMM/1.png" alt="">  </p><h4 id="我们可以看到，当认为是当前词语是N的时候有4-9的可能性是mary"><a href="#我们可以看到，当认为是当前词语是N的时候有4-9的可能性是mary" class="headerlink" title="我们可以看到，当认为是当前词语是N的时候有4/9的可能性是mary"></a>我们可以看到，当认为是当前词语是N的时候有4/9的可能性是mary</h4><h4 id="接下来是第二个概念-Transition-Probabilities"><a href="#接下来是第二个概念-Transition-Probabilities" class="headerlink" title="接下来是第二个概念  Transition Probabilities"></a>接下来是第二个概念  Transition Probabilities</h4><h4 id="gt-指状态之间的转换概率，-分别表示开始和结束，看下图"><a href="#gt-指状态之间的转换概率，-分别表示开始和结束，看下图" class="headerlink" title="&gt; 指状态之间的转换概率，/分别表示开始和结束，看下图"></a>&gt; 指状态之间的转换概率，<s>/<e>分别表示开始和结束，看下图</e></s></h4><p><img src="/images/NLP/HMM/2.png" alt="">  </p><h4 id="OK，那我们先来看一个例子"><a href="#OK，那我们先来看一个例子" class="headerlink" title="OK，那我们先来看一个例子"></a>OK，那我们先来看一个例子</h4><blockquote><p>Jane will spot Will  </p></blockquote><h4 id="我们根据前序经验统计出前面的两个概率，然后可以构造流程图如下"><a href="#我们根据前序经验统计出前面的两个概率，然后可以构造流程图如下" class="headerlink" title="我们根据前序经验统计出前面的两个概率，然后可以构造流程图如下"></a>我们根据前序经验统计出前面的两个概率，然后可以构造流程图如下</h4><p><img src="/images/NLP/HMM/3.png" alt="">   </p><h4 id="我们要计算每一条链的可能性就是把边数值与节点数值一路相乘，为了减少计算，我们采用每一层的动态规划（就是最简单那种），每个节点只保留前序节点数值最大的那一条。"><a href="#我们要计算每一条链的可能性就是把边数值与节点数值一路相乘，为了减少计算，我们采用每一层的动态规划（就是最简单那种），每个节点只保留前序节点数值最大的那一条。" class="headerlink" title="我们要计算每一条链的可能性就是把边数值与节点数值一路相乘，为了减少计算，我们采用每一层的动态规划（就是最简单那种），每个节点只保留前序节点数值最大的那一条。"></a>我们要计算每一条链的可能性就是把边数值与节点数值一路相乘，为了减少计算，我们采用每一层的动态规划（就是最简单那种），每个节点只保留前序节点数值最大的那一条。</h4><h4 id="最后我们就可以得到这样一条-通过分析我们可以发现确实得到的结果和我们预期相同"><a href="#最后我们就可以得到这样一条-通过分析我们可以发现确实得到的结果和我们预期相同" class="headerlink" title="最后我们就可以得到这样一条,通过分析我们可以发现确实得到的结果和我们预期相同"></a>最后我们就可以得到这样一条,通过分析我们可以发现确实得到的结果和我们预期相同</h4><h2 id=""><a href="#" class="headerlink" title="   "></a><img src="/images/NLP/HMM/3.png" alt="">   </h2><h3 id="以上是找best-path，接下来我们看一下HMM的forward-algorithm"><a href="#以上是找best-path，接下来我们看一下HMM的forward-algorithm" class="headerlink" title="以上是找best path，接下来我们看一下HMM的forward algorithm"></a>以上是找best path，接下来我们看一下HMM的forward algorithm</h3><hr><p>已知概率分布  </p><p><strong>1. Initial</strong></p><table><thead><tr><th>Sunny</th><th>Rainy</th></tr></thead><tbody><tr><td>0.5</td><td>0.5</td></tr></tbody></table><p><strong>2. Emission Probabilities</strong></p><table><thead><tr><th>null</th><th>yes</th><th>no</th></tr></thead><tbody><tr><td>sunny</td><td>0.1</td><td>0.9</td></tr><tr><td>rainy</td><td>0.8</td><td>0.2</td></tr></tbody></table><p><strong>3. State transition probabilities</strong></p><table><thead><tr><th>null</th><th>sunny</th><th>rainy</th></tr></thead><tbody><tr><td>sunny</td><td>0.8</td><td>0.2</td></tr><tr><td>rainy</td><td>0.4</td><td>0.6  </td></tr></tbody></table><h5 id="现在给定一个序列-S-‘yes’-‘no’-‘yes’"><a href="#现在给定一个序列-S-‘yes’-‘no’-‘yes’" class="headerlink" title="现在给定一个序列 S = [‘yes’, ‘no’, ‘yes’]"></a>现在给定一个序列 S = [‘yes’, ‘no’, ‘yes’]</h5><h5 id="通过forward-algorithm可以计算出在所有的天气组合当中所有满足该序列的概率"><a href="#通过forward-algorithm可以计算出在所有的天气组合当中所有满足该序列的概率" class="headerlink" title="通过forward algorithm可以计算出在所有的天气组合当中所有满足该序列的概率\"></a>通过forward algorithm可以计算出在所有的天气组合当中所有满足该序列的概率\</h5><p>$$<br>P(S|1-sunny) = 0.5 * 0.1 = 0.05<br>$$</p><p>$$<br>P(S|1-rainy) = 0.5 * 0.8 = 0.4<br>$$</p><p>$$<br>P(S|2-sunny) = (P(S|1-sunny)*0.8 + P(S|1-rainy)*0.4)P(no|sunny)<br>$$</p><h4 id="以此类推，最终结果为-P-S-3-sunny-P-S-3-rainy"><a href="#以此类推，最终结果为-P-S-3-sunny-P-S-3-rainy" class="headerlink" title="以此类推，最终结果为\(P(S|3-sunny) + P(S|3-rainy)\)"></a>以此类推，最终结果为\(P(S|3-sunny) + P(S|3-rainy)\)</h4><h4 id="我们可以看出来这个过程相当繁琐-这里用pomegranate库来实现"><a href="#我们可以看出来这个过程相当繁琐-这里用pomegranate库来实现" class="headerlink" title="我们可以看出来这个过程相当繁琐, 这里用pomegranate库来实现"></a>我们可以看出来这个过程相当繁琐, 这里用pomegranate库来实现</h4><blockquote><p>参考的问题是关于一个海藻的理论推导 <a href="https://blog.csdn.net/TH_NUM/article/details/51570174" target="_blank" rel="noopener">https://blog.csdn.net/TH_NUM/article/details/51570174</a></p></blockquote><h4 id="为什么和手动算的结果有些偏差呢，因为这个每一步都会进行估算"><a href="#为什么和手动算的结果有些偏差呢，因为这个每一步都会进行估算" class="headerlink" title="为什么和手动算的结果有些偏差呢，因为这个每一步都会进行估算"></a>为什么和手动算的结果有些偏差呢，因为这个每一步都会进行估算</h4><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">from pomegranate import State, HiddenMarkovModel, <span class="keyword">DiscreteDistribution</span></span><br><span class="line"><span class="keyword">import </span>numpy as np</span><br><span class="line">model = HiddenMarkovModel(name=<span class="string">"Example Model"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置每个状态的发射概率</span></span><br><span class="line">sunny_emissions = <span class="keyword">DiscreteDistribution(&#123;"Dry": </span><span class="number">0</span>.<span class="number">6</span>, <span class="string">"Dryish"</span>: <span class="number">0</span>.<span class="number">2</span>, <span class="string">"Damp"</span>:<span class="number">0</span>.<span class="number">15</span>, <span class="string">"Soggy"</span>:<span class="number">0</span>.<span class="number">05</span>&#125;)</span><br><span class="line">sunny_state = State(sunny_emissions, name=<span class="string">"Sunny"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">cloud_emissions </span>= <span class="keyword">DiscreteDistribution(&#123;"Dry": </span><span class="number">0</span>.<span class="number">25</span>, <span class="string">"Dryish"</span>: <span class="number">0</span>.<span class="number">25</span>, <span class="string">"Damp"</span>:<span class="number">0</span>.<span class="number">25</span>, <span class="string">"Soggy"</span>:<span class="number">0</span>.<span class="number">25</span>&#125;)</span><br><span class="line"><span class="keyword">cloud_state </span>= State(<span class="keyword">cloud_emissions, </span>name=<span class="string">"Cloud"</span>)</span><br><span class="line"></span><br><span class="line">rainy_emissions = <span class="keyword">DiscreteDistribution(&#123;"Dry": </span><span class="number">0</span>.<span class="number">05</span>, <span class="string">"Dryish"</span>: <span class="number">0</span>.<span class="number">10</span>, <span class="string">"Damp"</span>:<span class="number">0</span>.<span class="number">35</span>, <span class="string">"Soggy"</span>:<span class="number">0</span>.<span class="number">50</span>&#125;)</span><br><span class="line">rainy_state = State(rainy_emissions, name=<span class="string">"Rainy"</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="keyword">cloud_emissions.probability("Dryish"))</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword"># </span>添加状态</span><br><span class="line">model.<span class="keyword">add_states(sunny_state, </span><span class="keyword">cloud_state, </span>rainy_state)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加转移概率，从init开始</span></span><br><span class="line">model.<span class="keyword">add_transition(model.start, </span>sunny_state, <span class="number">0</span>.<span class="number">63</span>)</span><br><span class="line">model.<span class="keyword">add_transition(model.start, </span>rainy_state, <span class="number">0</span>.<span class="number">20</span>)</span><br><span class="line">model.<span class="keyword">add_transition(model.start, </span><span class="keyword">cloud_state, </span><span class="number">0</span>.<span class="number">17</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.<span class="keyword">add_transition(sunny_state, </span>sunny_state, <span class="number">0</span>.<span class="number">5</span>)  <span class="comment"># 50% sunny-&gt;sunny</span></span><br><span class="line">model.<span class="keyword">add_transition(sunny_state, </span>rainy_state, <span class="number">0</span>.<span class="number">125</span>)  <span class="comment"># 12.5% sunny-&gt;rainy</span></span><br><span class="line">model.<span class="keyword">add_transition(sunny_state, </span><span class="keyword">cloud_state, </span><span class="number">0</span>.<span class="number">375</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.<span class="keyword">add_transition(rainy_state, </span>sunny_state, <span class="number">0</span>.<span class="number">25</span>)  <span class="comment"># 25% rainy-&gt;sunny</span></span><br><span class="line">model.<span class="keyword">add_transition(rainy_state, </span>rainy_state, <span class="number">0</span>.<span class="number">375</span>)  <span class="comment"># 37.5% rainy-&gt;rainy</span></span><br><span class="line">model.<span class="keyword">add_transition(rainy_state, </span><span class="keyword">cloud_state, </span><span class="number">0</span>.<span class="number">375</span>)</span><br><span class="line"></span><br><span class="line">model.<span class="keyword">add_transition(cloud_state, </span><span class="keyword">cloud_state, </span><span class="number">0</span>.<span class="number">125</span>)</span><br><span class="line">model.<span class="keyword">add_transition(cloud_state, </span>sunny_state, <span class="number">0</span>.<span class="number">25</span>)</span><br><span class="line">model.<span class="keyword">add_transition(cloud_state, </span>rainy_state, <span class="number">0</span>.<span class="number">625</span>)</span><br><span class="line"><span class="comment"># 最后使用bake完结</span></span><br><span class="line">model.<span class="keyword">bake()</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword">observations </span>= [<span class="string">'Dry'</span>, <span class="string">'Damp'</span>, <span class="string">'Soggy'</span>]</span><br><span class="line">forward_matrix = np.exp(model.forward(observations))</span><br><span class="line"></span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span> use model.log_probability() to calculate the all-paths likelihood of the</span></span><br><span class="line"><span class="comment"># observed sequence and then use np.exp() to convert log-likelihood to likelihood</span></span><br><span class="line">probability_percentage = np.exp(model.log_probability(observations))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display the forward probabilities</span></span><br><span class="line">print(<span class="string">"         "</span> + <span class="string">""</span>.<span class="keyword">join(s.name.center(len(s.name)+6) </span>for s in model.states))</span><br><span class="line">for i in range(len(observations) + <span class="number">1</span>):</span><br><span class="line">    print(<span class="string">" &lt;start&gt; "</span> if i==<span class="number">0</span> else observations[i - <span class="number">1</span>].center(<span class="number">9</span>), end=<span class="string">""</span>)</span><br><span class="line">    print(<span class="string">""</span>.<span class="keyword">join("&#123;:.0f&#125;%".format(100 </span>* forward_matrix[i, <span class="keyword">j]).center(len(s.name) </span>+ <span class="number">6</span>)</span><br><span class="line">                  for <span class="keyword">j, </span>s in enumerate(model.states)))</span><br><span class="line"></span><br><span class="line">print(<span class="string">"\nThe likelihood over all possible paths "</span> + \</span><br><span class="line">      <span class="string">"of this model producing the sequence &#123;&#125; is &#123;:.2f&#125;%\n\n"</span></span><br><span class="line">      .format(observations, <span class="number">100</span> * probability_percentage))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&quot;&gt;&lt;/script&gt;  

&lt;h3 id=&quot;隐马尔可夫模型在词性标注
      
    
    </summary>
    
      <category term="NLP" scheme="http://yoursite.com/categories/NLP/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>spam classification --- naive bayes</title>
    <link href="http://yoursite.com/2018/11/16/spam-classification/"/>
    <id>http://yoursite.com/2018/11/16/spam-classification/</id>
    <published>2018-11-16T12:58:52.786Z</published>
    <updated>2018-11-17T05:57:39.553Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script> <h3 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h3><h5 id="我们在清分的时候认为有easy和money就可能使垃圾邮件，通过检查邮件中有两个单词就可以说明是否为spam，“朴素”贝叶斯朴素在于认为各个元素是相互独立的，因此直接将概率相乘"><a href="#我们在清分的时候认为有easy和money就可能使垃圾邮件，通过检查邮件中有两个单词就可以说明是否为spam，“朴素”贝叶斯朴素在于认为各个元素是相互独立的，因此直接将概率相乘" class="headerlink" title="我们在清分的时候认为有easy和money就可能使垃圾邮件，通过检查邮件中有两个单词就可以说明是否为spam，“朴素”贝叶斯朴素在于认为各个元素是相互独立的，因此直接将概率相乘"></a>我们在清分的时候认为有easy和money就可能使垃圾邮件，通过检查邮件中有两个单词就可以说明是否为spam，“朴素”贝叶斯朴素在于认为各个元素是相互独立的，因此直接将概率相乘</h5><p>$$<br>(1) P(spam) P(‘easy’|spam) P(‘money’|spam)  +  P(ham) P(‘easy’|ham) P(‘money’|ham) = \alpha<br>$$</p><p>$$<br>(2) P(spam|’easy’, ‘money’) = \frac{ P(spam) P(‘easy’|spam) P(‘money’|spam) }{\alpha}<br>$$    </p><p>$$<br>(3) P(ham|’easy’, ‘money’) = \frac{ P(ham) P(‘easy’|ham) P(‘money’|ham) }{\alpha}<br>$$</p><p>$$<br> Final : P(spam|’easy’, ‘money’)  +  P(ham|’easy’, ‘money’) = 1<br>$$</p><h5 id="当然我们在实际过程中调用sklearn-naive-bayes-MultinomialNB就可以"><a href="#当然我们在实际过程中调用sklearn-naive-bayes-MultinomialNB就可以" class="headerlink" title="当然我们在实际过程中调用sklearn.naive_bayes.MultinomialNB就可以"></a>当然我们在实际过程中调用sklearn.naive_bayes.MultinomialNB就可以</h5><h5 id="gt-注意训练数据的形式是dataframe，用pandas直接读取或者是用matrix转换"><a href="#gt-注意训练数据的形式是dataframe，用pandas直接读取或者是用matrix转换" class="headerlink" title="&gt; 注意训练数据的形式是dataframe，用pandas直接读取或者是用matrix转换"></a>&gt; 注意训练数据的形式是dataframe，用pandas直接读取或者是用matrix转换</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># Dataset from - https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"></span><br><span class="line">df = pd.read_table(</span><br><span class="line">        <span class="string">'./smsspamcollection/SMSSpamCollection'</span>,</span><br><span class="line">        sep=<span class="string">'\t'</span>,</span><br><span class="line">       names = [<span class="string">'label'</span>, <span class="string">'sms_message'</span>]</span><br><span class="line">        )</span><br><span class="line"><span class="comment"># Note1. 注意读出的是data_frame，命名用names</span></span><br><span class="line"></span><br><span class="line">df[<span class="string">'label'</span>] = df.label.map(&#123;<span class="string">'spam'</span>:<span class="number">1</span>, <span class="string">'ham'</span>:<span class="number">0</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Note2. 二分类问题</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(df[<span class="string">'sms_message'</span>],</span><br><span class="line">                                                    df[<span class="string">'label'</span>],</span><br><span class="line">                                                    random_state=<span class="number">1</span>)</span><br><span class="line">count_vector = CountVectorizer()</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">fit是找到规律，如果fit过之后就可以直接transform，因为规律已经学会了</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">training_data = count_vector.fit_transform(X_train)</span><br><span class="line">testing_data = count_vector.transform(X_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line">naive_bayes = MultinomialNB()</span><br><span class="line">naive_bayes.fit(training_data, y_train)</span><br><span class="line">predictions = naive_bayes.predict(testing_data)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Precision tells us what proportion of messages we classified as spam, actually were spam.</span></span><br><span class="line"><span class="string">[True Positives/(True Positives + False Positives)]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Recall tells us what proportion of messages we classified as spam in the total number of spam</span></span><br><span class="line"><span class="string">[True Positives/(True Positives + False Negatives)]</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, precision_score, recall_score, f1_score</span><br><span class="line">print(<span class="string">'Accuracy score: '</span>, format(accuracy_score(y_test, predictions)))</span><br><span class="line">print(<span class="string">'Precision score: '</span>, format(precision_score(y_test, predictions)))</span><br><span class="line">print(<span class="string">'Recall score: '</span>, format(recall_score(y_test, predictions)))</span><br><span class="line">print(<span class="string">'F1 score: '</span>, format(f1_score(y_test, predictions)))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&quot;&gt;&lt;/script&gt; 

&lt;h3 id=&quot;举个栗子&quot;&gt;&lt;a href
      
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>NLP(First) Text Processing</title>
    <link href="http://yoursite.com/2018/11/14/NLP1/"/>
    <id>http://yoursite.com/2018/11/14/NLP1/</id>
    <published>2018-11-14T14:18:27.448Z</published>
    <updated>2018-11-14T14:26:21.557Z</updated>
    
    <content type="html"><![CDATA[<h2 id="basic-rules-of-text-procession-and-how-to-use-nltk"><a href="#basic-rules-of-text-procession-and-how-to-use-nltk" class="headerlink" title="basic rules of text procession and how to use nltk"></a>basic rules of text procession and how to use nltk</h2><h3 id="下图是一个简单的处理流程"><a href="#下图是一个简单的处理流程" class="headerlink" title="下图是一个简单的处理流程"></a>下图是一个简单的处理流程</h3><p><img src="/images/NLP/text_processing/text_p.png" alt=""></p><p>判断一段文字中单词出现的数量是一个经典的问题，首先建立一个dict。接着把str用spilt给分开，用正则表达式去除标点，然后统计数量</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def count_words(str):</span><br><span class="line">    <span class="string">""</span><span class="string">"Count how many times each unique word occurs in text."</span><span class="string">""</span></span><br><span class="line">    counts = dict()  <span class="comment"># dictionary of &#123; &lt;word&gt;: &lt;count&gt; &#125; pairs to return</span></span><br><span class="line">    <span class="comment"># text = str(text)</span></span><br><span class="line">    <span class="comment"># str = "one and two and three and two and one\nbuffalo buffalo buffalo, buffalo buffalo!"</span></span><br><span class="line">    str = str.<span class="built_in">replace</span>(<span class="string">"\n"</span>, <span class="string">" "</span>)</span><br><span class="line">    str = str.<span class="built_in">lower</span>()</span><br><span class="line">    word_l = str.<span class="built_in">split</span>(<span class="string">" "</span>)</span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Split text into tokens (words), leaving out punctuation</span></span><br><span class="line">    <span class="comment"># (Hint: Use regex to split on non-alphanumeric characters)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Aggregate word counts using a dictionary</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">word</span> <span class="keyword">in</span> word_l:</span><br><span class="line">        <span class="built_in">word</span> = re.match(<span class="string">"([a-zA-Z]+).*"</span>, <span class="built_in">word</span>)</span><br><span class="line">        <span class="built_in">word</span> = <span class="built_in">word</span>.group(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">word</span> <span class="keyword">not</span> <span class="keyword">in</span> counts:</span><br><span class="line">            counts[<span class="built_in">word</span>] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            counts[<span class="built_in">word</span>] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="literal">return</span> counts</span><br></pre></td></tr></table></figure><p>看起来不错，但是如果有一套统一的工具来做这些是不是会更好，这时候就出现了nltk(Natural Language ToolKit)  </p><blockquote><p>pip install nltk  </p></blockquote><p><strong>1. from nltk.tokenize import word_tokenize</strong></p><blockquote><p>将一个句子中的单词一个个提取出来，相比于自己split好在他更智能。e.g. 可以提取出Dr.</p></blockquote><p><strong>2. from nltk.tokenize import sent_tokenize</strong> </p><blockquote><p>可以将一个个句子提取出来  </p></blockquote><p><strong>3. from nltk.corpus import stopwords</strong>  </p><blockquote><p>有一些句子中的单词是没有意义的，stopwords可以帮助我们快速提取出来  </p></blockquote><p><strong>4. Sentence Parsing</strong></p><blockquote><p>根据语法规则把一句话变成一棵树，没搞懂啥意思</p></blockquote><p><img src="/images/NLP/text_processing/parse_tree.png" alt=""></p><p><strong>5. Stemming &amp; Lemmatization</strong></p><blockquote><p>同一个单词可能有不同时态、单复数等，取其枝干可以大大减小运算量和内存占用  </p></blockquote><p>另外我们需要了解的还有beautiful的相应用法，imooc的爬虫课程讲解了基础。</p><p>正则表达式也是很重要的知识，在这里就不一一阐述</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;basic-rules-of-text-procession-and-how-to-use-nltk&quot;&gt;&lt;a href=&quot;#basic-rules-of-text-procession-and-how-to-use-nltk&quot; class=&quot;headerlink&quot;
      
    
    </summary>
    
      <category term="NLP" scheme="http://yoursite.com/categories/NLP/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Pyspider (Four) how to use a simple Spider</title>
    <link href="http://yoursite.com/2018/11/11/pyspider4/"/>
    <id>http://yoursite.com/2018/11/11/pyspider4/</id>
    <published>2018-11-11T09:44:23.846Z</published>
    <updated>2018-11-11T17:15:49.089Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、创建环境"><a href="#一、创建环境" class="headerlink" title="一、创建环境"></a>一、创建环境</h3><p>使用pycharm安装spyder<br>打开想要创建的目录</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">scrapy </span>startproject ArticleSpyder <span class="comment">#创建工程</span></span><br><span class="line"><span class="keyword">scrapy </span>genspider <span class="keyword">jobbole </span><span class="keyword">blog.jobbole.com </span><span class="comment">#创建模板</span></span><br></pre></td></tr></table></figure><p>这时候我们就会发现用pycharm打开这个文件~<br>在setting.py中将obey robots.txt 设置为false防止去多url被过滤<br>在ArticleSpider下创立main.py  </p><blockquote></blockquote><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from scrapy<span class="selector-class">.cmdline</span> import execute</span><br><span class="line">import sys</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">path = os<span class="selector-class">.path</span><span class="selector-class">.dirname</span>(os<span class="selector-class">.path</span><span class="selector-class">.abspath</span>(__file__))</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(path)</span></span></span><br><span class="line">sys<span class="selector-class">.path</span><span class="selector-class">.append</span>(path)</span><br><span class="line"><span class="function"><span class="title">execute</span><span class="params">([<span class="string">"scrapy"</span>,<span class="string">"crawl"</span>, <span class="string">"jobblole"</span>])</span></span></span><br></pre></td></tr></table></figure><h3 id="二、在cmd中进行实验"><a href="#二、在cmd中进行实验" class="headerlink" title="二、在cmd中进行实验"></a>二、在cmd中进行实验</h3><p>好处是不用反复run对网页内容进行拉取  </p><blockquote></blockquote><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy shell http:<span class="regexp">//</span>blog.jobbole.com<span class="regexp">/114461/</span></span><br></pre></td></tr></table></figure><h3 id="三、使用xpath"><a href="#三、使用xpath" class="headerlink" title="三、使用xpath"></a>三、使用xpath</h3><p>这里可以一次拉取我们需要的信息，接着我们选取拉回的response进行操作<br>这里我们选取一篇可怜的博客作为实验对象，分别拉取他的title、create_date、praise_nums</p><blockquote><p>实验对象 <a href="http://blog.jobbole.com/114461/" target="_blank" rel="noopener">http://blog.jobbole.com/114461/</a>   </p></blockquote><p>这里我们分别采用绝对路径、选取全部class名字、选取部分class名字进行操作。<strong>extract()帮助我们提取出里面的有效信息</strong>，操作时候注意我们需要的文本是在 <strong>当前class下还是h10等小标签下</strong> </p><p>注意：在python project中在def parse(self, response)下进行操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#这里是用绝对路径并extract出里面的文本信息  </span></span><br><span class="line">title = response.xpath(<span class="string">"/html/head/title/text()"</span>) </span><br><span class="line">title.extract() </span><br><span class="line"></span><br><span class="line"><span class="comment"># //p: 所有的p标签 、[@class=xxx]:class 名字为xxx</span></span><br><span class="line"><span class="comment"># strip():去掉空格和换行</span></span><br><span class="line">create_date = response.xpath(<span class="string">"//p[@class='entry-meta-hide-on-mobile']/text()"</span>).extract()[<span class="number">0</span>].strip()</span><br><span class="line">create_date = create_date.replace(<span class="string">"`"</span>,<span class="string">""</span>).strip()</span><br><span class="line"></span><br><span class="line"><span class="comment">#用了contains函数：注意要加[]以及'，'分割两个参数</span></span><br><span class="line">praise_nums = response.xpath(<span class="string">"//span[contains(@class,'vote-post-up')]/h10/text()"</span>).extract()</span><br><span class="line"></span><br><span class="line"> favor = response.xpath(<span class="string">"//span[contains(@class,'bookmark-btn')]/text()"</span>).extract()</span><br></pre></td></tr></table></figure><p>全部操作完成后可以用正则表达式进行清洗  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">favor = response.xpath(<span class="string">"//span[contains(@class,'bookmark-btn')]/text()"</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        match_f = re.match(<span class="string">".*(\d+).*"</span>,favor)</span><br><span class="line">        print(<span class="string">"sdfg"</span>)</span><br><span class="line">        <span class="keyword">if</span> match_f:</span><br><span class="line">            print(match_f.group(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># given a tag_list 我们要去除掉不是tag的评论</span></span><br><span class="line">[element <span class="keyword">for</span> element <span class="keyword">in</span> tag_list <span class="keyword">if</span> <span class="keyword">not</span> element.endswith(<span class="string">"评论"</span>)]  </span><br><span class="line">```</span><br></pre></td></tr></table></figure><hr><h3 id="四、使用css"><a href="#四、使用css" class="headerlink" title="四、使用css"></a>四、使用css</h3><p>*: 选择所有  </p><p>#container: 选择id为container的节点<br>.container: 选取所有class包含container的节点<br>li a: 选取所有li下的所有a节点<br>ul + p: 选择ul后面的第一个p元素<br>div#container &gt; ul: 选取id为container的div的第一个ul元素<br>ul ~ p : 选取和ul相邻的所有p元素<br>a[href=”<a href="http://jobbole.com&quot;]" target="_blank" rel="noopener">http://jobbole.com&quot;]</a>: 选出所有该gref的所有元素<br>a[href*=”jobblole”]: 选出所有该gref的所有元素<br>a[href^=”http”]: 选出所有该gref以http的所有元素<br>a[href$=”.jpg”]: 选出所有该gref以jpg结尾的所有元素</p><p>#id: id 写法</p><blockquote><p>爬取例子 <a href="http://blog.jobbole.com/107390/" target="_blank" rel="noopener">http://blog.jobbole.com/107390/</a></p></blockquote><ol><li>选取p元素下的entry-meta-hide-on-mobile类的text</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">date = response.css(<span class="string">"p.entry-meta-hide-on-mobile::text"</span>).extract()[<span class="number">0</span>].strip()</span><br></pre></td></tr></table></figure><ol start="2"><li>取span下vote-post-up中和h10的文本（点赞数），第一个用’.’,后面的用空格，text用冒号。如果说后面的class唯一可以省去span  </li></ol><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">vote</span> = response.css(<span class="string">"span.vote-post-up h10::text"</span>).extract()[<span class="number">0</span>].strip()</span><br></pre></td></tr></table></figure><ol start="3"><li>取herf=”#article-comment”下的span中的文字  </li></ol><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">comment</span> = response.css(<span class="string">"a[href='#article-comment'] span::text"</span>).extract()[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><ol start="4"><li><p>提取内容  </p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">content</span> = response.css(<span class="string">".entry"</span>)</span><br></pre></td></tr></table></figure></li><li><p>提取tag并用’,’连接  </p></li></ol><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">tags</span> = response.css(<span class="string">"div.entry-meta p a::text"</span>).extract()</span><br><span class="line"><span class="attr">t</span> = <span class="string">","</span>.join(tags)</span><br></pre></td></tr></table></figure><ol start="6"><li>提取一个页面中的所有url</li></ol><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">post_urls</span> = response.css(<span class="string">"#archive .floated-thumb .post-thumb a::attr(href)"</span>).extract()</span><br></pre></td></tr></table></figure><ol start="7"><li>选取下一页  <blockquote><p>注意attr的提取功能  </p></blockquote></li></ol><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">next_p</span> = response.css(<span class="string">".next.page-numbers::attr(href)"</span>).extract_first(<span class="string">""</span>)</span><br></pre></td></tr></table></figure><h3 id="五、实战"><a href="#五、实战" class="headerlink" title="五、实战"></a>五、实战</h3><h5 id="这里记录下来debug了两个小时的坑"><a href="#这里记录下来debug了两个小时的坑" class="headerlink" title="这里记录下来debug了两个小时的坑"></a>这里记录下来debug了两个小时的坑</h5><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name</span> = <span class="string">"jobblole"</span></span><br><span class="line">   <span class="attr">allowed_domains</span> = [<span class="string">"web.jobbole.com"</span>]</span><br><span class="line">   <span class="attr">start_urls</span> = ['http://web.jobbole.com/all-posts/']</span><br></pre></td></tr></table></figure><h5 id="一直没注意domain，我们应该确保搜索的范围在domain中，不然会出现错误"><a href="#一直没注意domain，我们应该确保搜索的范围在domain中，不然会出现错误" class="headerlink" title="一直没注意domain，我们应该确保搜索的范围在domain中，不然会出现错误"></a>一直没注意domain，我们应该确保搜索的范围在domain中，不然会出现错误</h5><p>接着打开一中创建的模板  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 递归运行函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        1. 获取文章列表页中的文章url并交给scrapy下载后并进行解析</span></span><br><span class="line"><span class="string">        2. 获取下一页的url并交给scrapy进行下载， 下载完成后交给parse</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 解析列表页中的所有文章url并交给scrapy下载后并进行解析</span></span><br><span class="line"></span><br><span class="line">        post_nodes = response.css(<span class="string">"#archive .floated-thumb .post-thumb a"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> post_node <span class="keyword">in</span> post_nodes:</span><br><span class="line">            post_url = post_node.css(<span class="string">"::attr(href)"</span>).extract_first(<span class="string">""</span>)</span><br><span class="line">            print(post_url)</span><br><span class="line">            <span class="keyword">yield</span> Request(url=parse.urljoin(response.url, post_url), callback=self.parse_detail)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取下一页并交给scrapy进行下载</span></span><br><span class="line">        next_url = response.css(<span class="string">".next.page-numbers::attr(href)"</span>).extract_first(<span class="string">""</span>)</span><br><span class="line">        <span class="keyword">if</span> next_url:</span><br><span class="line">            <span class="keyword">yield</span> Request(url=parse.urljoin(response.url, post_url), callback=self.parse)</span><br></pre></td></tr></table></figure><p>这里有三个需要注意的地方  </p><ol><li>yield Request就是运行，无需其他操作</li><li>url要使用parse.urljoin(response.url, post_url), 比如github，能抓取到的只有仓库名，但是前面需要加上github的大域名  </li><li>callback不需要加括号，只需要函数名字  </li></ol><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def parse_detail(self, response):</span><br><span class="line"></span><br><span class="line">       <span class="comment"># 通过css选择器提取字段</span></span><br><span class="line"></span><br><span class="line">       <span class="attr">title</span> = response.css(<span class="string">".entry-header h1::text"</span>).extract()[<span class="number">0</span>]</span><br><span class="line">       <span class="attr">create_date</span> = response.css(<span class="string">"p.entry-meta-hide-on-mobile::text"</span>).extract()[<span class="number">0</span>].strip().replace(<span class="string">"·"</span>, <span class="string">""</span>).strip()</span><br><span class="line">       <span class="attr">praise_nums</span> = response.css(<span class="string">".vote-post-up h10::text"</span>).extract()[<span class="number">0</span>]</span><br><span class="line">       <span class="attr">fav_nums</span> = response.css(<span class="string">".bookmark-btn::text"</span>).extract()[<span class="number">0</span>]</span><br><span class="line">       <span class="attr">match_re</span> = re.match(<span class="string">".*?(\d+).*"</span>, fav_nums)</span><br><span class="line">       <span class="keyword">if</span> match_re:</span><br><span class="line">           <span class="attr">fav_nums</span> = int(match_re.group(<span class="number">1</span>))</span><br><span class="line">       <span class="keyword">else</span>:</span><br><span class="line">           <span class="attr">fav_nums</span> = <span class="number">0</span></span><br></pre></td></tr></table></figure><p>未完待续….等项目全部做完附赠项目地址  </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;一、创建环境&quot;&gt;&lt;a href=&quot;#一、创建环境&quot; class=&quot;headerlink&quot; title=&quot;一、创建环境&quot;&gt;&lt;/a&gt;一、创建环境&lt;/h3&gt;&lt;p&gt;使用pycharm安装spyder&lt;br&gt;打开想要创建的目录&lt;/p&gt;
&lt;figure class=&quot;high
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Pyspider (Third) Basic knowledge</title>
    <link href="http://yoursite.com/2018/11/11/pyspider3/"/>
    <id>http://yoursite.com/2018/11/11/pyspider3/</id>
    <published>2018-11-11T04:08:29.611Z</published>
    <updated>2018-11-11T04:08:48.367Z</updated>
    
    <content type="html"><![CDATA[<p>URL网络实际是一个树形结构，因此分为广度优先和深度优先搜索。<br>真实网站是存在许多环路的，因此一个重要的方法就是去重。本文介绍去重和字符串编码问题  </p><h4 id="一、Depth-First-amp-Width-First"><a href="#一、Depth-First-amp-Width-First" class="headerlink" title="一、Depth-First &amp; Width-First"></a>一、Depth-First &amp; Width-First</h4><p>不做赘述。  </p><h4 id="二、爬虫去重序列"><a href="#二、爬虫去重序列" class="headerlink" title="二、爬虫去重序列"></a>二、爬虫去重序列</h4><ol><li>url经过md5等方法哈希后保存到set中  </li><li>用bitmap方法，将url hash到某一位（缺点：冲突不命中会比较高）  </li><li>用bloomfilter对bitmap进行优化 </li></ol><h3 id="三、Unicode-amp-utf8"><a href="#三、Unicode-amp-utf8" class="headerlink" title="三、Unicode &amp; utf8"></a>三、Unicode &amp; utf8</h3><p>Unicode将所有语言统一到一套编码，都用2byte表示。但是如果说一篇文章全是英文，储存空间和传输量会比Ascii多一倍<br>utf-8将英文又变回一个字节<br>将UTF-8文件读取成Unicode（方便统一操作），处理完后保存成UFT-8文件（节省空间）<br>python3现在用unicode统一进行表示  </p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">"我爱python"</span></span><br><span class="line">s.encode(<span class="string">"utf8"</span>) <span class="comment"># 此时s必须是unicode，不然会报错</span></span><br></pre></td></tr></table></figure><p>前面介绍了基本背景(First)，正则表达式(Second)，和去重及编码，下章节开始讲解Scrapy框架</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;URL网络实际是一个树形结构，因此分为广度优先和深度优先搜索。&lt;br&gt;真实网站是存在许多环路的，因此一个重要的方法就是去重。本文介绍去重和字符串编码问题  &lt;/p&gt;
&lt;h4 id=&quot;一、Depth-First-amp-Width-First&quot;&gt;&lt;a href=&quot;#一、Dep
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Pyspider (Second) regular expression</title>
    <link href="http://yoursite.com/2018/11/09/pyspider2/"/>
    <id>http://yoursite.com/2018/11/09/pyspider2/</id>
    <published>2018-11-09T13:40:54.235Z</published>
    <updated>2018-11-11T04:06:16.854Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、基本规则"><a href="#一、基本规则" class="headerlink" title="一、基本规则"></a>一、基本规则</h4><p> ^b: 强制以b开头<br> .: 可以匹配任意字符<br> *: 可以代表无限多个前一字符<br> 3$: 必须以3强制结尾<br> (): 返回括号内匹配的内容<br> ？: 非贪婪匹配，遇到该字符的第一个就停下 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">line = <span class="string">"waaaaangww123"</span></span><br><span class="line"></span><br><span class="line">regex_str = <span class="string">".*?(w.*w).*"</span> <span class="comment"># waaaaangww</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">regex_str = ".*?(w.*?w).*" # waaaaangw</span></span><br><span class="line"><span class="string">regex_str = ".*(w.*w).*" # ww</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">match_str = re.match(regex_str, line)</span><br><span class="line"><span class="keyword">if</span> match_str:</span><br><span class="line">    print(match_str.group(<span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>+: 前面的字符至少出现一次(与<em>都是次数限定符)<br>{2}: 前面的出现2次  {2,}:前面的出现至少两次  {2，5}: 前面的出现至少两次至多5次<br>|：或, 模式1或者模式2 (优先提取竖线前的模式)<br>[abcd]:前面的字符是abcd中任意一个均可<br>[0-9]:区间任意一个字符<br>[^1]: 不为1<br>[.</em>]: 去除特殊字符的特殊含义</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line"><span class="section"># 举个例子提取电话号码</span></span><br><span class="line">phone_num = "17673168577"</span><br><span class="line">regex_str = "(1[<span class="string">5678</span>][<span class="symbol">0-9</span>]&#123;9&#125;)" # "(1[<span class="string">5678</span>][<span class="symbol">^1</span>]&#123;9&#125;)"</span><br><span class="line"><span class="section"># 17673168577</span></span><br><span class="line"><span class="section"># 以1开头，后面跟5or6or7or8, 再跟9个任意数字</span></span><br><span class="line">match<span class="emphasis">_str = re.match(regex_</span>str, phone_num)</span><br><span class="line">if match_str:</span><br><span class="line"><span class="code">    print(match_str.group(1))</span></span><br></pre></td></tr></table></figure><p>\s: 空格(小写)<br>\S: 单一字符且只要不为空格都可以(大写)<br>\w: 与[A-Za-z0-9_]相同<br>\W: 与上面的相反<br>[\u4E00–u9FA5]: 任意汉字</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;一、基本规则&quot;&gt;&lt;a href=&quot;#一、基本规则&quot; class=&quot;headerlink&quot; title=&quot;一、基本规则&quot;&gt;&lt;/a&gt;一、基本规则&lt;/h4&gt;&lt;p&gt; ^b: 强制以b开头&lt;br&gt; .: 可以匹配任意字符&lt;br&gt; *: 可以代表无限多个前一字符&lt;br&gt; 3$
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Introduction of Pyspider(First)</title>
    <link href="http://yoursite.com/2018/11/09/pyspider1/"/>
    <id>http://yoursite.com/2018/11/09/pyspider1/</id>
    <published>2018-11-09T06:05:38.545Z</published>
    <updated>2018-11-09T06:12:48.628Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、mysql-fo-navicat连接权限问题"><a href="#一、mysql-fo-navicat连接权限问题" class="headerlink" title="一、mysql fo navicat连接权限问题"></a>一、mysql fo navicat连接权限问题</h4><ol><li>在windows上下载navicat</li><li>在linux上配置mysql并在win下用navicat进行连接  </li></ol><blockquote><p>mysql配置文件修改  </p></blockquote><p>外部访问：/etc/mysql/mysql.conf.d/mysqld.cnf<br>编辑文件：bind-address=0.0.0.0</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">to</span> <span class="string">'root'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'root'</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> <span class="keyword">OPTION</span>;</span><br><span class="line"><span class="keyword">flush</span> <span class="keyword">privileges</span>;     <span class="comment">#刷新权限</span></span><br></pre></td></tr></table></figure><h4 id="二、用什么技术"><a href="#二、用什么技术" class="headerlink" title="二、用什么技术"></a>二、用什么技术</h4><p>requests和beautifulsoup都是库，而scrapy是框架。因此本教程运用scrapy  </p><blockquote><p>Scrapy内置的css和xpath selector方便  </p></blockquote><h4 id="三、网页分类"><a href="#三、网页分类" class="headerlink" title="三、网页分类"></a>三、网页分类</h4><ol><li>静态网页（例如hexo）  </li><li>动态网页（例如淘宝）  </li><li>webservice  </li></ol><h4 id="四、能做什么"><a href="#四、能做什么" class="headerlink" title="四、能做什么"></a>四、能做什么</h4><ol><li>搜索引擎—Baidu  </li><li>推荐引擎—今日头条  </li><li>机器学习的数据样本  </li><li>数据分析  </li><li>….</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;一、mysql-fo-navicat连接权限问题&quot;&gt;&lt;a href=&quot;#一、mysql-fo-navicat连接权限问题&quot; class=&quot;headerlink&quot; title=&quot;一、mysql fo navicat连接权限问题&quot;&gt;&lt;/a&gt;一、mysql fo nav
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Super-Resolution Research</title>
    <link href="http://yoursite.com/2018/11/04/super-resolution/"/>
    <id>http://yoursite.com/2018/11/04/super-resolution/</id>
    <published>2018-11-04T10:32:47.610Z</published>
    <updated>2018-11-04T10:34:24.148Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Adapt-Super-resolution-into-real-production"><a href="#Adapt-Super-resolution-into-real-production" class="headerlink" title="Adapt Super-resolution into real production"></a>Adapt Super-resolution into real production</h3><h4 id="08-2018-11-2018"><a href="#08-2018-11-2018" class="headerlink" title="08/2018-11/2018"></a>08/2018-11/2018</h4><ul><li><strong>Tutor:</strong> <a href="http://www.cs.cornell.edu/selman/" target="_blank" rel="noopener">Bart Selman from Cornell University</a> </li><li><strong>Purpose:</strong> Used symmetric padding to improve perceptual quality of image after super-resolution   </li><li><strong>Duties:</strong> Edited code to realize VDSR using tensorflow and symmetric padding to process the images with three channels; Used EC2 of AWS to do experiments using classic Datasets (ImageNet, Set5, Set14) and evaluated the outcomes via PSNR and SSIM; Wrote the Introduction and Experiment&amp;Analysis of the final paper</li><li><a href="https://github.com/JasonWang0808/paper_reading/blob/master/Super-resolution-final.pdf" target="_blank" rel="noopener">Final paper</a> and <a href="https://github.com/JasonWang0808/paper_reading/blob/master/RL.jpg" target="_blank" rel="noopener">Recommendation Letter</a> <strong>(&lt;-CLICK)</strong></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Adapt-Super-resolution-into-real-production&quot;&gt;&lt;a href=&quot;#Adapt-Super-resolution-into-real-production&quot; class=&quot;headerlink&quot; title=&quot;Adapt 
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Reinforment Learning(Five) Actor-Critic</title>
    <link href="http://yoursite.com/2018/11/04/Reinforment_Learning5/"/>
    <id>http://yoursite.com/2018/11/04/Reinforment_Learning5/</id>
    <published>2018-11-04T07:59:58.848Z</published>
    <updated>2018-11-04T08:10:56.306Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>    <blockquote><p>这个方法比较综合，结合了Deep Q-learning Network(DQN)以及Policy-Based Method，通过搭建两个神经网络实现目标<br>buffer、fixed-Q</p></blockquote><h5 id="一、首先看一下action的职责，基于policy-based。当输入不同state的时候，神经网络可以帮我们自动计算出当前采取各个动作的概率。而训练过程我们只需要-action-porb-和-TD-error-即可。-TD-error-是Critic传过来的，actor部分要做的就是通过神经网络得到当前动作，拿到Critic给的-TD-error-反向传播"><a href="#一、首先看一下action的职责，基于policy-based。当输入不同state的时候，神经网络可以帮我们自动计算出当前采取各个动作的概率。而训练过程我们只需要-action-porb-和-TD-error-即可。-TD-error-是Critic传过来的，actor部分要做的就是通过神经网络得到当前动作，拿到Critic给的-TD-error-反向传播" class="headerlink" title="一、首先看一下action的职责，基于policy-based。当输入不同state的时候，神经网络可以帮我们自动计算出当前采取各个动作的概率。而训练过程我们只需要\(action \_porb\)和\(TD\_error\)即可。\(TD\_error\)是Critic传过来的，actor部分要做的就是通过神经网络得到当前动作，拿到Critic给的 \(TD\_error\)反向传播"></a>一、首先看一下action的职责，基于policy-based。当输入不同state的时候，神经网络可以帮我们自动计算出当前采取各个动作的概率。而训练过程我们只需要\(action \_porb\)和\(TD\_error\)即可。\(TD\_error\)是Critic传过来的，actor部分要做的就是通过神经网络得到当前动作，拿到Critic给的 \(TD\_error\)反向传播</h5><blockquote><ol><li>构建网络  </li><li>def learn： 通过state和当前的action(构建one-hot来选择state得到的结果)，以及critic传入的TD-error得到self.exp_v传给优化器优化  </li><li>choose_action : 从概率数组里按照动作的概率选择动作  </li></ol></blockquote><p>注意： 公式\(TD\_error = (r+gamma*V\_next) - V\_eval\)用来说明当前是否比平均状况好，\(TD\_error\)为正且越大说明当前动作选择的越好</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Actor</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, sess, n_features, n_actions, lr=<span class="number">0.001</span>)</span>:</span></span><br><span class="line">        self.sess = sess</span><br><span class="line"></span><br><span class="line">        self.s = tf.placeholder(tf.float32, [<span class="number">1</span>, n_features], <span class="string">"state"</span>)</span><br><span class="line">        self.a = tf.placeholder(tf.int32, <span class="keyword">None</span>, <span class="string">"act"</span>)</span><br><span class="line">        self.td_error = tf.placeholder(tf.float32, <span class="keyword">None</span>, <span class="string">"td_error"</span>)  <span class="comment"># TD_error</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'Actor'</span>):</span><br><span class="line">            l1 = tf.layers.dense(</span><br><span class="line">                inputs=self.s,</span><br><span class="line">                units=<span class="number">20</span>,    <span class="comment"># number of hidden units</span></span><br><span class="line">                activation=tf.nn.relu,</span><br><span class="line">                kernel_initializer=tf.random_normal_initializer(<span class="number">0.</span>, <span class="number">.1</span>),    <span class="comment"># weights</span></span><br><span class="line">                bias_initializer=tf.constant_initializer(<span class="number">0.1</span>),  <span class="comment"># biases</span></span><br><span class="line">                name=<span class="string">'l1'</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            self.acts_prob = tf.layers.dense(</span><br><span class="line">                inputs=l1,</span><br><span class="line">                units=n_actions,    <span class="comment"># output units</span></span><br><span class="line">                activation=tf.nn.softmax,   <span class="comment"># get action probabilities</span></span><br><span class="line">                kernel_initializer=tf.random_normal_initializer(<span class="number">0.</span>, <span class="number">.1</span>),  <span class="comment"># weights</span></span><br><span class="line">                bias_initializer=tf.constant_initializer(<span class="number">0.1</span>),  <span class="comment"># biases</span></span><br><span class="line">                name=<span class="string">'acts_prob'</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'exp_v'</span>):</span><br><span class="line">            log_prob = tf.log(self.acts_prob[<span class="number">0</span>, self.a])</span><br><span class="line">            self.exp_v = tf.reduce_mean(log_prob * self.td_error)  <span class="comment"># advantage (TD_error) guided loss</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'train'</span>):</span><br><span class="line">            self.train_op = tf.train.AdamOptimizer(lr).minimize(-self.exp_v)  <span class="comment"># minimize(-exp_v) = maximize(exp_v)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">learn</span><span class="params">(self, s, a, td)</span>:</span></span><br><span class="line">        s = s[np.newaxis, :]</span><br><span class="line">        feed_dict = &#123;self.s: s, self.a: a, self.td_error: td&#125;</span><br><span class="line">        _, exp_v = self.sess.run([self.train_op, self.exp_v], feed_dict)</span><br><span class="line">        <span class="keyword">return</span> exp_v</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">choose_action</span><span class="params">(self, s)</span>:</span></span><br><span class="line">        s = s[np.newaxis, :]</span><br><span class="line">        probs = self.sess.run(self.acts_prob, &#123;self.s: s&#125;)   <span class="comment"># get probabilities for all actions</span></span><br><span class="line">        <span class="keyword">return</span> np.random.choice(np.arange(probs.shape[<span class="number">1</span>]), p=probs.ravel())   <span class="comment"># return a int</span></span><br></pre></td></tr></table></figure><h5 id="二、看一下Critic的职责。拿到了-state，next-state-reward-计算得到TD-error-进行优化器优化，并传给actor"><a href="#二、看一下Critic的职责。拿到了-state，next-state-reward-计算得到TD-error-进行优化器优化，并传给actor" class="headerlink" title="二、看一下Critic的职责。拿到了\(state，next\_state,reward\), 计算得到TD_error, 进行优化器优化，并传给actor"></a>二、看一下Critic的职责。拿到了\(state，next\_state,reward\), 计算得到TD_error, 进行优化器优化，并传给actor</h5><blockquote><ol><li>构建网络，state对应唯一输出，意思就是当前state应该对应的\(value\_eval\)（平均值，期望），更加简单  </li><li>\(loss={TD\_error}^{2}\), 并不断减小这个loss。</li><li>def learn：传入当前\(s, reward, s\_next\)运行tf得到error   </li></ol></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Critic</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, sess, n_features, lr=<span class="number">0.01</span>)</span>:</span></span><br><span class="line">        self.sess = sess</span><br><span class="line"></span><br><span class="line">        self.s = tf.placeholder(tf.float32, [<span class="number">1</span>, n_features], <span class="string">"state"</span>)</span><br><span class="line">        self.v_ = tf.placeholder(tf.float32, [<span class="number">1</span>, <span class="number">1</span>], <span class="string">"v_next"</span>)</span><br><span class="line">        self.r = tf.placeholder(tf.float32, <span class="keyword">None</span>, <span class="string">'r'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'Critic'</span>):</span><br><span class="line">            l1 = tf.layers.dense(</span><br><span class="line">                inputs=self.s,</span><br><span class="line">                units=<span class="number">20</span>,  <span class="comment"># number of hidden units</span></span><br><span class="line">                activation=tf.nn.relu,  <span class="comment"># None</span></span><br><span class="line">                <span class="comment"># have to be linear to make sure the convergence of actor.</span></span><br><span class="line">                <span class="comment"># But linear approximator seems hardly learns the correct Q.</span></span><br><span class="line">                kernel_initializer=tf.random_normal_initializer(<span class="number">0.</span>, <span class="number">.1</span>),  <span class="comment"># weights</span></span><br><span class="line">                bias_initializer=tf.constant_initializer(<span class="number">0.1</span>),  <span class="comment"># biases</span></span><br><span class="line">                name=<span class="string">'l1'</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            self.v = tf.layers.dense(</span><br><span class="line">                inputs=l1,</span><br><span class="line">                units=<span class="number">1</span>,  <span class="comment"># output units</span></span><br><span class="line">                activation=<span class="keyword">None</span>,</span><br><span class="line">                kernel_initializer=tf.random_normal_initializer(<span class="number">0.</span>, <span class="number">.1</span>),  <span class="comment"># weights</span></span><br><span class="line">                bias_initializer=tf.constant_initializer(<span class="number">0.1</span>),  <span class="comment"># biases</span></span><br><span class="line">                name=<span class="string">'V'</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'squared_TD_error'</span>):</span><br><span class="line">            self.td_error = self.r + GAMMA * self.v_ - self.v</span><br><span class="line">            self.loss = tf.square(self.td_error)    <span class="comment"># TD_error = (r+gamma*V_next) - V_eval</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'train'</span>):</span><br><span class="line">            self.train_op = tf.train.AdamOptimizer(lr).minimize(self.loss)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">learn</span><span class="params">(self, s, r, s_)</span>:</span></span><br><span class="line">        s, s_ = s[np.newaxis, :], s_[np.newaxis, :]</span><br><span class="line"></span><br><span class="line">        v_ = self.sess.run(self.v, &#123;self.s: s_&#125;)</span><br><span class="line">        td_error, _ = self.sess.run([self.td_error, self.train_op],</span><br><span class="line">                                          &#123;self.s: s, self.v_: v_, self.r: r&#125;)</span><br><span class="line">        <span class="keyword">return</span> td_error</span><br></pre></td></tr></table></figure><h5 id="三、两者实现交互"><a href="#三、两者实现交互" class="headerlink" title="三、两者实现交互"></a>三、两者实现交互</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = actor.choose_action(s)</span><br><span class="line"></span><br><span class="line">s_, r, done, info = env.step(a)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   td_error = critic.learn(s, r, s_)  <span class="comment"># gradient = grad[r + gamma * V(s_) - V(s)]</span></span><br><span class="line">   actor.learn(s, a, td_error)     <span class="comment"># true_gradient = grad[logPi(s,a) * td_error]</span></span><br></pre></td></tr></table></figure><p>Refer : <a href="https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/6-1-actor-critic/" target="_blank" rel="noopener">https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/6-1-actor-critic/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&quot;&gt;&lt;/script&gt;    

&lt;blockquote&gt;
&lt;p&gt;这个
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Reinforment Learning(Four) Policy Based Method</title>
    <link href="http://yoursite.com/2018/11/03/Reinforcement_Learning4/"/>
    <id>http://yoursite.com/2018/11/03/Reinforcement_Learning4/</id>
    <published>2018-11-03T04:07:05.799Z</published>
    <updated>2018-11-04T07:59:39.221Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>  <h3 id="Policy-Based-method"><a href="#Policy-Based-method" class="headerlink" title="Policy Based method"></a>Policy Based method</h3><h5 id="莫烦python-Policy-Based-Method"><a href="#莫烦python-Policy-Based-Method" class="headerlink" title="莫烦python Policy Based Method"></a><a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/7_Policy_gradient_softmax" target="_blank" rel="noopener">莫烦python Policy Based Method</a></h5><p>意思是给特定的状态特定的动作 ,适用于一个连续的运动 , <strong>相比于Value-Based方法，我们只在乎当前状态经过神经网络运算出来的action。通过Reward进行训练神经网络的参数\(w\)，而不考虑其数值的算法进行收敛</strong>。<br>随机性搜索策略 (这里以蒙特卡洛为例子，即有限个动作)<br>$$<br>\theta = \theta + \alpha \bigtriangledown_{\theta}log \pi_{\theta}(s_{\tau},a_{t}, \theta)v_{\tau}，可以看到v_{\tau}越大，更新的幅度越大<br>$$</p><blockquote></blockquote><p>$$<br>R_{\tau} = R_{t+1} + \gamma R_{t+2} + \gamma^{2} R_{t+3} + ….<br>$$</p><blockquote></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">neg_log_prob = tf.reduce_sum(-tf.log(self.all_act_prob)*tf.one_hot(self.tf_acts, self.n_actions), axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment">##这里log有符号，因此minimize其实是增大</span></span><br><span class="line">loss = tf.reduce_mean(neg_log_prob * self.tf_vt) </span><br><span class="line"><span class="comment"># 对于不同action，他们的tf.vt不同，train的过程都是增加，但是vt越大增加的概率越大，训练到最后会选择那些vt大的动作</span></span><br></pre></td></tr></table></figure><blockquote><p>\(v_{t}\)是指奖惩的大小，如果我们发现奖惩很好，那么调整神经网络使得这个动作以后多被选中一些。 如果觉得不好，则下一次选中的机会会变小  </p></blockquote><p>但是对于没有终点的任务，比如我们训练一个小孩子上学、吃饭、睡觉、再上学….显然这个是没有终点的，我们找不到一个合适的时间点来更新我们的\(w\)，因此我们采用下面的公式</p><p>$$<br>\Delta \theta = \alpha \ \bigtriangledown_{\theta}(log (S_{t}, A_{t}, \theta) Q(S_{t},A_{t}), 我们采用Q(S_{t},A_{t}来替换R_{\tau}<br>$$</p><p>$$<br>Q(S_{t},A_{t} )= Q(S_{t}, A_{t}) + \beta(R_{t+1} + \gamma Q(S_{t+1}, A_{t+1} - Q(S_{t},A_{t}))<br>$$</p><h4 id="actor-critic-method"><a href="#actor-critic-method" class="headerlink" title="actor-critic method"></a>actor-critic method</h4><p>用两套神经网络，一套用于预测动作，另一套用于评估动作的好坏。 \(\theta \)是Policy Based 来选择动作，\(w\)是前面DQN来生成反馈\(\hat{q}(S, A)\)。因此这个方法也叫做Actor-Critic</p><blockquote><p>actor来源于policy-based， critic来源于value-based。actor来指手画脚，critic告诉他哪一个动作是对，哪一个是错  </p></blockquote><p>$$<br>Actor : \Delta \theta = \alpha \bigtriangledown_{\theta}(log\pi(S_{t},A_{t},\theta))\hat{q}(S_{t}, A_{t}, w)<br>\pi 是选取动作的指令，q是反馈的动作值<br>$$</p><blockquote></blockquote><p>$$<br>Critic : \Delta w = \beta(R_{t+1} + \gamma \hat{q}(S_{t+1}, A_{t}, w)) - \hat{q}(S_{t}, A_{t}, w)) \bigtriangledown_{w} \hat{q}(S_{t}, A_{t}, w)<br>$$</p><h3 id="Deep-Deterministic-Policy-Gradient-DDPG"><a href="#Deep-Deterministic-Policy-Gradient-DDPG" class="headerlink" title="Deep Deterministic Policy Gradient(DDPG)"></a>Deep Deterministic Policy Gradient(DDPG)</h3><p>Deep: 仿照DQN，有一个buffer，两个更新频率不相同的神经网络参数\(w\) , 由deepMind对actor-critic method  </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&quot;&gt;&lt;/script&gt;  

&lt;h3 id=&quot;Policy-Based
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Reinforcement Learning（Third）Code of DQN with TF</title>
    <link href="http://yoursite.com/2018/11/02/Reinforcement_Learning3/"/>
    <id>http://yoursite.com/2018/11/02/Reinforcement_Learning3/</id>
    <published>2018-11-02T07:08:45.222Z</published>
    <updated>2018-11-02T07:19:46.130Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>  <h3 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h3><hr><h4 id="缓冲区及神经网络"><a href="#缓冲区及神经网络" class="headerlink" title="缓冲区及神经网络"></a>缓冲区及神经网络</h4><h5 id="先用-epsilon-greedy-策略选出下一个action，并得到reward和next-state。将-lt-s-t-action-reward-s-t-1-gt-存入缓冲区"><a href="#先用-epsilon-greedy-策略选出下一个action，并得到reward和next-state。将-lt-s-t-action-reward-s-t-1-gt-存入缓冲区" class="headerlink" title="先用\(\epsilon greedy\)策略选出下一个action，并得到reward和next_state。将 \(&lt;s_{t}, action, reward, s_{t+1}&gt;\)存入缓冲区"></a>先用\(\epsilon greedy\)策略选出下一个action，并得到reward和next_state。将 \(&lt;s_{t}, action, reward, s_{t+1}&gt;\)存入缓冲区</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Memory</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, max_size=<span class="number">1000</span>)</span>:</span></span><br><span class="line">        self.buffer = deque(maxlen=max_size)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(self, experience)</span>:</span></span><br><span class="line">        self.buffer.append(experience) <span class="comment">## 添加</span></span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sample</span><span class="params">(self, batch_size)</span>:</span></span><br><span class="line">        idx = np.random.choice(np.arange(len(self.buffer)), </span><br><span class="line">                               size=batch_size, </span><br><span class="line">                               replace=<span class="keyword">False</span>)</span><br><span class="line">        <span class="keyword">return</span> [self.buffer[ii] <span class="keyword">for</span> ii <span class="keyword">in</span> idx] <span class="comment">##随机返回一些batch进行学习</span></span><br></pre></td></tr></table></figure><h5 id="构建一个基础的神经网络，将state的单热点编码作为输入，得到若干个action及他们的数值。"><a href="#构建一个基础的神经网络，将state的单热点编码作为输入，得到若干个action及他们的数值。" class="headerlink" title="构建一个基础的神经网络，将state的单热点编码作为输入，得到若干个action及他们的数值。"></a>构建一个基础的神经网络，将state的单热点编码作为输入，得到若干个action及他们的数值。</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QNetwork</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, learning_rate=<span class="number">0.01</span>, state_size=<span class="number">4</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">                 action_size=<span class="number">2</span>, hidden_size=<span class="number">10</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">                 name=<span class="string">'QNetwork'</span>)</span>:</span></span><br><span class="line">        <span class="comment"># state inputs to the Q-network</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(name):</span><br><span class="line">            self.inputs_ = tf.placeholder(tf.float32, [<span class="keyword">None</span>, state_size], name=<span class="string">'inputs'</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 由于我们都是选定一个动作之后比较Q值，因此在计算时我们会传入当前state选择的action</span></span><br><span class="line">            self.actions_ = tf.placeholder(tf.int32, [<span class="keyword">None</span>], name=<span class="string">'actions'</span>)</span><br><span class="line">            one_hot_actions = tf.one_hot(self.actions_, action_size)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># targetQ另作计算,在training的时候直接传入</span></span><br><span class="line">            self.targetQs_ = tf.placeholder(tf.float32, [<span class="keyword">None</span>], name=<span class="string">'target'</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 构建relu网络</span></span><br><span class="line">            self.fc1 = tf.contrib.layers.fully_connected(self.inputs_, hidden_size)</span><br><span class="line">            self.fc2 = tf.contrib.layers.fully_connected(self.fc1, hidden_size)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 这里是神经网络的输出，targetQ的计算就是单独得到self.output进行处理  </span></span><br><span class="line">            self.output = tf.contrib.layers.fully_connected(self.fc2, action_size, </span><br><span class="line">                                                            activation_fn=<span class="keyword">None</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment">### Train with loss (targetQ - Q)^2</span></span><br><span class="line">            <span class="comment"># </span></span><br><span class="line">            <span class="comment"># 根据state选择的action得到相应的结果，axis=1，说明是行相乘</span></span><br><span class="line">            self.Q = tf.reduce_sum(tf.multiply(self.output, one_hot_actions), axis=<span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># self.targetQs是用神经网络得到不同action的数值后选取max，因此每一个targetQ也是单一数值，与上面的Q对应</span></span><br><span class="line">            self.loss = tf.reduce_mean(tf.square(self.targetQs_ - self.Q))</span><br><span class="line">            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)</span><br></pre></td></tr></table></figure><blockquote><p>\(s_{t}\)与对应的action用来得到\(\hat{Q}(s,a,w)\) then 得到 \(Q(s, max_a, w)\)  </p></blockquote><hr><h4 id="算法主体"><a href="#算法主体" class="headerlink" title="算法主体"></a>算法主体</h4><h5 id="1-使用-epsilon-策略拿到每一次的action"><a href="#1-使用-epsilon-策略拿到每一次的action" class="headerlink" title="1. 使用\(\epsilon \)策略拿到每一次的action"></a>1. 使用\(\epsilon \)策略拿到每一次的action</h5><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">if explore_p &gt; np.<span class="keyword">random</span>.rand():</span><br><span class="line">    <span class="comment"># Make a random action</span></span><br><span class="line">    action = env.action_space.sample()</span><br><span class="line">else:</span><br><span class="line">            <span class="comment"># Get action from Q-network</span></span><br><span class="line">            feed = &#123;mainQN.inputs_: <span class="keyword">state</span>.reshape((<span class="number">1</span>, *<span class="keyword">state</span>.shape))&#125;</span><br><span class="line">            Qs = sess.run(mainQN.output, feed_dict=feed)</span><br><span class="line">            action = np.argmax(Qs)</span><br></pre></td></tr></table></figure><h5 id="2-接着拿到reward、next-state-并存入"><a href="#2-接着拿到reward、next-state-并存入" class="headerlink" title="2. 接着拿到reward、next_state  并存入"></a>2. 接着拿到reward、next_state  并存入</h5><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">next_state, reward, done, _ = env.step(action) <span class="comment">#拿到信息</span></span><br><span class="line"></span><br><span class="line">memory.add((<span class="keyword">state</span>, action, reward, next_state)) <span class="comment">#存入</span></span><br></pre></td></tr></table></figure><blockquote></blockquote><h5 id="3-得到-reward-Q-s-a-w-策略是选取神经网络输出的若干个动作value的最大值"><a href="#3-得到-reward-Q-s-a-w-策略是选取神经网络输出的若干个动作value的最大值" class="headerlink" title="3. 得到\reward + (Q(s,a, w)\), 策略是选取神经网络输出的若干个动作value的最大值"></a>3. 得到\reward + (Q(s,a, w)\), 策略是选取神经网络输出的若干个动作value的最大值</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">    # Train network</span><br><span class="line">    target_Qs = sess.run(mainQN.output, feed_dict=&#123;mainQN.inputs_: next_states&#125;)</span><br><span class="line">                </span><br><span class="line">    # Set target_Qs to <span class="number">0</span> <span class="keyword">for</span> states where episode ends</span><br><span class="line">    episode_ends = (next_states == np.zeros(states[<span class="number">0</span>].shape)).all(axis=<span class="number">1</span>)</span><br><span class="line">    target_Qs[episode_ends] = (<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">                </span><br><span class="line">    targets = rewards + gamma * np.max(target_Qs, axis=<span class="number">1</span>)</span><br><span class="line">```    </span><br><span class="line">&gt; </span><br><span class="line"></span><br><span class="line">#####  <span class="number">4.</span> 训练</span><br></pre></td></tr></table></figure><pre><code>loss, _ = sess.run([mainQN.loss, mainQN.opt],                    feed_dict={mainQN.inputs_: states, ##当前状态                    mainQN.targetQs_: targets,         ##已经计算好                    mainQN.actions_: actions})         ##当前状态所要选取的动作</code></pre><p><code>`</code></p><h5 id="点击这里查看完整ipynb"><a href="#点击这里查看完整ipynb" class="headerlink" title="点击这里查看完整ipynb"></a><a href="https://github.com/JasonWang0808/JasonWang0808.github.io/blob/master/codes/Q-learning-cart.ipynb" target="_blank" rel="noopener">点击这里查看完整ipynb</a></h5>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&quot;&gt;&lt;/script&gt;  

&lt;h3 id=&quot;算法思想&quot;&gt;&lt;a hre
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Reinforcement Learning (Second)</title>
    <link href="http://yoursite.com/2018/11/01/Reinforce_Learning2/"/>
    <id>http://yoursite.com/2018/11/01/Reinforce_Learning2/</id>
    <published>2018-11-01T02:55:19.115Z</published>
    <updated>2018-11-01T12:32:18.616Z</updated>
    
    <content type="html"><![CDATA[<p><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script></p><h4 id="Reference-An-introduction-to-Deep-Q-Learning-let’s-play-Doom"><a href="#Reference-An-introduction-to-Deep-Q-Learning-let’s-play-Doom" class="headerlink" title="Reference : An introduction to Deep Q-Learning: let’s play Doom"></a>Reference : <a href="https://medium.freecodecamp.org/an-introduction-to-deep-q-learning-lets-play-doom-54d02d8017d8/" target="_blank" rel="noopener">An introduction to Deep Q-Learning: let’s play Doom</a></h4><h3 id="Deep-Q-Learning-Network-DQN"><a href="#Deep-Q-Learning-Network-DQN" class="headerlink" title="Deep Q-Learning Network (DQN)"></a>Deep Q-Learning Network (DQN)</h3><h5 id="1-深度强化学习"><a href="#1-深度强化学习" class="headerlink" title="1. 深度强化学习"></a>1. 深度强化学习</h5><p>对于一个复杂的游戏，表示动作及其Value、在Q表里搜索相应的动作变得十分没有效率。因此这里改用神经网络进行Q表的计算。  每次将S放入，即可计算出相应的action及对应的value</p><blockquote><p>\(w\)表示神经网络的权值，\(R\)表示Reward，\(Q\)表示Q表中相应状态和动作对应的数值  </p></blockquote><p>$$<br>current\_predict\_Q = \hat{Q}(s,a,w)<br>$$  </p><p>$$<br>Grdient = \bigtriangledown \hat{Q}(s,a,w)<br>$$   </p><p>$$<br>\Delta w(TDerror) = \alpha[R + \gamma max_{a} \hat{Q}(s\prime ,a, w)) - current\_predict\_Q]<br>$$   </p><h5 id="2-主要优化方法"><a href="#2-主要优化方法" class="headerlink" title="2. 主要优化方法"></a>2. 主要优化方法</h5><blockquote><p>经验回放(Experience Deplay)和固定Q目标是其中的两个主要贡献</p></blockquote><ul><li>经验回放<br>有些动作的代价很大，我们可以把经历过的  \(&lt;S_{t}, A_{t}, R_{t+1}, S_{t+1}&gt;\) 储存在缓冲区中(replay buffer)，后面可以再次用来学习。并可以采取<strong>优先经验回收</strong><br>我们认为，loss越大的数值越具有学习价值，因此buffer里的所有数据都根据其loss决定被选择的概率，每一次学习之后都会更新其概率\(p(i)=\frac{p_{i}^{a}}{\sum_{k=1}^{n} p_{k}^{a}}\),这里的\(a\)保证了不完全按照概率，减少过拟合。（a=1时完全按照概率选取）</li></ul><blockquote><p>研究证明，优先经验回收策略可以减少迭代次数</p></blockquote><ul><li>Q固定<br>我们可以看到在我们的\(R + \gamma max_{a} \hat{Q}(s\prime ,a, w)\)和\(\hat{Q}(s,a,w)\)中都有\(w\)存在。因此两者都在变，导致无法持续收敛。<blockquote><p>打个比方。小明在追他养的牛，想要不断向他的牛靠近。然而他的牛的位置（Q）因为\(w\)的改变也在不断变化。可能一会在小明前，一会去小明后。小明也会懵逼，到底该往哪个方向追。因此我们将\(w^{-}\)固定，事后更新\(w^{-} \gets w\)。这样保证了在收敛过程中目标是确定的不会变化。</p></blockquote></li></ul><p>$$<br>\Delta w(TDerror) = \alpha[R + \gamma max_{a} \hat{Q}(s\prime ,a, w^{-})) - \hat{Q}(s,a,w)]\bigtriangledown \hat{Q}(s,a,w)<br>$$   </p><blockquote><p>Thrun 和 Schwartz，1993 年，<a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.73.3097" target="_blank" rel="noopener">《使用函数逼近进行强化学习存在的问题》（ 高估 Q 值）</a><br>van Hasselt et al.，2015 年，<a href="https://arxiv.org/abs/1509.06461" target="_blank" rel="noopener">《双 Q 学习的深度强化学习》</a><br>Schaul et al.，2016 年，<a href="https://arxiv.org/abs/1511.05952" target="_blank" rel="noopener">《优先经验回放》</a><br>Wang et al.，2015 年，<a href="https://arxiv.org/abs/1511.06581/" target="_blank" rel="noopener">《深度强化学习的对抗网络架构》</a><br>Hausknecht 和 Stone，2015 年，<a href="https://arxiv.org/abs/1507.06527/" target="_blank" rel="noopener">《部分可观察 MDP 的深度递归 Q 学习》</a>    </p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&quot;&gt;&lt;/script&gt;&lt;/p&gt;
&lt;h4 id=&quot;Referenc
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Basic Rules of Tensorflow</title>
    <link href="http://yoursite.com/2018/10/31/tensorflow_basic/"/>
    <id>http://yoursite.com/2018/10/31/tensorflow_basic/</id>
    <published>2018-10-31T13:20:12.830Z</published>
    <updated>2018-11-01T12:31:48.900Z</updated>
    
    <content type="html"><![CDATA[<h2 id="常见符号"><a href="#常见符号" class="headerlink" title="常见符号"></a>常见符号</h2><h3 id="1-tf-Variable-与-tf-constant"><a href="#1-tf-Variable-与-tf-constant" class="headerlink" title="1. tf.Variable 与 tf.constant"></a>1. tf.Variable 与 tf.constant</h3><blockquote><p>第一个可以根据计算改变，第二个是不能变的, 因此神经网络的权值通常都是Variable<br>另外要注意, 定义了变量和常量之后，要初始化才能使用</p></blockquote><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">init = <span class="keyword">tf</span>.global_variables_initializer()</span><br><span class="line">with <span class="keyword">tf</span>.Session() <span class="keyword">as</span> ses<span class="variable">s:</span></span><br><span class="line">    sess.run(init)</span><br></pre></td></tr></table></figure><h3 id="2-tf-reduce-mean"><a href="#2-tf-reduce-mean" class="headerlink" title="2. tf.reduce_mean"></a>2. tf.reduce_mean</h3><blockquote><p>取平均值，后面跟1是取行，跟0是取列</p></blockquote><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">x = np.array([[1.,2.,3.],[4.,5.,6.]])</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    mean_none = sess.<span class="builtin-name">run</span>(tf.reduce_mean(x))</span><br><span class="line">    mean_1 = sess.<span class="builtin-name">run</span>(tf.reduce_mean(x,1))</span><br><span class="line">    mean_2 = sess.<span class="builtin-name">run</span>(tf.reduce_mean(x,0))</span><br><span class="line">    <span class="builtin-name">print</span>(x)</span><br><span class="line">    <span class="builtin-name">print</span>(mean_none)</span><br><span class="line">    <span class="builtin-name">print</span>(mean_1)</span><br><span class="line">    <span class="builtin-name">print</span>(mean_2)</span><br></pre></td></tr></table></figure><h3 id="3-tf-equal"><a href="#3-tf-equal" class="headerlink" title="3. tf.equal"></a>3. tf.equal</h3><blockquote><p>分别比较矩阵中相同的元素，相同就返回true,不同就返回false</p></blockquote><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf  </span><br><span class="line"> import numpy as np  </span><br><span class="line">   </span><br><span class="line"> A = <span class="string">[[1,3,4,5,6]]</span>  </span><br><span class="line"> B = <span class="string">[[1,3,4,3,2]]</span>  </span><br><span class="line">   </span><br><span class="line"> with tf.Session() as sess:  </span><br><span class="line">     <span class="built_in">print</span>(sess.run(tf.equal(A, B)))</span><br></pre></td></tr></table></figure><h3 id="4-tf-truncated-normal"><a href="#4-tf-truncated-normal" class="headerlink" title="4. tf.truncated_normal"></a>4. tf.truncated_normal</h3><blockquote><p>shape 表示要生成的矩阵的大小<br>mean 表示正态函数的均值<br>stddev表示要生成的随机数的方差<br>seed 是随机数种，通常条件下为None</p></blockquote><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.random_normal(shape, <span class="attribute">mean</span>=0.0, <span class="attribute">stddev</span>=1.0, <span class="attribute">dtype</span>=tf.float32, <span class="attribute">seed</span>=None, <span class="attribute">name</span>=None)</span><br></pre></td></tr></table></figure><h3 id="5-tf-reshape"><a href="#5-tf-reshape" class="headerlink" title="5. tf.reshape"></a>5. tf.reshape</h3><blockquote><p>更改矩阵的大小, 通常对图像进行改变<br>参数中可以指定一个 -1 （且只能有一个）, 将根据其他参数的指定自动计算出该维度</p></blockquote><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:<span class="regexp">//</span>blog.csdn.net<span class="regexp">/m0_37592397/</span>article<span class="regexp">/details/</span><span class="number">78695318</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;常见符号&quot;&gt;&lt;a href=&quot;#常见符号&quot; class=&quot;headerlink&quot; title=&quot;常见符号&quot;&gt;&lt;/a&gt;常见符号&lt;/h2&gt;&lt;h3 id=&quot;1-tf-Variable-与-tf-constant&quot;&gt;&lt;a href=&quot;#1-tf-Variable-与-tf
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Flower Classification via VGG</title>
    <link href="http://yoursite.com/2018/10/31/flower_classification/"/>
    <id>http://yoursite.com/2018/10/31/flower_classification/</id>
    <published>2018-10-31T13:18:31.258Z</published>
    <updated>2018-11-01T12:31:36.401Z</updated>
    
    <content type="html"><![CDATA[<h3 id="利用vgg迁移学习实现花朵的分类，基于tensorflow进行实现"><a href="#利用vgg迁移学习实现花朵的分类，基于tensorflow进行实现" class="headerlink" title="利用vgg迁移学习实现花朵的分类，基于tensorflow进行实现"></a>利用vgg迁移学习实现花朵的分类，基于tensorflow进行实现</h3><h4 id="为什么要迁移学习"><a href="#为什么要迁移学习" class="headerlink" title="为什么要迁移学习"></a>为什么要迁移学习</h4><blockquote><h5 id="一个好的CNN可以判断出一个图片的基本轮廓-我们利用这个训练好的CNN得到轮廓并扁平化处理-我们要做的就是搭建ANN-来实现我们自己的classifier"><a href="#一个好的CNN可以判断出一个图片的基本轮廓-我们利用这个训练好的CNN得到轮廓并扁平化处理-我们要做的就是搭建ANN-来实现我们自己的classifier" class="headerlink" title="一个好的CNN可以判断出一个图片的基本轮廓, 我们利用这个训练好的CNN得到轮廓并扁平化处理, 我们要做的就是搭建ANN, 来实现我们自己的classifier"></a>一个好的CNN可以判断出一个图片的基本轮廓, 我们利用这个训练好的CNN得到轮廓并扁平化处理, 我们要做的就是搭建ANN, 来实现我们自己的classifier</h5><p><a href="http://setosa.io/ev/image-kernels/" target="_blank" rel="noopener">一个理解的网站</a></p></blockquote><h3 id="首先介绍两个比较常用的方法"><a href="#首先介绍两个比较常用的方法" class="headerlink" title="首先介绍两个比较常用的方法"></a>首先介绍两个比较常用的方法</h3><h4 id="1-单热点编码"><a href="#1-单热点编码" class="headerlink" title="1. 单热点编码"></a>1. 单热点编码</h4><blockquote><h5 id="在这里我们有五种花-他们的名字都是中文-我们需要对他进行编码"><a href="#在这里我们有五种花-他们的名字都是中文-我们需要对他进行编码" class="headerlink" title="在这里我们有五种花, 他们的名字都是中文, 我们需要对他进行编码"></a>在这里我们有五种花, 他们的名字都是中文, 我们需要对他进行编码</h5></blockquote><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">/* labels是我们要编码的str数组，生成了labels_vecs的二维单热点编码  */</span><br><span class="line">from sklearn.preprocessing import LabelBinarizer</span><br><span class="line"></span><br><span class="line">lb = LabelBinarizer()</span><br><span class="line">lb.fit(labels)</span><br><span class="line"></span><br><span class="line">labels_vecs = lb.transform(labels)</span><br></pre></td></tr></table></figure><p><strong>array</strong><br>([[0, 1, 0, 0, 0],<br>       [0, 1, 0, 0, 0],<br>       [0, 1, 0, 0, 0],<br>       …,<br>       [0, 0, 0, 1, 0],<br>       [0, 0, 0, 1, 0],<br>       [0, 0, 0, 1, 0]])<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></p><h4 id="2-分类—我们需要随机的分出test、valid和Train"><a href="#2-分类—我们需要随机的分出test、valid和Train" class="headerlink" title="2. 分类—我们需要随机的分出test、valid和Train"></a>2. 分类—我们需要随机的分出test、valid和Train</h4><blockquote><h5 id="这里使用机器学习库-how-to-use"><a href="#这里使用机器学习库-how-to-use" class="headerlink" title="这里使用机器学习库 how to use"></a>这里使用机器学习库 <a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html" target="_blank" rel="noopener">how to use</a></h5></blockquote><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection <span class="built_in">import</span> StratifiedShuffleSplit</span><br><span class="line"><span class="comment">/*  固定搭配，里面的参数要弄懂  */</span></span><br><span class="line"><span class="attr">ss</span> = StratifiedShuffleSplit(<span class="attr">n_splits=1,</span> <span class="attr">test_size=0.2)</span></span><br><span class="line"><span class="comment">/* 注意一定要加next，这里返回的是indices（指数） 即数标  */</span></span><br><span class="line">train_idx, <span class="attr">val_idxs</span> = next(ss.split(codes,labels_vecs))</span><br><span class="line"></span><br><span class="line"><span class="attr">half_val</span> = int(len(val_idxs)/<span class="number">2</span>)</span><br><span class="line"><span class="comment">/*  把valid拆分成valid和test    */</span></span><br><span class="line"></span><br><span class="line">val_idx,<span class="attr">test_idx</span> = val_idxs[:half_val],val_idxs[half_val:]</span><br><span class="line"></span><br><span class="line">train_x, <span class="attr">train_y</span> = codes[train_idx],labels_vecs[train_idx]</span><br><span class="line"></span><br><span class="line">val_x, <span class="attr">val_y</span> = codes[val_idx],labels_vecs[val_idx]</span><br><span class="line">test_x, <span class="attr">test_y</span> =  codes[test_idx],labels_vecs[test_idx]</span><br></pre></td></tr></table></figure><h4 id="3-储存结果"><a href="#3-储存结果" class="headerlink" title="3. 储存结果"></a>3. 储存结果</h4><blockquote><h5 id="每次训练结束都要把参数的结果储存到checkpoint中来-下一次test时候直接进行调用"><a href="#每次训练结束都要把参数的结果储存到checkpoint中来-下一次test时候直接进行调用" class="headerlink" title="每次训练结束都要把参数的结果储存到checkpoint中来, 下一次test时候直接进行调用"></a>每次训练结束都要把参数的结果储存到checkpoint中来, 下一次test时候直接进行调用</h5></blockquote><h4 id="4-计算主体"><a href="#4-计算主体" class="headerlink" title="4. 计算主体"></a>4. 计算主体</h4><blockquote><h5 id="外部一个epochs的循环，内部一个计算函数"><a href="#外部一个epochs的循环，内部一个计算函数" class="headerlink" title="外部一个epochs的循环，内部一个计算函数"></a>外部一个epochs的循环，内部一个计算函数</h5></blockquote><h4 id="储存结果"><a href="#储存结果" class="headerlink" title="储存结果"></a>储存结果</h4><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*  详见training部分 */</span></span><br><span class="line">saver.<span class="keyword">save</span>(sess, <span class="string">"checkpoints/flowers.ckpt"</span>)</span><br></pre></td></tr></table></figure><h4 id="加载结果进行使用"><a href="#加载结果进行使用" class="headerlink" title="加载结果进行使用"></a>加载结果进行使用</h4><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 先迁移得到一维矩阵，然后Saver加载参数，test一边   */</span></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    <span class="selector-tag">img</span> = utils.load_image(test_img_path)</span><br><span class="line">    <span class="selector-tag">img</span> = <span class="selector-tag">img</span>.reshape((<span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    feed_dict = &#123;input_: img&#125;</span><br><span class="line">    <span class="selector-tag">code</span> = sess.run(vgg<span class="selector-class">.relu6</span>, feed_dict=feed_dict)</span><br><span class="line">        </span><br><span class="line">saver = tf<span class="selector-class">.train</span><span class="selector-class">.Saver</span>()</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    saver.restore(sess, tf<span class="selector-class">.train</span><span class="selector-class">.latest_checkpoint</span>(<span class="string">'checkpoints'</span>))</span><br><span class="line">    </span><br><span class="line">    feed = &#123;inputs_: code&#125;</span><br><span class="line">    prediction = sess.run(predicted, feed_dict=feed).squeeze()</span><br></pre></td></tr></table></figure><h4 id="data-cutting"><a href="#data-cutting" class="headerlink" title="data cutting"></a>data cutting</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">/* 设置函数<span class="number">10</span>个图片的处理    */</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_batches</span><span class="params">(x, y, n_batches=<span class="number">10</span>)</span>:</span></span><br><span class="line">    <span class="string">""" Return a generator that yields batches from arrays x and y. """</span></span><br><span class="line">    batch_size = len(x)//n_batches</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> ii <span class="keyword">in</span> range(<span class="number">0</span>, n_batches*batch_size, batch_size):</span><br><span class="line">        <span class="comment"># If we're not on the last batch, grab data with size batch_size</span></span><br><span class="line">        <span class="keyword">if</span> ii != (n_batches<span class="number">-1</span>)*batch_size:</span><br><span class="line">            X, Y = x[ii: ii+batch_size], y[ii: ii+batch_size] </span><br><span class="line">        <span class="comment"># On the last batch, grab the rest of the data</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            X, Y = x[ii:], y[ii:]</span><br><span class="line">        <span class="comment"># I love generators</span></span><br><span class="line">        <span class="keyword">yield</span> X, Y</span><br></pre></td></tr></table></figure><h4 id="building-NN"><a href="#building-NN" class="headerlink" title="building NN"></a>building NN</h4><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">inputs_ = tf.placeholder(tf.float32, shape=[None, codes.shape[1]])</span><br><span class="line">labels_ = tf.placeholder(tf.int64, shape=[None, labels_vecs.shape[1]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span> Classifier layers and operations</span></span><br><span class="line">/* 搭建一个简单的ANN   */</span><br><span class="line">fc = tf.contrib.layers.fully_connected(inputs_,256)</span><br><span class="line"></span><br><span class="line">logits = tf.contrib.layers.fully_connected(fc, labels_vecs.shape[1], activation_fn=None)</span><br><span class="line">cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=labels_, logits=logits)</span><br><span class="line">cost = tf.reduce_mean(cross_entropy)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">optimizer =  tf.train.AdamOptimizer().minimize(cost)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Operations for validation/test accuracy</span></span><br><span class="line">predicted = tf.nn.softmax(logits)</span><br><span class="line">correct_pred = tf.equal(tf.argmax(predicted, 1), tf.argmax(labels_, 1))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span><br></pre></td></tr></table></figure><h4 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h4><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">epochs = 10</span><br><span class="line">iteration = 0</span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    </span><br><span class="line">    sess.<span class="builtin-name">run</span>(tf.global_variables_initializer())</span><br><span class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> get_batches(train_x, train_y):</span><br><span class="line">            feed = &#123;inputs_: x,</span><br><span class="line">                    labels_: y&#125;</span><br><span class="line">            loss, _ = sess.<span class="builtin-name">run</span>([cost, optimizer], <span class="attribute">feed_dict</span>=feed)</span><br><span class="line">            <span class="builtin-name">print</span>(<span class="string">"Epoch: &#123;&#125;/&#123;&#125;"</span>.format(e+1, epochs),</span><br><span class="line">                  <span class="string">"Iteration: &#123;&#125;"</span>.format(iteration),</span><br><span class="line">                  <span class="string">"Training loss: &#123;:.5f&#125;"</span>.format(loss))</span><br><span class="line">            iteration += 1</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> iteration % 5 == 0:</span><br><span class="line">                feed = &#123;inputs_: val_x,</span><br><span class="line">                        labels_: val_y&#125;</span><br><span class="line">                val_acc = sess.<span class="builtin-name">run</span>(accuracy, <span class="attribute">feed_dict</span>=feed)</span><br><span class="line">                <span class="builtin-name">print</span>(<span class="string">"Epoch: &#123;&#125;/&#123;&#125;"</span>.format(e, epochs),</span><br><span class="line">                      <span class="string">"Iteration: &#123;&#125;"</span>.format(iteration),</span><br><span class="line">                      <span class="string">"Validation Acc: &#123;:.4f&#125;"</span>.format(val_acc))</span><br><span class="line">    saver.save(sess, <span class="string">"checkpoints/flowers.ckpt"</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;利用vgg迁移学习实现花朵的分类，基于tensorflow进行实现&quot;&gt;&lt;a href=&quot;#利用vgg迁移学习实现花朵的分类，基于tensorflow进行实现&quot; class=&quot;headerlink&quot; title=&quot;利用vgg迁移学习实现花朵的分类，基于tensorf
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>OBject claasification via Resnet50</title>
    <link href="http://yoursite.com/2018/10/31/Model_detexting_1/"/>
    <id>http://yoursite.com/2018/10/31/Model_detexting_1/</id>
    <published>2018-10-31T13:14:17.923Z</published>
    <updated>2018-11-01T12:31:05.466Z</updated>
    
    <content type="html"><![CDATA[<h2 id="how-to-detect-a-model"><a href="#how-to-detect-a-model" class="headerlink" title="how to detect a model"></a>how to detect a model</h2><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing import image                  </span><br><span class="line"><span class="keyword">from</span> tqdm import tqdm</span><br><span class="line"></span><br><span class="line">def path_to_tensor(img_path):</span><br><span class="line">    # loads RGB image as PIL.Image.Image type</span><br><span class="line">    img = image.load_img(img_path, target_size=(224, 224))</span><br><span class="line">    # convert PIL.Image.Image<span class="built_in"> type </span><span class="keyword">to</span> 3D tensor with shape (224, 224, 3)</span><br><span class="line">    x = image.img_to_array(img)</span><br><span class="line">    # convert 3D tensor <span class="keyword">to</span> 4D tensor with shape (1, 224, 224, 3) <span class="keyword">and</span> return 4D tensor</span><br><span class="line">    return np.expand_dims(x, <span class="attribute">axis</span>=0)</span><br><span class="line"></span><br><span class="line">def paths_to_tensor(img_paths):</span><br><span class="line">    list_of_tensors = [path_to_tensor(img_path) <span class="keyword">for</span> img_path <span class="keyword">in</span> tqdm(img_paths)]</span><br><span class="line">    return np.vstack(list_of_tensors)</span><br></pre></td></tr></table></figure><p><a href="https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a" target="_blank" rel="noopener">you can check in this Dictionary</a>  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications.resnet50 <span class="keyword">import</span> preprocess_input, decode_predictions</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ResNet50_predict_labels</span><span class="params">(img_path)</span>:</span></span><br><span class="line">    <span class="comment"># returns prediction vector for image located at img_path</span></span><br><span class="line">    img = preprocess_input(path_to_tensor(img_path))</span><br><span class="line">    <span class="keyword">return</span> np.argmax(ResNet50_model.predict(img))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;how-to-detect-a-model&quot;&gt;&lt;a href=&quot;#how-to-detect-a-model&quot; class=&quot;headerlink&quot; title=&quot;how to detect a model&quot;&gt;&lt;/a&gt;how to detect a model&lt;/
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>一些在图像处理上常用的方法</title>
    <link href="http://yoursite.com/2018/10/31/basic%20operations%20of%20CV/"/>
    <id>http://yoursite.com/2018/10/31/basic operations of CV/</id>
    <published>2018-10-31T13:08:51.191Z</published>
    <updated>2018-11-01T12:31:44.434Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-获取图像目录"><a href="#1-获取图像目录" class="headerlink" title="1. 获取图像目录"></a>1. 获取图像目录</h3><blockquote><h3 id="glob-cv2"><a href="#glob-cv2" class="headerlink" title="glob, cv2"></a>glob, cv2</h3></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> glob</span><br><span class="line">files_path = glob.glob(<span class="string">r'flower/*'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">img = cv2.imread(files_path[<span class="number">1</span>])</span><br><span class="line">img = cv2.reshape(img, (<span class="number">224</span>,<span class="number">224</span>))</span><br><span class="line"></span><br><span class="line">size = img.size()</span><br><span class="line">print(size)</span><br></pre></td></tr></table></figure><h3 id="2-将图像矩阵连接"><a href="#2-将图像矩阵连接" class="headerlink" title="2. 将图像矩阵连接"></a>2. 将图像矩阵连接</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">codes = <span class="keyword">None</span></span><br><span class="line"><span class="keyword">if</span> codes <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">    codes = code_batch</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    codes = np.concatnate((codes,code_batch))</span><br></pre></td></tr></table></figure><h3 id="3-将图像矩阵（经过CNN处理完）写入txt，并将结果一并储存"><a href="#3-将图像矩阵（经过CNN处理完）写入txt，并将结果一并储存" class="headerlink" title="3. 将图像矩阵（经过CNN处理完）写入txt，并将结果一并储存"></a>3. 将图像矩阵（经过CNN处理完）写入txt，并将结果一并储存</h3><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">'codes'</span>,<span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    codes.tofile(f)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">'labels'</span>,<span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    writer = csv.writer(f,delimiter=<span class="string">'\n'</span>)</span><br><span class="line">    writer.writerow(labels)</span><br></pre></td></tr></table></figure><h3 id="4-将图像矩阵（经过CNN处理完）从txt和CSV读出"><a href="#4-将图像矩阵（经过CNN处理完）从txt和CSV读出" class="headerlink" title="4. 将图像矩阵（经过CNN处理完）从txt和CSV读出"></a>4. 将图像矩阵（经过CNN处理完）从txt和CSV读出</h3><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import csv</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">'labels'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    reader = csv.reader(f,delimiter=<span class="string">'\n'</span>)</span><br><span class="line">    labels = np.array([<span class="keyword">each</span> <span class="keyword">for</span> <span class="keyword">each</span> <span class="keyword">in</span> reader <span class="keyword">if</span> <span class="built_in">len</span>(<span class="keyword">each</span>) &gt; <span class="number">0</span>] ).squeeze()</span><br><span class="line">    </span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">'codes'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    codes = np.fromfile(f, dtype=np.float32)</span><br><span class="line">    codes = np.codes.reshape(<span class="built_in">len</span>(labels),<span class="number">-1</span>)</span><br></pre></td></tr></table></figure><h3 id="5-图像读出并存回"><a href="#5-图像读出并存回" class="headerlink" title="5. 图像读出并存回"></a>5. 图像读出并存回</h3><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import cv2 as <span class="built_in">cv</span></span><br><span class="line"># <span class="built_in">load</span> </span><br><span class="line">img = <span class="built_in">cv</span>.imread(imagepath)</span><br><span class="line"># shape=(<span class="built_in">height</span>, <span class="built_in">width</span>, channel)</span><br><span class="line">h,w,c = img.shape</span><br><span class="line"># <span class="built_in">show</span></span><br><span class="line"><span class="built_in">cv</span>.imshow('window_title', img)</span><br><span class="line"># <span class="built_in">save</span></span><br><span class="line"><span class="built_in">cv</span>.imwrite(savepath, img)</span><br></pre></td></tr></table></figure><h3 id="6-图像旋转"><a href="#6-图像旋转" class="headerlink" title="6.图像旋转"></a>6.图像旋转</h3><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">from math <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> numpy as np</span><br><span class="line"></span><br><span class="line">img = cv2.imread(path[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">height</span>,<span class="built_in">width</span>=img.<span class="built_in">shape</span>[:<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">degree=<span class="number">45</span></span><br><span class="line">#旋转后的尺寸</span><br><span class="line">heightNew=<span class="built_in">int</span>(<span class="built_in">width</span>*fabs(<span class="built_in">sin</span>(<span class="built_in">radians</span>(degree)))+<span class="built_in">height</span>*fabs(<span class="built_in">cos</span>(<span class="built_in">radians</span>(degree))))</span><br><span class="line">widthNew=<span class="built_in">int</span>(<span class="built_in">height</span>*fabs(<span class="built_in">sin</span>(<span class="built_in">radians</span>(degree)))+<span class="built_in">width</span>*fabs(<span class="built_in">cos</span>(<span class="built_in">radians</span>(degree))))</span><br><span class="line"></span><br><span class="line">matRotation=cv2.getRotationMatrix2D((<span class="built_in">width</span>/<span class="number">2</span>,<span class="built_in">height</span>/<span class="number">2</span>),degree,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">matRotation[<span class="number">0</span>,<span class="number">2</span>] +=(widthNew-<span class="built_in">width</span>)/<span class="number">2</span>  #重点在这步，目前不懂为什么加这步</span><br><span class="line">matRotation[<span class="number">1</span>,<span class="number">2</span>] +=(heightNew-<span class="built_in">height</span>)/<span class="number">2</span>  #重点在这步</span><br><span class="line"></span><br><span class="line">imgRotation=cv2.warpAffine(img,matRotation,(widthNew,heightNew),borderValue=(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>))</span><br></pre></td></tr></table></figure><h3 id="7-图像色道分离与合并"><a href="#7-图像色道分离与合并" class="headerlink" title="7. 图像色道分离与合并"></a>7. 图像色道分离与合并</h3><pre><code># 加载图像image = cv2.imread(args[&quot;image&quot;])# 通道分离，注意顺序BGR不是RGB,并且会发现得到的都是灰度图(B, G, R) = cv2.split(image)# 生成一个值为0的单通道数组zeros = np.zeros(image.shape[:2], dtype = &quot;uint8&quot;)# 分别扩展B、G、R成为三通道。另外两个通道用上面的值为0的数组填充cv2.imshow(&quot;Blue&quot;, cv2.merge([B, zeros, zeros]))cv2.imshow(&quot;Green&quot;, cv2.merge([zeros, G, zeros]))cv2.imshow(&quot;Red&quot;, cv2.merge([zeros, zeros, R]))</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1-获取图像目录&quot;&gt;&lt;a href=&quot;#1-获取图像目录&quot; class=&quot;headerlink&quot; title=&quot;1. 获取图像目录&quot;&gt;&lt;/a&gt;1. 获取图像目录&lt;/h3&gt;&lt;blockquote&gt;
&lt;h3 id=&quot;glob-cv2&quot;&gt;&lt;a href=&quot;#glob-c
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Reinforcement Learning（First）</title>
    <link href="http://yoursite.com/2018/10/31/Reinforce_Learning1/"/>
    <id>http://yoursite.com/2018/10/31/Reinforce_Learning1/</id>
    <published>2018-10-31T13:00:28.427Z</published>
    <updated>2018-11-02T07:24:01.708Z</updated>
    
    <content type="html"><![CDATA[<h4 id="我看到网上的强化学习教程通常比较复杂-看完莫烦python后总结出来如下-我将主要用代码形式进行理论的展现-其中个别地方用的是OPENAI的表示方式"><a href="#我看到网上的强化学习教程通常比较复杂-看完莫烦python后总结出来如下-我将主要用代码形式进行理论的展现-其中个别地方用的是OPENAI的表示方式" class="headerlink" title="我看到网上的强化学习教程通常比较复杂, 看完莫烦python后总结出来如下, 我将主要用代码形式进行理论的展现, 其中个别地方用的是OPENAI的表示方式"></a>我看到网上的强化学习教程通常比较复杂, 看完莫烦python后总结出来如下, 我将主要用代码形式进行理论的展现, 其中个别地方用的是OPENAI的表示方式</h4><hr><h3 id="一、回合更新-Monte-Carlo-update"><a href="#一、回合更新-Monte-Carlo-update" class="headerlink" title="一、回合更新(Monte-Carlo update)"></a>一、回合更新(Monte-Carlo update)</h3><h4 id="玩完所有的步数-等到一个episode结束之后再更新数值"><a href="#玩完所有的步数-等到一个episode结束之后再更新数值" class="headerlink" title="玩完所有的步数, 等到一个episode结束之后再更新数值"></a>玩完所有的步数, 等到一个episode结束之后再更新数值</h4><blockquote><p>Monte-Carlo Learning<br>这个方法比较esay, 就是根据尽可能多的经验, 以及平均期望来更新数值。实验成本大, 并且现在很多需要决策的问题是没有结束标志的。  </p></blockquote><h3 id="二、单步更新-Temporal-Difference-update"><a href="#二、单步更新-Temporal-Difference-update" class="headerlink" title="二、单步更新(Temporal-Difference update)"></a>二、单步更新(Temporal-Difference update)</h3><h4 id="每走一步都会更新当前的数值"><a href="#每走一步都会更新当前的数值" class="headerlink" title="每走一步都会更新当前的数值"></a>每走一步都会更新当前的数值</h4><blockquote><p>Q-Learning(off-policy), Sarsa(on-policy)    </p></blockquote><h4 id="1-什么是off-on-policy"><a href="#1-什么是off-on-policy" class="headerlink" title="1. 什么是off/on-policy?"></a>1. 什么是off/on-policy?</h4><h4 id="off-policy的更新value时候的next-action不一定会真实采取-而on-policy更新时候的next-value就是真实采取的"><a href="#off-policy的更新value时候的next-action不一定会真实采取-而on-policy更新时候的next-value就是真实采取的" class="headerlink" title="off-policy的更新value时候的next_action不一定会真实采取, 而on-policy更新时候的next_value就是真实采取的"></a>off-policy的更新value时候的next_action不一定会真实采取, 而on-policy更新时候的next_value就是真实采取的</h4><blockquote><p>小明正在准备高考, 课间的时候小明在思考接下来学习什么知识。首先, 小明想学习数学, 但是小明的数学已经学习的很熟练了，于是<strong>小明并没有拿出课本, 而是在脑海里把课本背诵了一边, 这样一来, 小明虽然没有拿出课本, 但是依然更新了当前的知识,</strong> 接下来小明可能拿出的是英语/语文/物理课本进行学习。这就是我们的off-policy。<strong>倘若是on-policy, 小明就失去了默背这一流程, 想回忆一下数学下一步骤必须拿出数学课本</strong>   </p></blockquote><h4 id="2-epsilon-greedy策略"><a href="#2-epsilon-greedy策略" class="headerlink" title="2. epsilon_greedy策略"></a>2. epsilon_greedy策略</h4><blockquote><p>取到最大值的概率为 <strong>(1-eps) + (eps)/n</strong><br>取到其他n-1种动作的概率为 <strong>(eps)/n</strong></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">epsilon_greedy</span><span class="params">(Q, state, nA, eps)</span>:</span></span><br><span class="line">    <span class="string">"""Selects epsilon-greedy action for supplied state.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Params</span></span><br><span class="line"><span class="string">    ======</span></span><br><span class="line"><span class="string">        Q (dictionary): action-value function</span></span><br><span class="line"><span class="string">        state (int): current state</span></span><br><span class="line"><span class="string">        nA (int): number actions in the environment</span></span><br><span class="line"><span class="string">        eps (float): epsilon</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> random.random() &gt; eps: </span><br><span class="line">    <span class="comment">#  此时是选取最大数值的action进行返回</span></span><br><span class="line">        <span class="keyword">return</span> np.argmax(Q[state])</span><br><span class="line">    <span class="keyword">else</span>:                     </span><br><span class="line">    <span class="comment"># 这个时候对每个取平均</span></span><br><span class="line">        <span class="keyword">return</span> random.choice(np.arange(env.action_space.n))</span><br></pre></td></tr></table></figure><h4 id="3-Q-learning-with-sarsa-max-off-policy"><a href="#3-Q-learning-with-sarsa-max-off-policy" class="headerlink" title="3. Q-learning with sarsa_max?(off-policy)"></a>3. Q-learning with sarsa_max?(off-policy)</h4><p>sarsa_max: 选取下一状态是value最大的动作更新当前状态  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Q-learning Sarsamax</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_Q_sarsamax</span><span class="params">(alpha, gamma, Q, state, action, reward, next_state=None)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Returns updated Q-value for the most recent experience.</span></span><br><span class="line">    </span><br><span class="line">    current = Q[state][action]  <span class="comment"># estimate in Q-table (for current state, action pair)</span></span><br><span class="line">    Qsa_next = np.max(Q[next_state]) <span class="keyword">if</span> next_state <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span> <span class="keyword">else</span> <span class="number">0</span> </span><br><span class="line">    <span class="comment"># find the max q in next_state, but this action is not the real action</span></span><br><span class="line">    target = reward + (gamma * Qsa_next)               <span class="comment"># construct TD target</span></span><br><span class="line">    new_value = current + (alpha * (target - current)) <span class="comment"># get updated value </span></span><br><span class="line">    <span class="keyword">return</span> new_value</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Q-learning</span></span><br><span class="line"> <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    </span><br><span class="line">    action = epsilon_greedy(Q, state, nA, eps)</span><br><span class="line">    <span class="comment"># epsilon-greedy action selection, get next_action in every interation</span></span><br><span class="line">    next_state, reward, done, info = env.step(action)  <span class="comment"># take action A, observe R, S'</span></span><br><span class="line">    score += reward                                    <span class="comment"># add reward to agent's score</span></span><br><span class="line">    Q[state][action] = update_Q_sarsamax(alpha, gamma, Q, \</span><br><span class="line">                                                 state, action, reward, next_state)        </span><br><span class="line">    state = next_state                                 </span><br><span class="line">    <span class="comment">#只更新状态</span></span><br><span class="line">    <span class="keyword">if</span> done:</span><br><span class="line">        tmp_scores.append(score)                       <span class="comment"># append score</span></span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><h4 id="4-Sarsa-Learning"><a href="#4-Sarsa-Learning" class="headerlink" title="4. Sarsa Learning"></a>4. Sarsa Learning</h4><p>每次迭代都会选出下一状态和下一状态将要采取的动作，根据事实(update_Q_sarsa)来进行更新<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_Q_sarsa</span><span class="params">(alpha, gamma, Q, state, action, reward, next_state=None, next_action=None)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#Returns updated Q-value for the most recent experience.</span></span><br><span class="line">    </span><br><span class="line">    current = Q[state][action]  <span class="comment"># estimate in Q-table (for current state, action pair)</span></span><br><span class="line">    <span class="comment"># get value of state, action pair at next time step</span></span><br><span class="line">    Qsa_next = Q[next_state][next_action] <span class="keyword">if</span> next_state <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span> <span class="keyword">else</span> <span class="number">0</span>    </span><br><span class="line">    target = reward + (gamma * Qsa_next)               <span class="comment"># construct TD target</span></span><br><span class="line">    new_value = current + (alpha * (target - current)) <span class="comment"># get updated value</span></span><br><span class="line">    <span class="keyword">return</span> new_value</span><br></pre></td></tr></table></figure></p><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">while True:</span><br><span class="line">    next_state, reward, done, info = env.step(action) <span class="comment"># take action A, observe R, S'</span></span><br><span class="line">    score += reward                                   <span class="comment"># add reward to agent's score</span></span><br><span class="line">    if not done:</span><br><span class="line">    next_action = epsilon_greedy(Q, next_state, nA, eps) <span class="comment"># epsilon-greedy action</span></span><br><span class="line">    Q[<span class="keyword">state</span>][action] = update_Q_sarsa(alpha, gamma, Q, \</span><br><span class="line">                                                  <span class="keyword">state</span>, action, reward, next_state, next_action)</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">state</span> = next_state     <span class="comment"># S &lt;- S'</span></span><br><span class="line">                action = next_action   <span class="comment"># A &lt;- A'</span></span><br><span class="line">                '''</span><br><span class="line">                这里会根据传入update函数的next_action 和 next_state进行更新</span><br><span class="line">                '''</span><br><span class="line">            if done:</span><br><span class="line">                Q[<span class="keyword">state</span>][action] = update_Q_sarsa(alpha, gamma, Q, \</span><br><span class="line">                                                  <span class="keyword">state</span>, action, reward)</span><br><span class="line">                tmp_scores.append(score)    <span class="comment"># append score</span></span><br><span class="line">                break</span><br></pre></td></tr></table></figure><h4 id="5-expected-Sarsa"><a href="#5-expected-Sarsa" class="headerlink" title="5. expected Sarsa"></a>5. expected Sarsa</h4><p>3,4 种描述的更新方法都是取单一action的value, 在期望Sarsa中将对所有的action产生的value计算一个平均期望进行更新  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_Q_expsarsa</span><span class="params">(alpha, gamma, nA, eps, Q, state, action, reward, next_state=None)</span>:</span></span><br><span class="line">    <span class="string">"""Returns updated Q-value for the most recent experience."""</span></span><br><span class="line">    current = Q[state][action]         <span class="comment"># estimate in Q-table (for current state, action pair)</span></span><br><span class="line">    policy_s = np.ones(nA) * eps / nA  </span><br><span class="line">    <span class="comment"># 建立一个向量储存概率，每一个都是 （eps / nA）, nA表示action数量</span></span><br><span class="line">    policy_s[np.argmax(Q[next_state])] = <span class="number">1</span> - eps + (eps / nA) </span><br><span class="line">    <span class="comment"># 将最大value的action的概率变为1 - eps + (eps / nA) </span></span><br><span class="line">    Qsa_next = np.dot(Q[next_state], policy_s)         <span class="comment"># get value of state at next time step</span></span><br><span class="line">    target = reward + (gamma * Qsa_next)               <span class="comment"># construct target</span></span><br><span class="line">    new_value = current + (alpha * (target - current)) <span class="comment"># get updated value </span></span><br><span class="line">    <span class="keyword">return</span> new_value</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;我看到网上的强化学习教程通常比较复杂-看完莫烦python后总结出来如下-我将主要用代码形式进行理论的展现-其中个别地方用的是OPENAI的表示方式&quot;&gt;&lt;a href=&quot;#我看到网上的强化学习教程通常比较复杂-看完莫烦python后总结出来如下-我将主要用代码形式
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>c++ basic rules</title>
    <link href="http://yoursite.com/2018/10/30/c++_rules/"/>
    <id>http://yoursite.com/2018/10/30/c++_rules/</id>
    <published>2018-10-30T11:25:06.905Z</published>
    <updated>2018-11-01T12:31:40.251Z</updated>
    
    <content type="html"><![CDATA[<h3 id="C-STL"><a href="#C-STL" class="headerlink" title="C++ STL"></a>C++ STL</h3><h4 id="1-map"><a href="#1-map" class="headerlink" title="1. map"></a>1. map</h4><p>This can be use there are some simple rules, for example, an integer refers to a string, like in leetcode12 and leetcode13<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;map&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>; </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">map</span>&lt;<span class="keyword">int</span>, <span class="built_in">string</span>&gt; mymap;</span><br><span class="line">    mymap.insert(pair&lt;<span class="keyword">int</span>, <span class="built_in">string</span>&gt;(<span class="number">3</span>,<span class="string">"sdf"</span>));<span class="comment">//using "insert" to do the insert operation</span></span><br><span class="line">    </span><br><span class="line">    <span class="built_in">map</span>&lt;<span class="keyword">int</span>, <span class="built_in">string</span>&gt;::iterator iter;<span class="comment">// define an interator</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (iter = mymap.begin(); iter != mymap.end(); iter ++)&#123;<span class="comment">// from begin() to the end()</span></span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;iter-&gt;first&lt;&lt;<span class="string">" "</span>&lt;&lt;iter-&gt;second;<span class="comment">// first and second value</span></span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="c-String"><a href="#c-String" class="headerlink" title="c++ String"></a>c++ String</h3><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int <span class="built_in">first</span> = str.find(s); // <span class="built_in">return</span> the <span class="built_in">first</span> index of <span class="built_in">substring</span> <span class="string">"s"</span> <span class="keyword">in</span> <span class="string">"str"</span></span><br><span class="line">int <span class="built_in">last</span> = str.find(s); // <span class="built_in">return</span> the <span class="built_in">last</span> index of <span class="built_in">substring</span> <span class="string">"s"</span> <span class="keyword">in</span> <span class="string">"str"</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;C-STL&quot;&gt;&lt;a href=&quot;#C-STL&quot; class=&quot;headerlink&quot; title=&quot;C++ STL&quot;&gt;&lt;/a&gt;C++ STL&lt;/h3&gt;&lt;h4 id=&quot;1-map&quot;&gt;&lt;a href=&quot;#1-map&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Recursion---leetcode</title>
    <link href="http://yoursite.com/2018/10/30/Recursion/"/>
    <id>http://yoursite.com/2018/10/30/Recursion/</id>
    <published>2018-10-30T02:28:18.149Z</published>
    <updated>2018-11-01T12:31:00.605Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Recursion"><a href="#Recursion" class="headerlink" title="Recursion"></a>Recursion</h2><p>From my perspective, Recursion is an efficient way because it makes us to <strong>only look at the current step</strong>. However, its <strong>complexity is very high.</strong></p><hr><h4 id="Example1-10-Regular-Expression-Matching-from-Leetcode"><a href="#Example1-10-Regular-Expression-Matching-from-Leetcode" class="headerlink" title="Example1. 10. Regular Expression Matching from Leetcode"></a>Example1. <a href="https://leetcode.com/problems/regular-expression-matching/solution/" target="_blank" rel="noopener">10. Regular Expression Matching</a> from Leetcode</h4><blockquote><p>You can see the description on the above link.  </p></blockquote><p>My problem is that it contains tooooo many different combination of <strong>“character”, “.” and “*“</strong>. It looks like a time array, which you should look at <strong>the moment</strong>. <strong>time before</strong> and the <strong>future</strong>, which is very bothering.   </p><blockquote><p>So what we do here is only determine the current action, and let the function to judge what to do next itself.  </p></blockquote><p>So, given two arries, we have several choices  </p><ol><li>whether reach the end?<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># p and s reach the end at the same time</span></span><br><span class="line"><span class="comment"># p reach the end, but s doesn't</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isMatch</span><span class="params">(s, p)</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(p.empty())&#123;</span><br><span class="line"><span class="keyword">if</span>(s == empty()) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="string">``</span><span class="string">`  </span></span><br><span class="line"><span class="string">2. if the first character match?</span></span><br></pre></td></tr></table></figure></li></ol><p>def isMatch(s, p){<br>    bool first_match;<br>    if(s[0] == p[0] || p[0] == ‘.’) first_match = true;</p><p>}<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">3.</span> <span class="keyword">is</span> <span class="keyword">it</span> followed <span class="keyword">by</span> * ?</span><br></pre></td></tr></table></figure></p><p>def isMatch(s, p){<br>    if(p.length() &gt;= 2 || p[1] == ‘<em>‘): # the second character of p is </em></p><pre><code># this if means: * is 0 or not    return isMatch(s, p.substr(2)) || (first_match &amp;&amp; isMatch(s.substr(1), p)else:    return first_match &amp;&amp; isMatch(s.substr(1), p.substr(1))</code></pre><p>}<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The complete <span class="selector-tag">code</span> <span class="keyword">in</span> C++</span><br></pre></td></tr></table></figure></p><p>#include <iostream><br>using namespace std;<br>class Solution {<br>public:<br>    bool isMatch(string s, string p) {<br>        bool first = false;<br>        if(p.empty()){<br>            return (s.empty());<br>        }<br>        else{<br>            first = (!s.empty() &amp;&amp; (s[0] == p[0] || p[0] == ‘.’));<br>        }<br>        if(p.length()&gt;= 2 &amp;&amp; p[1] == ‘<em>‘){<br>            return (isMatch(s, p.substr(2)) || (first &amp;&amp; isMatch(s.substr(1), p) ) ); // make </em> be 0  || make * be at least 1<br>        }<br>        else return first &amp;&amp; isMatch(s.substr(1), p.substr(1));<br>    }<br>};<br>int main() {<br>    Solution solution;</iostream></p><pre><code>return 0;</code></pre><p>}<br><code>`</code><br>We can see that the compexity is high. Because there are many duplicated calculations. SO we can set an array to solve this problem, this is same with <strong>DYNAMIC PROGRAMMING</strong>, which we will dicuss in there.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Recursion&quot;&gt;&lt;a href=&quot;#Recursion&quot; class=&quot;headerlink&quot; title=&quot;Recursion&quot;&gt;&lt;/a&gt;Recursion&lt;/h2&gt;&lt;p&gt;From my perspective, Recursion is an effic
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Dynamic Programming---Leetcode</title>
    <link href="http://yoursite.com/2018/10/30/DP/"/>
    <id>http://yoursite.com/2018/10/30/DP/</id>
    <published>2018-10-30T02:28:18.140Z</published>
    <updated>2018-11-01T12:31:23.431Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Dynamic-Programming"><a href="#Dynamic-Programming" class="headerlink" title="Dynamic Programming"></a>Dynamic Programming</h3><p>The situations are that our current situations depend on the old calculations. So we don’t need to start from the begining again, <strong>we can store the outcome of each step so we can cite it directly.</strong></p><p>Usually, the parameters of the function are the index instead of the object (string etc.) itself. Because our operations are on the matrix.</p><hr><h5 id="Example1-5-Longest-Palindromic-Substring-from-Leetcode"><a href="#Example1-5-Longest-Palindromic-Substring-from-Leetcode" class="headerlink" title="Example1. 5. Longest Palindromic Substring from Leetcode"></a>Example1. <a href="https://leetcode.com/problems/longest-palindromic-substring/description/" target="_blank" rel="noopener">5. Longest Palindromic Substring</a> from Leetcode</h5><p>We calculation according to the length of the string. If we wanna judge ‘cbbaac’, we can find whether ‘bbaa’ is Palindromic, then find the character from the two ends are same.</p><hr><h5 id="Example2-10-Regular-Expression-Matching-from-the-Leetcode"><a href="#Example2-10-Regular-Expression-Matching-from-the-Leetcode" class="headerlink" title="Example2. 10. Regular Expression Matching from the Leetcode"></a>Example2. <a href="https://leetcode.com/problems/regular-expression-matching/description/" target="_blank" rel="noopener">10. Regular Expression Matching</a> from the Leetcode</h5><p>Just like we talk in  “Recursion”, DP algorithm sometimes help Recursion to decrease the calculation. Such as:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dp</span><span class="params">(i, j, arr)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> arr[i][j] != null: <span class="comment">## it can returns directly</span></span><br><span class="line">        <span class="keyword">return</span> arr[i][j] </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        calculate the arr[i][j]</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Dynamic-Programming&quot;&gt;&lt;a href=&quot;#Dynamic-Programming&quot; class=&quot;headerlink&quot; title=&quot;Dynamic Programming&quot;&gt;&lt;/a&gt;Dynamic Programming&lt;/h3&gt;&lt;p&gt;Th
      
    
    </summary>
    
    
  </entry>
  
</feed>
